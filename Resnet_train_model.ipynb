{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "199ef76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module Import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f280797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05b7aa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:2.0.0\n",
      "MPS 장치를 지원하도록 build 되었는지: True\n",
      "MPS 장치가 사용 가능한지: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (f\"PyTorch version:{torch.__version__}\") # 1.12.1 이상\n",
    "print(f\"MPS 장치를 지원하도록 build 되었는지: {torch.backends.mps.is_built()}\") # True 여야 합니다.\n",
    "print(f\"MPS 장치가 사용 가능한지: {torch.backends.mps.is_available()}\") # True 여야 합니다.\n",
    "#python -c 'import platform;print(platform.platform())'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f6fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchvision import models\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15731536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"mps\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edb1ea9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mps_device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m5\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[43mmps_device\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mps_device' is not defined"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, device=mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb137239",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccb58986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'images', 'meta', 'license_agreement.txt', 'README.txt']\n"
     ]
    }
   ],
   "source": [
    "input_root_dir = \"/Users/munseunghyeon/input/food-101/food-101\"\n",
    "input_root_path = Path(input_root_dir)\n",
    "print(os.listdir(input_root_dir))\n",
    "image_dir_path = input_root_path/'images'\n",
    "\n",
    "class_path = input_root_dir+'/meta/classes.txt'\n",
    "train_img_name_path = input_root_dir+'/meta/train.txt'\n",
    "test_img_name_path = input_root_dir+'/meta/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9f4e3d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/munseunghyeon/input/food-101/food-101/meta/train.txt'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "89a11e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie/1005649',\n",
       " 'apple_pie/1014775',\n",
       " 'apple_pie/1026328',\n",
       " 'apple_pie/1028787',\n",
       " 'apple_pie/1043283',\n",
       " 'apple_pie/1050519',\n",
       " 'apple_pie/1057749',\n",
       " 'apple_pie/1057810',\n",
       " 'apple_pie/1072416',\n",
       " 'apple_pie/1074856',\n",
       " 'apple_pie/1074942',\n",
       " 'apple_pie/1076891',\n",
       " 'apple_pie/1077610',\n",
       " 'apple_pie/1077964',\n",
       " 'apple_pie/1088809',\n",
       " 'apple_pie/1097378',\n",
       " 'apple_pie/1103795',\n",
       " 'apple_pie/1109597',\n",
       " 'apple_pie/1111062',\n",
       " 'apple_pie/1112300',\n",
       " 'apple_pie/1112838',\n",
       " 'apple_pie/1121884',\n",
       " 'apple_pie/112378',\n",
       " 'apple_pie/1133267',\n",
       " 'apple_pie/1142597',\n",
       " 'apple_pie/1147371',\n",
       " 'apple_pie/1154371',\n",
       " 'apple_pie/1158360',\n",
       " 'apple_pie/1159801',\n",
       " 'apple_pie/1165004',\n",
       " 'apple_pie/1166116',\n",
       " 'apple_pie/1166210',\n",
       " 'apple_pie/116697',\n",
       " 'apple_pie/1174241',\n",
       " 'apple_pie/1174949',\n",
       " 'apple_pie/1177254',\n",
       " 'apple_pie/118237',\n",
       " 'apple_pie/1184568',\n",
       " 'apple_pie/1185445',\n",
       " 'apple_pie/1185654',\n",
       " 'apple_pie/1191665',\n",
       " 'apple_pie/1196628',\n",
       " 'apple_pie/1199851',\n",
       " 'apple_pie/1200079',\n",
       " 'apple_pie/1214326',\n",
       " 'apple_pie/1215650',\n",
       " 'apple_pie/1218767',\n",
       " 'apple_pie/1220194',\n",
       " 'apple_pie/1230465',\n",
       " 'apple_pie/1232311',\n",
       " 'apple_pie/123782',\n",
       " 'apple_pie/1239205',\n",
       " 'apple_pie/1240585',\n",
       " 'apple_pie/1246460',\n",
       " 'apple_pie/1246552',\n",
       " 'apple_pie/1252879',\n",
       " 'apple_pie/1264435',\n",
       " 'apple_pie/1265307',\n",
       " 'apple_pie/1272778',\n",
       " 'apple_pie/127721',\n",
       " 'apple_pie/1280767',\n",
       " 'apple_pie/128259',\n",
       " 'apple_pie/1284682',\n",
       " 'apple_pie/1289014',\n",
       " 'apple_pie/1290425',\n",
       " 'apple_pie/1305678',\n",
       " 'apple_pie/1322211',\n",
       " 'apple_pie/1323309',\n",
       " 'apple_pie/1335563',\n",
       " 'apple_pie/134',\n",
       " 'apple_pie/1340287',\n",
       " 'apple_pie/1343307',\n",
       " 'apple_pie/1344873',\n",
       " 'apple_pie/1346262',\n",
       " 'apple_pie/1348788',\n",
       " 'apple_pie/1350394',\n",
       " 'apple_pie/1354215',\n",
       " 'apple_pie/1355206',\n",
       " 'apple_pie/1357950',\n",
       " 'apple_pie/1361950',\n",
       " 'apple_pie/136256',\n",
       " 'apple_pie/1376013',\n",
       " 'apple_pie/1379062',\n",
       " 'apple_pie/1391393',\n",
       " 'apple_pie/1392703',\n",
       " 'apple_pie/1397313',\n",
       " 'apple_pie/1399051',\n",
       " 'apple_pie/1406371',\n",
       " 'apple_pie/1410907',\n",
       " 'apple_pie/1416578',\n",
       " 'apple_pie/1420227',\n",
       " 'apple_pie/1421796',\n",
       " 'apple_pie/142332',\n",
       " 'apple_pie/1428585',\n",
       " 'apple_pie/1442421',\n",
       " 'apple_pie/1443243',\n",
       " 'apple_pie/1445323',\n",
       " 'apple_pie/1447062',\n",
       " 'apple_pie/1448488',\n",
       " 'apple_pie/1450514',\n",
       " 'apple_pie/1456028',\n",
       " 'apple_pie/1456379',\n",
       " 'apple_pie/1464079',\n",
       " 'apple_pie/1466791',\n",
       " 'apple_pie/1481550',\n",
       " 'apple_pie/1484086',\n",
       " 'apple_pie/1486972',\n",
       " 'apple_pie/1487150',\n",
       " 'apple_pie/1488583',\n",
       " 'apple_pie/1491146',\n",
       " 'apple_pie/1498817',\n",
       " 'apple_pie/1503274',\n",
       " 'apple_pie/1528187',\n",
       " 'apple_pie/1528623',\n",
       " 'apple_pie/1544507',\n",
       " 'apple_pie/1547651',\n",
       " 'apple_pie/1550786',\n",
       " 'apple_pie/1558003',\n",
       " 'apple_pie/1558101',\n",
       " 'apple_pie/156078',\n",
       " 'apple_pie/157083',\n",
       " 'apple_pie/1575505',\n",
       " 'apple_pie/1580276',\n",
       " 'apple_pie/1581291',\n",
       " 'apple_pie/1581853',\n",
       " 'apple_pie/1586889',\n",
       " 'apple_pie/1595134',\n",
       " 'apple_pie/1596650',\n",
       " 'apple_pie/1596752',\n",
       " 'apple_pie/1620714',\n",
       " 'apple_pie/1622276',\n",
       " 'apple_pie/1633183',\n",
       " 'apple_pie/1633812',\n",
       " 'apple_pie/1646808',\n",
       " 'apple_pie/1648647',\n",
       " 'apple_pie/1659828',\n",
       " 'apple_pie/1667135',\n",
       " 'apple_pie/1670009',\n",
       " 'apple_pie/1677760',\n",
       " 'apple_pie/1689411',\n",
       " 'apple_pie/1698156',\n",
       " 'apple_pie/1700578',\n",
       " 'apple_pie/1710288',\n",
       " 'apple_pie/1717754',\n",
       " 'apple_pie/1725573',\n",
       " 'apple_pie/1725747',\n",
       " 'apple_pie/1727085',\n",
       " 'apple_pie/1735072',\n",
       " 'apple_pie/1739519',\n",
       " 'apple_pie/1753164',\n",
       " 'apple_pie/1753171',\n",
       " 'apple_pie/1753935',\n",
       " 'apple_pie/1756344',\n",
       " 'apple_pie/1764457',\n",
       " 'apple_pie/1766910',\n",
       " 'apple_pie/1767333',\n",
       " 'apple_pie/1771395',\n",
       " 'apple_pie/1786261',\n",
       " 'apple_pie/1789100',\n",
       " 'apple_pie/1790730',\n",
       " 'apple_pie/1810149',\n",
       " 'apple_pie/1815972',\n",
       " 'apple_pie/1816741',\n",
       " 'apple_pie/1818676',\n",
       " 'apple_pie/1819763',\n",
       " 'apple_pie/1820074',\n",
       " 'apple_pie/1822764',\n",
       " 'apple_pie/182745',\n",
       " 'apple_pie/1830100',\n",
       " 'apple_pie/1830215',\n",
       " 'apple_pie/1830582',\n",
       " 'apple_pie/1840575',\n",
       " 'apple_pie/1847944',\n",
       " 'apple_pie/185537',\n",
       " 'apple_pie/1873576',\n",
       " 'apple_pie/1874318',\n",
       " 'apple_pie/1874325',\n",
       " 'apple_pie/1879193',\n",
       " 'apple_pie/1886600',\n",
       " 'apple_pie/1886694',\n",
       " 'apple_pie/1895811',\n",
       " 'apple_pie/1897389',\n",
       " 'apple_pie/1899134',\n",
       " 'apple_pie/1914188',\n",
       " 'apple_pie/1923768',\n",
       " 'apple_pie/1931301',\n",
       " 'apple_pie/1936913',\n",
       " 'apple_pie/1939853',\n",
       " 'apple_pie/1941412',\n",
       " 'apple_pie/1944962',\n",
       " 'apple_pie/1946376',\n",
       " 'apple_pie/195087',\n",
       " 'apple_pie/1954841',\n",
       " 'apple_pie/1963597',\n",
       " 'apple_pie/1969851',\n",
       " 'apple_pie/1977565',\n",
       " 'apple_pie/1984895',\n",
       " 'apple_pie/1988310',\n",
       " 'apple_pie/1990658',\n",
       " 'apple_pie/1994318',\n",
       " 'apple_pie/1995380',\n",
       " 'apple_pie/2004963',\n",
       " 'apple_pie/2008772',\n",
       " 'apple_pie/2012973',\n",
       " 'apple_pie/2023705',\n",
       " 'apple_pie/202741',\n",
       " 'apple_pie/2030311',\n",
       " 'apple_pie/2034923',\n",
       " 'apple_pie/2047916',\n",
       " 'apple_pie/2051864',\n",
       " 'apple_pie/205716',\n",
       " 'apple_pie/2067073',\n",
       " 'apple_pie/2068700',\n",
       " 'apple_pie/2074865',\n",
       " 'apple_pie/2075376',\n",
       " 'apple_pie/208041',\n",
       " 'apple_pie/2086645',\n",
       " 'apple_pie/2088064',\n",
       " 'apple_pie/2101662',\n",
       " 'apple_pie/2106005',\n",
       " 'apple_pie/21063',\n",
       " 'apple_pie/2110106',\n",
       " 'apple_pie/2111966',\n",
       " 'apple_pie/2126901',\n",
       " 'apple_pie/2132230',\n",
       " 'apple_pie/2133067',\n",
       " 'apple_pie/2143318',\n",
       " 'apple_pie/214334',\n",
       " 'apple_pie/2151461',\n",
       " 'apple_pie/2153869',\n",
       " 'apple_pie/2157956',\n",
       " 'apple_pie/2163544',\n",
       " 'apple_pie/2171324',\n",
       " 'apple_pie/2178254',\n",
       " 'apple_pie/2195793',\n",
       " 'apple_pie/2200328',\n",
       " 'apple_pie/2202694',\n",
       " 'apple_pie/2205061',\n",
       " 'apple_pie/222074',\n",
       " 'apple_pie/2223296',\n",
       " 'apple_pie/2223847',\n",
       " 'apple_pie/2224273',\n",
       " 'apple_pie/2231842',\n",
       " 'apple_pie/2235547',\n",
       " 'apple_pie/2235729',\n",
       " 'apple_pie/2239083',\n",
       " 'apple_pie/2245633',\n",
       " 'apple_pie/2245635',\n",
       " 'apple_pie/2248020',\n",
       " 'apple_pie/2267350',\n",
       " 'apple_pie/2288697',\n",
       " 'apple_pie/2298862',\n",
       " 'apple_pie/2302866',\n",
       " 'apple_pie/2303859',\n",
       " 'apple_pie/2306493',\n",
       " 'apple_pie/2320000',\n",
       " 'apple_pie/2323355',\n",
       " 'apple_pie/2328227',\n",
       " 'apple_pie/2335873',\n",
       " 'apple_pie/2337097',\n",
       " 'apple_pie/2337652',\n",
       " 'apple_pie/2339010',\n",
       " 'apple_pie/2345199',\n",
       " 'apple_pie/2347111',\n",
       " 'apple_pie/2348133',\n",
       " 'apple_pie/235537',\n",
       " 'apple_pie/2361153',\n",
       " 'apple_pie/2364059',\n",
       " 'apple_pie/2369640',\n",
       " 'apple_pie/236966',\n",
       " 'apple_pie/2379223',\n",
       " 'apple_pie/2383378',\n",
       " 'apple_pie/238868',\n",
       " 'apple_pie/23893',\n",
       " 'apple_pie/2391509',\n",
       " 'apple_pie/2400434',\n",
       " 'apple_pie/2408052',\n",
       " 'apple_pie/2412284',\n",
       " 'apple_pie/2416573',\n",
       " 'apple_pie/2421227',\n",
       " 'apple_pie/2434963',\n",
       " 'apple_pie/2439188',\n",
       " 'apple_pie/2447106',\n",
       " 'apple_pie/2447421',\n",
       " 'apple_pie/2451702',\n",
       " 'apple_pie/2453243',\n",
       " 'apple_pie/245712',\n",
       " 'apple_pie/2458159',\n",
       " 'apple_pie/2479319',\n",
       " 'apple_pie/2480328',\n",
       " 'apple_pie/2485958',\n",
       " 'apple_pie/2486622',\n",
       " 'apple_pie/2490410',\n",
       " 'apple_pie/2510497',\n",
       " 'apple_pie/2517642',\n",
       " 'apple_pie/2518174',\n",
       " 'apple_pie/2519446',\n",
       " 'apple_pie/2520241',\n",
       " 'apple_pie/2520431',\n",
       " 'apple_pie/2523745',\n",
       " 'apple_pie/2527163',\n",
       " 'apple_pie/2528236',\n",
       " 'apple_pie/2536578',\n",
       " 'apple_pie/2538221',\n",
       " 'apple_pie/2540831',\n",
       " 'apple_pie/2542633',\n",
       " 'apple_pie/2546216',\n",
       " 'apple_pie/2548878',\n",
       " 'apple_pie/2564881',\n",
       " 'apple_pie/2569986',\n",
       " 'apple_pie/2570111',\n",
       " 'apple_pie/257378',\n",
       " 'apple_pie/2574026',\n",
       " 'apple_pie/2579504',\n",
       " 'apple_pie/2581687',\n",
       " 'apple_pie/2582077',\n",
       " 'apple_pie/2586142',\n",
       " 'apple_pie/2586267',\n",
       " 'apple_pie/2591737',\n",
       " 'apple_pie/2595208',\n",
       " 'apple_pie/2598068',\n",
       " 'apple_pie/259923',\n",
       " 'apple_pie/2600379',\n",
       " 'apple_pie/2601590',\n",
       " 'apple_pie/2601920',\n",
       " 'apple_pie/2602468',\n",
       " 'apple_pie/2603533',\n",
       " 'apple_pie/2605371',\n",
       " 'apple_pie/2605751',\n",
       " 'apple_pie/2606415',\n",
       " 'apple_pie/2607306',\n",
       " 'apple_pie/2607694',\n",
       " 'apple_pie/2610017',\n",
       " 'apple_pie/2612593',\n",
       " 'apple_pie/2615584',\n",
       " 'apple_pie/2620367',\n",
       " 'apple_pie/2621542',\n",
       " 'apple_pie/2626973',\n",
       " 'apple_pie/2627767',\n",
       " 'apple_pie/2635983',\n",
       " 'apple_pie/2648160',\n",
       " 'apple_pie/2651801',\n",
       " 'apple_pie/2656095',\n",
       " 'apple_pie/2658301',\n",
       " 'apple_pie/265928',\n",
       " 'apple_pie/266007',\n",
       " 'apple_pie/2666921',\n",
       " 'apple_pie/2677312',\n",
       " 'apple_pie/267865',\n",
       " 'apple_pie/2682484',\n",
       " 'apple_pie/2683315',\n",
       " 'apple_pie/2698000',\n",
       " 'apple_pie/2702725',\n",
       " 'apple_pie/2704442',\n",
       " 'apple_pie/2705419',\n",
       " 'apple_pie/2708417',\n",
       " 'apple_pie/2713482',\n",
       " 'apple_pie/2713820',\n",
       " 'apple_pie/2721937',\n",
       " 'apple_pie/2722097',\n",
       " 'apple_pie/2722635',\n",
       " 'apple_pie/2724897',\n",
       " 'apple_pie/2725375',\n",
       " 'apple_pie/2735083',\n",
       " 'apple_pie/2735451',\n",
       " 'apple_pie/2740775',\n",
       " 'apple_pie/2740848',\n",
       " 'apple_pie/274516',\n",
       " 'apple_pie/2745186',\n",
       " 'apple_pie/2745241',\n",
       " 'apple_pie/2751362',\n",
       " 'apple_pie/2751755',\n",
       " 'apple_pie/2761063',\n",
       " 'apple_pie/2761976',\n",
       " 'apple_pie/2762199',\n",
       " 'apple_pie/2764233',\n",
       " 'apple_pie/2764778',\n",
       " 'apple_pie/2766379',\n",
       " 'apple_pie/2766609',\n",
       " 'apple_pie/2766725',\n",
       " 'apple_pie/2767057',\n",
       " 'apple_pie/2768268',\n",
       " 'apple_pie/2769307',\n",
       " 'apple_pie/2769368',\n",
       " 'apple_pie/2769470',\n",
       " 'apple_pie/2776008',\n",
       " 'apple_pie/2777088',\n",
       " 'apple_pie/2777273',\n",
       " 'apple_pie/2781167',\n",
       " 'apple_pie/2782050',\n",
       " 'apple_pie/2782633',\n",
       " 'apple_pie/2785030',\n",
       " 'apple_pie/2799681',\n",
       " 'apple_pie/2800543',\n",
       " 'apple_pie/280199',\n",
       " 'apple_pie/2804953',\n",
       " 'apple_pie/2806926',\n",
       " 'apple_pie/2812998',\n",
       " 'apple_pie/2819375',\n",
       " 'apple_pie/2819833',\n",
       " 'apple_pie/282352',\n",
       " 'apple_pie/2825284',\n",
       " 'apple_pie/2828161',\n",
       " 'apple_pie/2839261',\n",
       " 'apple_pie/2839283',\n",
       " 'apple_pie/2840005',\n",
       " 'apple_pie/2847214',\n",
       " 'apple_pie/2851371',\n",
       " 'apple_pie/2853890',\n",
       " 'apple_pie/2854105',\n",
       " 'apple_pie/285509',\n",
       " 'apple_pie/2856273',\n",
       " 'apple_pie/2856319',\n",
       " 'apple_pie/2861144',\n",
       " 'apple_pie/2869633',\n",
       " 'apple_pie/2872568',\n",
       " 'apple_pie/2874860',\n",
       " 'apple_pie/2900219',\n",
       " 'apple_pie/2902847',\n",
       " 'apple_pie/2909830',\n",
       " 'apple_pie/2911613',\n",
       " 'apple_pie/2914000',\n",
       " 'apple_pie/2915359',\n",
       " 'apple_pie/2918880',\n",
       " 'apple_pie/2921600',\n",
       " 'apple_pie/2922138',\n",
       " 'apple_pie/292333',\n",
       " 'apple_pie/2924795',\n",
       " 'apple_pie/2928660',\n",
       " 'apple_pie/2929330',\n",
       " 'apple_pie/2929448',\n",
       " 'apple_pie/2934928',\n",
       " 'apple_pie/293530',\n",
       " 'apple_pie/2940483',\n",
       " 'apple_pie/2955004',\n",
       " 'apple_pie/2956823',\n",
       " 'apple_pie/2961406',\n",
       " 'apple_pie/2961496',\n",
       " 'apple_pie/2967700',\n",
       " 'apple_pie/2968495',\n",
       " 'apple_pie/2969119',\n",
       " 'apple_pie/2975948',\n",
       " 'apple_pie/2977851',\n",
       " 'apple_pie/2986199',\n",
       " 'apple_pie/2989031',\n",
       " 'apple_pie/2989799',\n",
       " 'apple_pie/2994917',\n",
       " 'apple_pie/2995608',\n",
       " 'apple_pie/2997124',\n",
       " 'apple_pie/299931',\n",
       " 'apple_pie/3004621',\n",
       " 'apple_pie/3018695',\n",
       " 'apple_pie/3021995',\n",
       " 'apple_pie/3023096',\n",
       " 'apple_pie/3025907',\n",
       " 'apple_pie/3031488',\n",
       " 'apple_pie/3047214',\n",
       " 'apple_pie/3059110',\n",
       " 'apple_pie/3059134',\n",
       " 'apple_pie/3065929',\n",
       " 'apple_pie/3079946',\n",
       " 'apple_pie/3096075',\n",
       " 'apple_pie/3098981',\n",
       " 'apple_pie/3103489',\n",
       " 'apple_pie/3108401',\n",
       " 'apple_pie/3110084',\n",
       " 'apple_pie/3113710',\n",
       " 'apple_pie/3116086',\n",
       " 'apple_pie/3127422',\n",
       " 'apple_pie/3128330',\n",
       " 'apple_pie/3132437',\n",
       " 'apple_pie/3134347',\n",
       " 'apple_pie/3139762',\n",
       " 'apple_pie/3140647',\n",
       " 'apple_pie/3158095',\n",
       " 'apple_pie/3175105',\n",
       " 'apple_pie/3176186',\n",
       " 'apple_pie/3177727',\n",
       " 'apple_pie/3191226',\n",
       " 'apple_pie/3192077',\n",
       " 'apple_pie/3192774',\n",
       " 'apple_pie/3197173',\n",
       " 'apple_pie/3198655',\n",
       " 'apple_pie/3203950',\n",
       " 'apple_pie/3209538',\n",
       " 'apple_pie/3211704',\n",
       " 'apple_pie/321197',\n",
       " 'apple_pie/3214508',\n",
       " 'apple_pie/3217969',\n",
       " 'apple_pie/3226877',\n",
       " 'apple_pie/323108',\n",
       " 'apple_pie/3233920',\n",
       " 'apple_pie/3236737',\n",
       " 'apple_pie/3241750',\n",
       " 'apple_pie/3242445',\n",
       " 'apple_pie/3251989',\n",
       " 'apple_pie/3252424',\n",
       " 'apple_pie/3254296',\n",
       " 'apple_pie/3256198',\n",
       " 'apple_pie/3273568',\n",
       " 'apple_pie/3277458',\n",
       " 'apple_pie/3277765',\n",
       " 'apple_pie/3279836',\n",
       " 'apple_pie/3280622',\n",
       " 'apple_pie/3287607',\n",
       " 'apple_pie/3297976',\n",
       " 'apple_pie/330431',\n",
       " 'apple_pie/3307686',\n",
       " 'apple_pie/3313267',\n",
       " 'apple_pie/3318370',\n",
       " 'apple_pie/3324492',\n",
       " 'apple_pie/3333030',\n",
       " 'apple_pie/3335126',\n",
       " 'apple_pie/333800',\n",
       " 'apple_pie/3349423',\n",
       " 'apple_pie/3358059',\n",
       " 'apple_pie/3373840',\n",
       " 'apple_pie/3375088',\n",
       " 'apple_pie/3376635',\n",
       " 'apple_pie/3392444',\n",
       " 'apple_pie/339902',\n",
       " 'apple_pie/339921',\n",
       " 'apple_pie/3408912',\n",
       " 'apple_pie/3410227',\n",
       " 'apple_pie/3419799',\n",
       " 'apple_pie/3420738',\n",
       " 'apple_pie/3421349',\n",
       " 'apple_pie/3427584',\n",
       " 'apple_pie/3428446',\n",
       " 'apple_pie/3438714',\n",
       " 'apple_pie/3439550',\n",
       " 'apple_pie/3440893',\n",
       " 'apple_pie/3443899',\n",
       " 'apple_pie/3448753',\n",
       " 'apple_pie/3452805',\n",
       " 'apple_pie/3461245',\n",
       " 'apple_pie/3468573',\n",
       " 'apple_pie/3478976',\n",
       " 'apple_pie/3495444',\n",
       " 'apple_pie/3501006',\n",
       " 'apple_pie/3503020',\n",
       " 'apple_pie/3503459',\n",
       " 'apple_pie/3506848',\n",
       " 'apple_pie/3508043',\n",
       " 'apple_pie/3539782',\n",
       " 'apple_pie/3545924',\n",
       " 'apple_pie/3546563',\n",
       " 'apple_pie/3549466',\n",
       " 'apple_pie/3551588',\n",
       " 'apple_pie/3563222',\n",
       " 'apple_pie/3570483',\n",
       " 'apple_pie/3574591',\n",
       " 'apple_pie/3577845',\n",
       " 'apple_pie/3586158',\n",
       " 'apple_pie/3588721',\n",
       " 'apple_pie/3589097',\n",
       " 'apple_pie/3593810',\n",
       " 'apple_pie/359419',\n",
       " 'apple_pie/3594414',\n",
       " 'apple_pie/3596143',\n",
       " 'apple_pie/360406',\n",
       " 'apple_pie/3613613',\n",
       " 'apple_pie/3619289',\n",
       " 'apple_pie/3634716',\n",
       " 'apple_pie/3636185',\n",
       " 'apple_pie/3637115',\n",
       " 'apple_pie/3638370',\n",
       " 'apple_pie/3641922',\n",
       " 'apple_pie/3659123',\n",
       " 'apple_pie/3664341',\n",
       " 'apple_pie/3670548',\n",
       " 'apple_pie/3670966',\n",
       " 'apple_pie/3671998',\n",
       " 'apple_pie/3683557',\n",
       " 'apple_pie/3687109',\n",
       " 'apple_pie/3696282',\n",
       " 'apple_pie/3699587',\n",
       " 'apple_pie/3708396',\n",
       " 'apple_pie/3718506',\n",
       " 'apple_pie/3723561',\n",
       " 'apple_pie/3723836',\n",
       " 'apple_pie/3728481',\n",
       " 'apple_pie/3736084',\n",
       " 'apple_pie/3748095',\n",
       " 'apple_pie/3748402',\n",
       " 'apple_pie/375297',\n",
       " 'apple_pie/3760032',\n",
       " 'apple_pie/3760078',\n",
       " 'apple_pie/3770020',\n",
       " 'apple_pie/3772671',\n",
       " 'apple_pie/3783821',\n",
       " 'apple_pie/3799430',\n",
       " 'apple_pie/380024',\n",
       " 'apple_pie/3805050',\n",
       " 'apple_pie/3805347',\n",
       " 'apple_pie/3814557',\n",
       " 'apple_pie/3814952',\n",
       " 'apple_pie/3815797',\n",
       " 'apple_pie/3819511',\n",
       " 'apple_pie/3829790',\n",
       " 'apple_pie/3831510',\n",
       " 'apple_pie/3831869',\n",
       " 'apple_pie/3833386',\n",
       " 'apple_pie/3833639',\n",
       " 'apple_pie/3848012',\n",
       " 'apple_pie/3869215',\n",
       " 'apple_pie/3879031',\n",
       " 'apple_pie/3882465',\n",
       " 'apple_pie/3890705',\n",
       " 'apple_pie/3897758',\n",
       " 'apple_pie/3910026',\n",
       " 'apple_pie/3913827',\n",
       " 'apple_pie/3915887',\n",
       " 'apple_pie/3917257',\n",
       " 'apple_pie/392009',\n",
       " 'apple_pie/395303',\n",
       " 'apple_pie/395839',\n",
       " 'apple_pie/405315',\n",
       " 'apple_pie/407939',\n",
       " 'apple_pie/412306',\n",
       " 'apple_pie/412545',\n",
       " 'apple_pie/420643',\n",
       " 'apple_pie/420768',\n",
       " 'apple_pie/421036',\n",
       " 'apple_pie/424996',\n",
       " 'apple_pie/437455',\n",
       " 'apple_pie/456190',\n",
       " 'apple_pie/456934',\n",
       " 'apple_pie/471995',\n",
       " 'apple_pie/481805',\n",
       " 'apple_pie/483621',\n",
       " 'apple_pie/484038',\n",
       " 'apple_pie/488508',\n",
       " 'apple_pie/490047',\n",
       " 'apple_pie/498726',\n",
       " 'apple_pie/502016',\n",
       " 'apple_pie/505249',\n",
       " 'apple_pie/523810',\n",
       " 'apple_pie/524697',\n",
       " 'apple_pie/532191',\n",
       " 'apple_pie/532423',\n",
       " 'apple_pie/532972',\n",
       " 'apple_pie/535444',\n",
       " 'apple_pie/543253',\n",
       " 'apple_pie/544151',\n",
       " 'apple_pie/547961',\n",
       " 'apple_pie/551535',\n",
       " 'apple_pie/559953',\n",
       " 'apple_pie/562659',\n",
       " 'apple_pie/589712',\n",
       " 'apple_pie/591398',\n",
       " 'apple_pie/594677',\n",
       " 'apple_pie/597533',\n",
       " 'apple_pie/603113',\n",
       " 'apple_pie/604375',\n",
       " 'apple_pie/605117',\n",
       " 'apple_pie/624715',\n",
       " 'apple_pie/631412',\n",
       " 'apple_pie/631445',\n",
       " 'apple_pie/63651',\n",
       " 'apple_pie/644109',\n",
       " 'apple_pie/647043',\n",
       " 'apple_pie/64846',\n",
       " 'apple_pie/649621',\n",
       " 'apple_pie/650815',\n",
       " 'apple_pie/653135',\n",
       " 'apple_pie/656340',\n",
       " 'apple_pie/657618',\n",
       " 'apple_pie/668603',\n",
       " 'apple_pie/671980',\n",
       " 'apple_pie/672196',\n",
       " 'apple_pie/672263',\n",
       " 'apple_pie/67826',\n",
       " 'apple_pie/678482',\n",
       " 'apple_pie/68383',\n",
       " 'apple_pie/687503',\n",
       " 'apple_pie/687506',\n",
       " 'apple_pie/692211',\n",
       " 'apple_pie/695587',\n",
       " 'apple_pie/696914',\n",
       " 'apple_pie/698341',\n",
       " 'apple_pie/715180',\n",
       " 'apple_pie/722783',\n",
       " 'apple_pie/727412',\n",
       " 'apple_pie/739410',\n",
       " 'apple_pie/739615',\n",
       " 'apple_pie/742789',\n",
       " 'apple_pie/750073',\n",
       " 'apple_pie/755031',\n",
       " 'apple_pie/767102',\n",
       " 'apple_pie/767395',\n",
       " 'apple_pie/769522',\n",
       " 'apple_pie/770439',\n",
       " 'apple_pie/771595',\n",
       " 'apple_pie/78081',\n",
       " 'apple_pie/790787',\n",
       " 'apple_pie/793078',\n",
       " 'apple_pie/794735',\n",
       " 'apple_pie/80734',\n",
       " 'apple_pie/80735',\n",
       " 'apple_pie/813881',\n",
       " 'apple_pie/817073',\n",
       " 'apple_pie/817552',\n",
       " 'apple_pie/822817',\n",
       " 'apple_pie/825589',\n",
       " 'apple_pie/833369',\n",
       " 'apple_pie/839808',\n",
       " 'apple_pie/839845',\n",
       " 'apple_pie/842012',\n",
       " 'apple_pie/854595',\n",
       " 'apple_pie/85857',\n",
       " 'apple_pie/858876',\n",
       " 'apple_pie/860651',\n",
       " 'apple_pie/865073',\n",
       " 'apple_pie/871917',\n",
       " 'apple_pie/873371',\n",
       " 'apple_pie/874809',\n",
       " 'apple_pie/881628',\n",
       " 'apple_pie/886518',\n",
       " 'apple_pie/89035',\n",
       " 'apple_pie/892425',\n",
       " 'apple_pie/902277',\n",
       " 'apple_pie/909196',\n",
       " 'apple_pie/910097',\n",
       " 'apple_pie/910333',\n",
       " 'apple_pie/913161',\n",
       " 'apple_pie/925525',\n",
       " 'apple_pie/934113',\n",
       " 'apple_pie/934503',\n",
       " 'apple_pie/936189',\n",
       " 'apple_pie/937118',\n",
       " 'apple_pie/939246',\n",
       " 'apple_pie/939768',\n",
       " 'apple_pie/939827',\n",
       " 'apple_pie/946403',\n",
       " 'apple_pie/947689',\n",
       " 'apple_pie/954830',\n",
       " 'apple_pie/957090',\n",
       " 'apple_pie/959388',\n",
       " 'apple_pie/959678',\n",
       " 'apple_pie/960233',\n",
       " 'apple_pie/960669',\n",
       " 'apple_pie/962315',\n",
       " 'apple_pie/966595',\n",
       " 'apple_pie/973088',\n",
       " 'apple_pie/973428',\n",
       " 'apple_pie/98352',\n",
       " 'apple_pie/98449',\n",
       " 'apple_pie/987860',\n",
       " 'apple_pie/997124',\n",
       " 'baby_back_ribs/1005293',\n",
       " 'baby_back_ribs/1007102',\n",
       " 'baby_back_ribs/1007272',\n",
       " 'baby_back_ribs/1008749',\n",
       " 'baby_back_ribs/1009028',\n",
       " 'baby_back_ribs/1031072',\n",
       " 'baby_back_ribs/1031112',\n",
       " 'baby_back_ribs/1034506',\n",
       " 'baby_back_ribs/1062026',\n",
       " 'baby_back_ribs/1062097',\n",
       " 'baby_back_ribs/1070017',\n",
       " 'baby_back_ribs/1073370',\n",
       " 'baby_back_ribs/1078506',\n",
       " 'baby_back_ribs/1078518',\n",
       " 'baby_back_ribs/1079522',\n",
       " 'baby_back_ribs/1081312',\n",
       " 'baby_back_ribs/108211',\n",
       " 'baby_back_ribs/1083903',\n",
       " 'baby_back_ribs/1084769',\n",
       " 'baby_back_ribs/1085337',\n",
       " 'baby_back_ribs/109256',\n",
       " 'baby_back_ribs/1099273',\n",
       " 'baby_back_ribs/1106965',\n",
       " 'baby_back_ribs/112032',\n",
       " 'baby_back_ribs/1128175',\n",
       " 'baby_back_ribs/1128504',\n",
       " 'baby_back_ribs/1131511',\n",
       " 'baby_back_ribs/1131795',\n",
       " 'baby_back_ribs/1140712',\n",
       " 'baby_back_ribs/1148389',\n",
       " 'baby_back_ribs/1153312',\n",
       " 'baby_back_ribs/1153453',\n",
       " 'baby_back_ribs/1157308',\n",
       " 'baby_back_ribs/1169971',\n",
       " 'baby_back_ribs/1174148',\n",
       " 'baby_back_ribs/1181199',\n",
       " 'baby_back_ribs/1181776',\n",
       " 'baby_back_ribs/1185974',\n",
       " 'baby_back_ribs/1189974',\n",
       " 'baby_back_ribs/119255',\n",
       " 'baby_back_ribs/1192660',\n",
       " 'baby_back_ribs/119355',\n",
       " 'baby_back_ribs/1193861',\n",
       " 'baby_back_ribs/1199055',\n",
       " 'baby_back_ribs/1201223',\n",
       " 'baby_back_ribs/1202936',\n",
       " 'baby_back_ribs/1211748',\n",
       " 'baby_back_ribs/1224799',\n",
       " 'baby_back_ribs/1229921',\n",
       " 'baby_back_ribs/1239239',\n",
       " 'baby_back_ribs/1239248',\n",
       " 'baby_back_ribs/1240920',\n",
       " 'baby_back_ribs/1241704',\n",
       " 'baby_back_ribs/1252252',\n",
       " 'baby_back_ribs/1258771',\n",
       " 'baby_back_ribs/1259396',\n",
       " 'baby_back_ribs/1262560',\n",
       " 'baby_back_ribs/1267432',\n",
       " 'baby_back_ribs/1285755',\n",
       " 'baby_back_ribs/1288297',\n",
       " 'baby_back_ribs/1291979',\n",
       " 'baby_back_ribs/1298956',\n",
       " 'baby_back_ribs/1299678',\n",
       " 'baby_back_ribs/1299686',\n",
       " 'baby_back_ribs/1300306',\n",
       " 'baby_back_ribs/1315753',\n",
       " 'baby_back_ribs/1316579',\n",
       " 'baby_back_ribs/1320872',\n",
       " 'baby_back_ribs/1324788',\n",
       " 'baby_back_ribs/1325806',\n",
       " 'baby_back_ribs/1334446',\n",
       " 'baby_back_ribs/1341092',\n",
       " 'baby_back_ribs/1342514',\n",
       " 'baby_back_ribs/1343043',\n",
       " 'baby_back_ribs/1346675',\n",
       " 'baby_back_ribs/1346686',\n",
       " 'baby_back_ribs/1353805',\n",
       " 'baby_back_ribs/1362359',\n",
       " 'baby_back_ribs/1367931',\n",
       " 'baby_back_ribs/1371630',\n",
       " 'baby_back_ribs/1373674',\n",
       " 'baby_back_ribs/137626',\n",
       " 'baby_back_ribs/1377033',\n",
       " 'baby_back_ribs/1384024',\n",
       " 'baby_back_ribs/1386077',\n",
       " 'baby_back_ribs/1392004',\n",
       " 'baby_back_ribs/1395170',\n",
       " 'baby_back_ribs/1395570',\n",
       " 'baby_back_ribs/140335',\n",
       " 'baby_back_ribs/1416598',\n",
       " 'baby_back_ribs/1421473',\n",
       " 'baby_back_ribs/1429122',\n",
       " 'baby_back_ribs/1436844',\n",
       " 'baby_back_ribs/1438054',\n",
       " 'baby_back_ribs/1441141',\n",
       " 'baby_back_ribs/1446793',\n",
       " 'baby_back_ribs/1459848',\n",
       " 'baby_back_ribs/1464660',\n",
       " 'baby_back_ribs/1475641',\n",
       " 'baby_back_ribs/1478335',\n",
       " 'baby_back_ribs/1480327',\n",
       " 'baby_back_ribs/148270',\n",
       " 'baby_back_ribs/1483871',\n",
       " 'baby_back_ribs/1485747',\n",
       " 'baby_back_ribs/1494720',\n",
       " 'baby_back_ribs/1495433',\n",
       " 'baby_back_ribs/1499720',\n",
       " 'baby_back_ribs/1503924',\n",
       " 'baby_back_ribs/1505833',\n",
       " 'baby_back_ribs/1520322',\n",
       " 'baby_back_ribs/1520658',\n",
       " 'baby_back_ribs/1525686',\n",
       " 'baby_back_ribs/1533018',\n",
       " 'baby_back_ribs/1537031',\n",
       " 'baby_back_ribs/1537034',\n",
       " 'baby_back_ribs/1537116',\n",
       " 'baby_back_ribs/153883',\n",
       " 'baby_back_ribs/1550594',\n",
       " 'baby_back_ribs/1552922',\n",
       " 'baby_back_ribs/155690',\n",
       " 'baby_back_ribs/1558128',\n",
       " 'baby_back_ribs/1558275',\n",
       " 'baby_back_ribs/1559619',\n",
       " 'baby_back_ribs/1563530',\n",
       " 'baby_back_ribs/156707',\n",
       " 'baby_back_ribs/1567658',\n",
       " 'baby_back_ribs/1571645',\n",
       " 'baby_back_ribs/1571940',\n",
       " 'baby_back_ribs/1576431',\n",
       " 'baby_back_ribs/1576772',\n",
       " 'baby_back_ribs/1577255',\n",
       " 'baby_back_ribs/1582932',\n",
       " 'baby_back_ribs/1587924',\n",
       " 'baby_back_ribs/1588562',\n",
       " 'baby_back_ribs/1593944',\n",
       " 'baby_back_ribs/1596759',\n",
       " 'baby_back_ribs/1597189',\n",
       " 'baby_back_ribs/1608850',\n",
       " 'baby_back_ribs/1610050',\n",
       " 'baby_back_ribs/1615155',\n",
       " 'baby_back_ribs/1619479',\n",
       " 'baby_back_ribs/1620823',\n",
       " 'baby_back_ribs/1621773',\n",
       " 'baby_back_ribs/1622288',\n",
       " 'baby_back_ribs/1622962',\n",
       " 'baby_back_ribs/1623979',\n",
       " 'baby_back_ribs/1632377',\n",
       " 'baby_back_ribs/1635329',\n",
       " 'baby_back_ribs/16366',\n",
       " 'baby_back_ribs/1640728',\n",
       " 'baby_back_ribs/1643275',\n",
       " 'baby_back_ribs/1644147',\n",
       " 'baby_back_ribs/1651771',\n",
       " 'baby_back_ribs/1656357',\n",
       " 'baby_back_ribs/1675917',\n",
       " 'baby_back_ribs/1676135',\n",
       " 'baby_back_ribs/1676905',\n",
       " 'baby_back_ribs/1676906',\n",
       " 'baby_back_ribs/1677624',\n",
       " 'baby_back_ribs/1679824',\n",
       " 'baby_back_ribs/167990',\n",
       " 'baby_back_ribs/1681286',\n",
       " 'baby_back_ribs/1684592',\n",
       " 'baby_back_ribs/1686741',\n",
       " 'baby_back_ribs/1688043',\n",
       " 'baby_back_ribs/1688240',\n",
       " 'baby_back_ribs/1695610',\n",
       " 'baby_back_ribs/1699771',\n",
       " 'baby_back_ribs/1709704',\n",
       " 'baby_back_ribs/1711775',\n",
       " 'baby_back_ribs/1716566',\n",
       " 'baby_back_ribs/1718129',\n",
       " 'baby_back_ribs/1726178',\n",
       " 'baby_back_ribs/1729685',\n",
       " 'baby_back_ribs/1730203',\n",
       " 'baby_back_ribs/1737370',\n",
       " 'baby_back_ribs/1740768',\n",
       " 'baby_back_ribs/1745601',\n",
       " 'baby_back_ribs/1749425',\n",
       " 'baby_back_ribs/1752664',\n",
       " 'baby_back_ribs/1757611',\n",
       " 'baby_back_ribs/1766448',\n",
       " 'baby_back_ribs/1770157',\n",
       " 'baby_back_ribs/1772427',\n",
       " 'baby_back_ribs/1774172',\n",
       " 'baby_back_ribs/1775388',\n",
       " 'baby_back_ribs/1794902',\n",
       " 'baby_back_ribs/1804408',\n",
       " 'baby_back_ribs/1804706',\n",
       " 'baby_back_ribs/1804724',\n",
       " 'baby_back_ribs/1806940',\n",
       " 'baby_back_ribs/1807563',\n",
       " 'baby_back_ribs/1814986',\n",
       " 'baby_back_ribs/1819387',\n",
       " 'baby_back_ribs/1821315',\n",
       " 'baby_back_ribs/1829271',\n",
       " 'baby_back_ribs/1832939',\n",
       " 'baby_back_ribs/1838405',\n",
       " 'baby_back_ribs/1839467',\n",
       " 'baby_back_ribs/1840540',\n",
       " 'baby_back_ribs/1841024',\n",
       " 'baby_back_ribs/1845573',\n",
       " 'baby_back_ribs/184567',\n",
       " 'baby_back_ribs/1848417',\n",
       " 'baby_back_ribs/1858401',\n",
       " 'baby_back_ribs/1862790',\n",
       " 'baby_back_ribs/1875652',\n",
       " 'baby_back_ribs/1876802',\n",
       " 'baby_back_ribs/1878380',\n",
       " 'baby_back_ribs/1879515',\n",
       " 'baby_back_ribs/1880868',\n",
       " 'baby_back_ribs/1887058',\n",
       " 'baby_back_ribs/188943',\n",
       " 'baby_back_ribs/189367',\n",
       " 'baby_back_ribs/1895338',\n",
       " 'baby_back_ribs/189917',\n",
       " 'baby_back_ribs/1902615',\n",
       " 'baby_back_ribs/1907959',\n",
       " 'baby_back_ribs/1910700',\n",
       " 'baby_back_ribs/1917025',\n",
       " 'baby_back_ribs/1921931',\n",
       " 'baby_back_ribs/1928477',\n",
       " 'baby_back_ribs/1929872',\n",
       " 'baby_back_ribs/1931741',\n",
       " 'baby_back_ribs/1934757',\n",
       " 'baby_back_ribs/1934927',\n",
       " 'baby_back_ribs/1936442',\n",
       " 'baby_back_ribs/1941026',\n",
       " 'baby_back_ribs/1941557',\n",
       " 'baby_back_ribs/1943575',\n",
       " 'baby_back_ribs/1951972',\n",
       " 'baby_back_ribs/1957350',\n",
       " 'baby_back_ribs/1959961',\n",
       " 'baby_back_ribs/1966568',\n",
       " 'baby_back_ribs/1970515',\n",
       " 'baby_back_ribs/1971262',\n",
       " 'baby_back_ribs/1972389',\n",
       " 'baby_back_ribs/1975684',\n",
       " 'baby_back_ribs/1976124',\n",
       " 'baby_back_ribs/1976409',\n",
       " 'baby_back_ribs/1978213',\n",
       " 'baby_back_ribs/1986342',\n",
       " 'baby_back_ribs/1987216',\n",
       " 'baby_back_ribs/1998638',\n",
       " 'baby_back_ribs/2009356',\n",
       " 'baby_back_ribs/2010205',\n",
       " 'baby_back_ribs/2013073',\n",
       " 'baby_back_ribs/2018808',\n",
       " 'baby_back_ribs/2022932',\n",
       " 'baby_back_ribs/2023500',\n",
       " ...]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89297aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2list(path):\n",
    "    file1 = open(path,'r')\n",
    "    lines = file1.readlines()\n",
    "    final_list = [line.strip() for line in lines]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "classes = file2list(class_path)\n",
    "train_data = file2list(train_img_name_path)\n",
    "test_data = file2list(test_img_name_path)\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a97e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodData(Dataset):\n",
    "    def __init__(self,img_path,img_dir,size,transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.size = size\n",
    "#         self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        label,img_name = self.img_path[index].split('/')\n",
    "        path = self.img_dir+'/images/'+label+'/'+img_name+'.jpg'\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img,(self.size,self.size))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return {\n",
    "                'gt': img,\n",
    "                'label': torch.tensor(le.transform([label])[0])\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2454bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "369d6eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_transform = {\\n    \\'train\\' : transforms.Compose([\\n        transforms.RandomResizedCrop(224),\\n        transforms.RandomHorizontalFlip(),\\n        transforms.ToTensor(),\\n        transforms.Normalize([0.5, 0.5, 0.5,], [0.5, 0.5, 0.5])\\n    ]),\\n    \\'val\\' : transforms.Compose([\\n        transforms.RandomResizedCrop(224),\\n        transforms.RandomHorizontalFlip(),\\n        transforms.ToTensor(),\\n        transforms.Normalize([0.5, 0.5, 0.5,], [0.5, 0.5, 0.5])\\n    ]),\\n}\\nimage_datasets = {x : datasets.ImageFolder(\"..//\")}\\ndataloaders = {x : torch.utils.data.DataLoader(image_datasets[x], \\n                                               batch_size = BATCH_SIZE,\\n                                               num_workers = 0,\\n                                               shuffle = True) for x in [\"train\", \"val\"]}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 참고용 코드\n",
    "'''data_transform = {\n",
    "    'train' : transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5,], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'val' : transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5,], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "}\n",
    "image_datasets = {x : datasets.ImageFolder(\"..//\")}\n",
    "dataloaders = {x : torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               num_workers = 0,\n",
    "                                               shuffle = True) for x in [\"train\", \"val\"]}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae53cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(90),\n",
    "#     transforms.CenterCrop(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "#     ImageNetPolicy(),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( mean = np.array([0.485, 0.456, 0.406]),\n",
    "    std = np.array([0.229, 0.224, 0.225]))\n",
    "])\n",
    "train_transforms = transforms.Compose([transforms.ToPILImage(),\n",
    "                                        transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "train_dataset = FoodData(train_data,input_root_dir,256,transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "775b3216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Img_020_0774.jpg',\n",
       " 'Img_020_0012.jpg',\n",
       " 'Img_020_0006.jpg',\n",
       " 'Img_020_0760.jpg',\n",
       " 'Img_020_0748.jpg',\n",
       " 'Img_020_0990.jpg',\n",
       " 'Img_020_0984.jpg',\n",
       " 'Img_020_0953.jpg',\n",
       " 'Img_020_0947.jpg',\n",
       " 'Img_020_0210.jpg',\n",
       " 'Img_020_0576.jpg',\n",
       " 'Img_020_0562.jpg',\n",
       " 'Img_020_0204.jpg',\n",
       " 'Img_020_0238.jpg',\n",
       " 'Img_020_0589.jpg',\n",
       " 'Img_020_0364.jpg',\n",
       " 'Img_020_0402.jpg',\n",
       " 'Img_020_0416.jpg',\n",
       " 'Img_020_0370.jpg',\n",
       " 'Img_020_0358.jpg',\n",
       " 'Img_020_0600.jpg',\n",
       " 'Img_020_0166.jpg',\n",
       " 'Img_020_0172.jpg',\n",
       " 'Img_020_0614.jpg',\n",
       " 'Img_020_0628.jpg',\n",
       " 'Img_020_0827.jpg',\n",
       " 'Img_020_0199.jpg',\n",
       " 'Img_020_0833.jpg',\n",
       " 'Img_020_0832.jpg',\n",
       " 'Img_020_0826.jpg',\n",
       " 'Img_020_0198.jpg',\n",
       " 'Img_020_0629.jpg',\n",
       " 'Img_020_0173.jpg',\n",
       " 'Img_020_0615.jpg',\n",
       " 'Img_020_0601.jpg',\n",
       " 'Img_020_0167.jpg',\n",
       " 'Img_020_0359.jpg',\n",
       " 'Img_020_0417.jpg',\n",
       " 'Img_020_0371.jpg',\n",
       " 'Img_020_0365.jpg',\n",
       " 'Img_020_0403.jpg',\n",
       " 'Img_020_0588.jpg',\n",
       " 'Img_020_0239.jpg',\n",
       " 'Img_020_0563.jpg',\n",
       " 'Img_020_0205.jpg',\n",
       " 'Img_020_0211.jpg',\n",
       " 'Img_020_0577.jpg',\n",
       " 'Img_020_0946.jpg',\n",
       " 'Img_020_0952.jpg',\n",
       " 'Img_020_0985.jpg',\n",
       " 'Img_020_0991.jpg',\n",
       " 'Img_020_0749.jpg',\n",
       " 'Img_020_0007.jpg',\n",
       " 'Img_020_0761.jpg',\n",
       " 'Img_020_0775.jpg',\n",
       " 'Img_020_0013.jpg',\n",
       " 'Img_020_0763.jpg',\n",
       " 'Img_020_0005.jpg',\n",
       " 'Img_020_0011.jpg',\n",
       " 'Img_020_0777.jpg',\n",
       " 'Img_020_0987.jpg',\n",
       " 'Img_020_0039.jpg',\n",
       " 'Img_020_0993.jpg',\n",
       " 'Img_020_0978.jpg',\n",
       " 'Img_020_0944.jpg',\n",
       " 'Img_020_0950.jpg',\n",
       " 'Img_020_0788.jpg',\n",
       " 'Img_020_0207.jpg',\n",
       " 'Img_020_0561.jpg',\n",
       " 'Img_020_0575.jpg',\n",
       " 'Img_020_0213.jpg',\n",
       " 'Img_020_0549.jpg',\n",
       " 'Img_020_0373.jpg',\n",
       " 'Img_020_0415.jpg',\n",
       " 'Img_020_0401.jpg',\n",
       " 'Img_020_0367.jpg',\n",
       " 'Img_020_0429.jpg',\n",
       " 'Img_020_0398.jpg',\n",
       " 'Img_020_0617.jpg',\n",
       " 'Img_020_0171.jpg',\n",
       " 'Img_020_0165.jpg',\n",
       " 'Img_020_0603.jpg',\n",
       " 'Img_020_0159.jpg',\n",
       " 'Img_020_0818.jpg',\n",
       " 'Img_020_0830.jpg',\n",
       " 'Img_020_0824.jpg',\n",
       " 'Img_020_0825.jpg',\n",
       " 'Img_020_0831.jpg',\n",
       " 'Img_020_0819.jpg',\n",
       " 'Img_020_0158.jpg',\n",
       " 'Img_020_0164.jpg',\n",
       " 'Img_020_0602.jpg',\n",
       " 'Img_020_0616.jpg',\n",
       " 'Img_020_0170.jpg',\n",
       " 'Img_020_0399.jpg',\n",
       " 'Img_020_0428.jpg',\n",
       " 'Img_020_0400.jpg',\n",
       " 'Img_020_0366.jpg',\n",
       " 'Img_020_0372.jpg',\n",
       " 'Img_020_0414.jpg',\n",
       " 'Img_020_0548.jpg',\n",
       " 'Img_020_0574.jpg',\n",
       " 'Img_020_0212.jpg',\n",
       " 'Img_020_0206.jpg',\n",
       " 'Img_020_0560.jpg',\n",
       " 'Img_020_0789.jpg',\n",
       " 'Img_020_0951.jpg',\n",
       " 'Img_020_0945.jpg',\n",
       " 'Img_020_0979.jpg',\n",
       " 'Img_020_0992.jpg',\n",
       " 'Img_020_0986.jpg',\n",
       " 'Img_020_0038.jpg',\n",
       " 'Img_020_0010.jpg',\n",
       " 'Img_020_0776.jpg',\n",
       " 'Img_020_0762.jpg',\n",
       " 'Img_020_0004.jpg',\n",
       " 'Img_020_0982.jpg',\n",
       " 'Img_020_0996.jpg',\n",
       " 'Img_020_0028.jpg',\n",
       " 'Img_020_0000.jpg',\n",
       " 'Img_020_0766.jpg',\n",
       " 'Img_020_0772.jpg',\n",
       " 'Img_020_0014.jpg',\n",
       " 'Img_020_0941.jpg',\n",
       " 'Img_020_0799.jpg',\n",
       " 'Img_020_0955.jpg',\n",
       " 'Img_020_0969.jpg',\n",
       " 'Img_020_0558.jpg',\n",
       " 'Img_020_0564.jpg',\n",
       " 'Img_020_0202.jpg',\n",
       " 'Img_020_0216.jpg',\n",
       " 'Img_020_0570.jpg',\n",
       " 'Img_020_0438.jpg',\n",
       " 'Img_020_0410.jpg',\n",
       " 'Img_020_0376.jpg',\n",
       " 'Img_020_0362.jpg',\n",
       " 'Img_020_0404.jpg',\n",
       " 'Img_020_0389.jpg',\n",
       " 'Img_020_0148.jpg',\n",
       " 'Img_020_0174.jpg',\n",
       " 'Img_020_0612.jpg',\n",
       " 'Img_020_0606.jpg',\n",
       " 'Img_020_0160.jpg',\n",
       " 'Img_020_0835.jpg',\n",
       " 'Img_020_0821.jpg',\n",
       " 'Img_020_0809.jpg',\n",
       " 'Img_020_0808.jpg',\n",
       " 'Img_020_0820.jpg',\n",
       " 'Img_020_0834.jpg',\n",
       " 'Img_020_0607.jpg',\n",
       " 'Img_020_0161.jpg',\n",
       " 'Img_020_0175.jpg',\n",
       " 'Img_020_0613.jpg',\n",
       " 'Img_020_0149.jpg',\n",
       " 'Img_020_0388.jpg',\n",
       " 'Img_020_0363.jpg',\n",
       " 'Img_020_0405.jpg',\n",
       " 'Img_020_0411.jpg',\n",
       " 'Img_020_0377.jpg',\n",
       " 'Img_020_0439.jpg',\n",
       " 'Img_020_0217.jpg',\n",
       " 'Img_020_0571.jpg',\n",
       " 'Img_020_0565.jpg',\n",
       " 'Img_020_0203.jpg',\n",
       " 'Img_020_0559.jpg',\n",
       " 'Img_020_0968.jpg',\n",
       " 'Img_020_0954.jpg',\n",
       " 'Img_020_0798.jpg',\n",
       " 'Img_020_0940.jpg',\n",
       " 'Img_020_0773.jpg',\n",
       " 'Img_020_0015.jpg',\n",
       " 'Img_020_0001.jpg',\n",
       " 'Img_020_0767.jpg',\n",
       " 'Img_020_0997.jpg',\n",
       " 'Img_020_0029.jpg',\n",
       " 'Img_020_0983.jpg',\n",
       " 'Img_020_0995.jpg',\n",
       " 'Img_020_0759.jpg',\n",
       " 'Img_020_0981.jpg',\n",
       " 'Img_020_0017.jpg',\n",
       " 'Img_020_0771.jpg',\n",
       " 'Img_020_0765.jpg',\n",
       " 'Img_020_0003.jpg',\n",
       " 'Img_020_0956.jpg',\n",
       " 'Img_020_0942.jpg',\n",
       " 'Img_020_0229.jpg',\n",
       " 'Img_020_0573.jpg',\n",
       " 'Img_020_0215.jpg',\n",
       " 'Img_020_0201.jpg',\n",
       " 'Img_020_0567.jpg',\n",
       " 'Img_020_0598.jpg',\n",
       " 'Img_020_0349.jpg',\n",
       " 'Img_020_0407.jpg',\n",
       " 'Img_020_0361.jpg',\n",
       " 'Img_020_0375.jpg',\n",
       " 'Img_020_0413.jpg',\n",
       " 'Img_020_0639.jpg',\n",
       " 'Img_020_0163.jpg',\n",
       " 'Img_020_0605.jpg',\n",
       " 'Img_020_0611.jpg',\n",
       " 'Img_020_0177.jpg',\n",
       " 'Img_020_0822.jpg',\n",
       " 'Img_020_0836.jpg',\n",
       " 'Img_020_0188.jpg',\n",
       " 'Img_020_0837.jpg',\n",
       " 'Img_020_0189.jpg',\n",
       " 'Img_020_0823.jpg',\n",
       " 'Img_020_0610.jpg',\n",
       " 'Img_020_0176.jpg',\n",
       " 'Img_020_0162.jpg',\n",
       " 'Img_020_0604.jpg',\n",
       " 'Img_020_0638.jpg',\n",
       " 'Img_020_0374.jpg',\n",
       " 'Img_020_0412.jpg',\n",
       " 'Img_020_0406.jpg',\n",
       " 'Img_020_0360.jpg',\n",
       " 'Img_020_0348.jpg',\n",
       " 'Img_020_0599.jpg',\n",
       " 'Img_020_0200.jpg',\n",
       " 'Img_020_0566.jpg',\n",
       " 'Img_020_0572.jpg',\n",
       " 'Img_020_0214.jpg',\n",
       " 'Img_020_0228.jpg',\n",
       " 'Img_020_0943.jpg',\n",
       " 'Img_020_0957.jpg',\n",
       " 'Img_020_0764.jpg',\n",
       " 'Img_020_0002.jpg',\n",
       " 'Img_020_0016.jpg',\n",
       " 'Img_020_0770.jpg',\n",
       " 'Img_020_0980.jpg',\n",
       " 'Img_020_0758.jpg',\n",
       " 'Img_020_0994.jpg',\n",
       " 'Img_020_0071.jpg',\n",
       " 'Img_020_0717.jpg',\n",
       " 'Img_020_0703.jpg',\n",
       " 'Img_020_0065.jpg',\n",
       " 'Img_020_0059.jpg',\n",
       " 'Img_020_0918.jpg',\n",
       " 'Img_020_0930.jpg',\n",
       " 'Img_020_0924.jpg',\n",
       " 'Img_020_0515.jpg',\n",
       " 'Img_020_0273.jpg',\n",
       " 'Img_020_0267.jpg',\n",
       " 'Img_020_0501.jpg',\n",
       " 'Img_020_0529.jpg',\n",
       " 'Img_020_0298.jpg',\n",
       " 'Img_020_0461.jpg',\n",
       " 'Img_020_0307.jpg',\n",
       " 'Img_020_0313.jpg',\n",
       " 'Img_020_0475.jpg',\n",
       " 'Img_020_0449.jpg',\n",
       " 'Img_020_0105.jpg',\n",
       " 'Img_020_0663.jpg',\n",
       " 'Img_020_0677.jpg',\n",
       " 'Img_020_0111.jpg',\n",
       " 'Img_020_0139.jpg',\n",
       " 'Img_020_0887.jpg',\n",
       " 'Img_020_0893.jpg',\n",
       " 'Img_020_0878.jpg',\n",
       " 'Img_020_0844.jpg',\n",
       " 'Img_020_0688.jpg',\n",
       " 'Img_020_0850.jpg',\n",
       " 'Img_020_0851.jpg',\n",
       " 'Img_020_0689.jpg',\n",
       " 'Img_020_0845.jpg',\n",
       " 'Img_020_0879.jpg',\n",
       " 'Img_020_0892.jpg',\n",
       " 'Img_020_0138.jpg',\n",
       " 'Img_020_0886.jpg',\n",
       " 'Img_020_0676.jpg',\n",
       " 'Img_020_0110.jpg',\n",
       " 'Img_020_0104.jpg',\n",
       " 'Img_020_0662.jpg',\n",
       " 'Img_020_0448.jpg',\n",
       " 'Img_020_0312.jpg',\n",
       " 'Img_020_0474.jpg',\n",
       " 'Img_020_0460.jpg',\n",
       " 'Img_020_0306.jpg',\n",
       " 'Img_020_0299.jpg',\n",
       " 'Img_020_0528.jpg',\n",
       " 'Img_020_0266.jpg',\n",
       " 'Img_020_0500.jpg',\n",
       " 'Img_020_0514.jpg',\n",
       " 'Img_020_0272.jpg',\n",
       " 'Img_020_0925.jpg',\n",
       " 'Img_020_0931.jpg',\n",
       " 'Img_020_0919.jpg',\n",
       " 'Img_020_0058.jpg',\n",
       " 'Img_020_0702.jpg',\n",
       " 'Img_020_0064.jpg',\n",
       " 'Img_020_0070.jpg',\n",
       " 'Img_020_0716.jpg',\n",
       " 'Img_020_0066.jpg',\n",
       " 'Img_020_0700.jpg',\n",
       " 'Img_020_0714.jpg',\n",
       " 'Img_020_0072.jpg',\n",
       " 'Img_020_0728.jpg',\n",
       " 'Img_020_0099.jpg',\n",
       " 'Img_020_0927.jpg',\n",
       " 'Img_020_0933.jpg',\n",
       " 'Img_020_0502.jpg',\n",
       " 'Img_020_0264.jpg',\n",
       " 'Img_020_0270.jpg',\n",
       " 'Img_020_0516.jpg',\n",
       " 'Img_020_0258.jpg',\n",
       " 'Img_020_0476.jpg',\n",
       " 'Img_020_0310.jpg',\n",
       " 'Img_020_0304.jpg',\n",
       " 'Img_020_0462.jpg',\n",
       " 'Img_020_0338.jpg',\n",
       " 'Img_020_0489.jpg',\n",
       " 'Img_020_0112.jpg',\n",
       " 'Img_020_0674.jpg',\n",
       " 'Img_020_0660.jpg',\n",
       " 'Img_020_0106.jpg',\n",
       " 'Img_020_0890.jpg',\n",
       " 'Img_020_0648.jpg',\n",
       " 'Img_020_0884.jpg',\n",
       " 'Img_020_0853.jpg',\n",
       " 'Img_020_0847.jpg',\n",
       " 'Img_020_0846.jpg',\n",
       " 'Img_020_0852.jpg',\n",
       " 'Img_020_0885.jpg',\n",
       " 'Img_020_0649.jpg',\n",
       " 'Img_020_0891.jpg',\n",
       " 'Img_020_0661.jpg',\n",
       " 'Img_020_0107.jpg',\n",
       " 'Img_020_0113.jpg',\n",
       " 'Img_020_0675.jpg',\n",
       " 'Img_020_0488.jpg',\n",
       " 'Img_020_0339.jpg',\n",
       " 'Img_020_0305.jpg',\n",
       " 'Img_020_0463.jpg',\n",
       " 'Img_020_0477.jpg',\n",
       " 'Img_020_0311.jpg',\n",
       " 'Img_020_0259.jpg',\n",
       " 'Img_020_0271.jpg',\n",
       " 'Img_020_0517.jpg',\n",
       " 'Img_020_0503.jpg',\n",
       " 'Img_020_0265.jpg',\n",
       " 'Img_020_0932.jpg',\n",
       " 'Img_020_0098.jpg',\n",
       " 'Img_020_0926.jpg',\n",
       " 'Img_020_0729.jpg',\n",
       " 'Img_020_0715.jpg',\n",
       " 'Img_020_0073.jpg',\n",
       " 'Img_020_0067.jpg',\n",
       " 'Img_020_0701.jpg',\n",
       " 'Img_020_0739.jpg',\n",
       " 'Img_020_0705.jpg',\n",
       " 'Img_020_0063.jpg',\n",
       " 'Img_020_0077.jpg',\n",
       " 'Img_020_0711.jpg',\n",
       " 'Img_020_0922.jpg',\n",
       " 'Img_020_0088.jpg',\n",
       " 'Img_020_0936.jpg',\n",
       " 'Img_020_0249.jpg',\n",
       " 'Img_020_0261.jpg',\n",
       " 'Img_020_0507.jpg',\n",
       " 'Img_020_0513.jpg',\n",
       " 'Img_020_0275.jpg',\n",
       " 'Img_020_0329.jpg',\n",
       " 'Img_020_0315.jpg',\n",
       " 'Img_020_0473.jpg',\n",
       " 'Img_020_0467.jpg',\n",
       " 'Img_020_0301.jpg',\n",
       " 'Img_020_0498.jpg',\n",
       " 'Img_020_0895.jpg',\n",
       " 'Img_020_0881.jpg',\n",
       " 'Img_020_0659.jpg',\n",
       " 'Img_020_0671.jpg',\n",
       " 'Img_020_0117.jpg',\n",
       " 'Img_020_0103.jpg',\n",
       " 'Img_020_0665.jpg',\n",
       " 'Img_020_0856.jpg',\n",
       " 'Img_020_0842.jpg',\n",
       " 'Img_020_0843.jpg',\n",
       " 'Img_020_0857.jpg',\n",
       " 'Img_020_0102.jpg',\n",
       " 'Img_020_0664.jpg',\n",
       " 'Img_020_0670.jpg',\n",
       " 'Img_020_0116.jpg',\n",
       " 'Img_020_0658.jpg',\n",
       " 'Img_020_0880.jpg',\n",
       " 'Img_020_0894.jpg',\n",
       " 'Img_020_0499.jpg',\n",
       " 'Img_020_0466.jpg',\n",
       " 'Img_020_0300.jpg',\n",
       " 'Img_020_0314.jpg',\n",
       " 'Img_020_0472.jpg',\n",
       " 'Img_020_0328.jpg',\n",
       " 'Img_020_0512.jpg',\n",
       " 'Img_020_0274.jpg',\n",
       " 'Img_020_0260.jpg',\n",
       " 'Img_020_0506.jpg',\n",
       " 'Img_020_0248.jpg',\n",
       " 'Img_020_0089.jpg',\n",
       " 'Img_020_0937.jpg',\n",
       " 'Img_020_0923.jpg',\n",
       " 'Img_020_0076.jpg',\n",
       " 'Img_020_0710.jpg',\n",
       " 'Img_020_0704.jpg',\n",
       " 'Img_020_0062.jpg',\n",
       " 'Img_020_0738.jpg',\n",
       " 'Img_020_0048.jpg',\n",
       " 'Img_020_0712.jpg',\n",
       " 'Img_020_0074.jpg',\n",
       " 'Img_020_0060.jpg',\n",
       " 'Img_020_0706.jpg',\n",
       " 'Img_020_0935.jpg',\n",
       " 'Img_020_0921.jpg',\n",
       " 'Img_020_0909.jpg',\n",
       " 'Img_020_0538.jpg',\n",
       " 'Img_020_0276.jpg',\n",
       " 'Img_020_0510.jpg',\n",
       " 'Img_020_0504.jpg',\n",
       " 'Img_020_0262.jpg',\n",
       " 'Img_020_0289.jpg',\n",
       " 'Img_020_0458.jpg',\n",
       " 'Img_020_0302.jpg',\n",
       " 'Img_020_0464.jpg',\n",
       " 'Img_020_0470.jpg',\n",
       " 'Img_020_0316.jpg',\n",
       " 'Img_020_0882.jpg',\n",
       " 'Img_020_0128.jpg',\n",
       " 'Img_020_0896.jpg',\n",
       " 'Img_020_0666.jpg',\n",
       " 'Img_020_0100.jpg',\n",
       " 'Img_020_0114.jpg',\n",
       " 'Img_020_0672.jpg',\n",
       " 'Img_020_0699.jpg',\n",
       " 'Img_020_0841.jpg',\n",
       " 'Img_020_0855.jpg',\n",
       " 'Img_020_0869.jpg',\n",
       " 'Img_020_0868.jpg',\n",
       " 'Img_020_0854.jpg',\n",
       " 'Img_020_0840.jpg',\n",
       " 'Img_020_0698.jpg',\n",
       " 'Img_020_0115.jpg',\n",
       " 'Img_020_0673.jpg',\n",
       " 'Img_020_0667.jpg',\n",
       " 'Img_020_0101.jpg',\n",
       " 'Img_020_0129.jpg',\n",
       " 'Img_020_0897.jpg',\n",
       " 'Img_020_0883.jpg',\n",
       " 'Img_020_0471.jpg',\n",
       " 'Img_020_0317.jpg',\n",
       " 'Img_020_0303.jpg',\n",
       " 'Img_020_0465.jpg',\n",
       " 'Img_020_0459.jpg',\n",
       " 'Img_020_0288.jpg',\n",
       " 'Img_020_0505.jpg',\n",
       " 'Img_020_0263.jpg',\n",
       " 'Img_020_0277.jpg',\n",
       " 'Img_020_0511.jpg',\n",
       " 'Img_020_0539.jpg',\n",
       " 'Img_020_0908.jpg',\n",
       " 'Img_020_0920.jpg',\n",
       " 'Img_020_0934.jpg',\n",
       " 'Img_020_0061.jpg',\n",
       " 'Img_020_0707.jpg',\n",
       " 'Img_020_0713.jpg',\n",
       " 'Img_020_0075.jpg',\n",
       " 'Img_020_0049.jpg',\n",
       " 'Img_020_0050.jpg',\n",
       " 'Img_020_0736.jpg',\n",
       " 'Img_020_0722.jpg',\n",
       " 'Img_020_0044.jpg',\n",
       " 'Img_020_0078.jpg',\n",
       " 'Img_020_0093.jpg',\n",
       " 'Img_020_0939.jpg',\n",
       " 'Img_020_0087.jpg',\n",
       " 'Img_020_0911.jpg',\n",
       " 'Img_020_0905.jpg',\n",
       " 'Img_020_0534.jpg',\n",
       " 'Img_020_0252.jpg',\n",
       " 'Img_020_0246.jpg',\n",
       " 'Img_020_0520.jpg',\n",
       " 'Img_020_0508.jpg',\n",
       " 'Img_020_0291.jpg',\n",
       " 'Img_020_0285.jpg',\n",
       " 'Img_020_0440.jpg',\n",
       " 'Img_020_0326.jpg',\n",
       " 'Img_020_0332.jpg',\n",
       " 'Img_020_0454.jpg',\n",
       " 'Img_020_0468.jpg',\n",
       " 'Img_020_0483.jpg',\n",
       " 'Img_020_0497.jpg',\n",
       " 'Img_020_0124.jpg',\n",
       " 'Img_020_0642.jpg',\n",
       " 'Img_020_0656.jpg',\n",
       " 'Img_020_0130.jpg',\n",
       " 'Img_020_0118.jpg',\n",
       " 'Img_020_0681.jpg',\n",
       " 'Img_020_0859.jpg',\n",
       " 'Img_020_0695.jpg',\n",
       " 'Img_020_0865.jpg',\n",
       " 'Img_020_0871.jpg',\n",
       " 'Img_020_0870.jpg',\n",
       " 'Img_020_0864.jpg',\n",
       " 'Img_020_0694.jpg',\n",
       " 'Img_020_0858.jpg',\n",
       " 'Img_020_0680.jpg',\n",
       " 'Img_020_0119.jpg',\n",
       " 'Img_020_0657.jpg',\n",
       " 'Img_020_0131.jpg',\n",
       " 'Img_020_0125.jpg',\n",
       " 'Img_020_0643.jpg',\n",
       " 'Img_020_0496.jpg',\n",
       " 'Img_020_0482.jpg',\n",
       " 'Img_020_0469.jpg',\n",
       " 'Img_020_0333.jpg',\n",
       " 'Img_020_0455.jpg',\n",
       " 'Img_020_0441.jpg',\n",
       " 'Img_020_0327.jpg',\n",
       " 'Img_020_0284.jpg',\n",
       " 'Img_020_0290.jpg',\n",
       " 'Img_020_0509.jpg',\n",
       " 'Img_020_0247.jpg',\n",
       " 'Img_020_0521.jpg',\n",
       " 'Img_020_0535.jpg',\n",
       " 'Img_020_0253.jpg',\n",
       " 'Img_020_0904.jpg',\n",
       " 'Img_020_0910.jpg',\n",
       " 'Img_020_0938.jpg',\n",
       " 'Img_020_0086.jpg',\n",
       " 'Img_020_0092.jpg',\n",
       " 'Img_020_0079.jpg',\n",
       " 'Img_020_0723.jpg',\n",
       " 'Img_020_0045.jpg',\n",
       " 'Img_020_0051.jpg',\n",
       " 'Img_020_0737.jpg',\n",
       " 'Img_020_0047.jpg',\n",
       " 'Img_020_0721.jpg',\n",
       " 'Img_020_0735.jpg',\n",
       " 'Img_020_0053.jpg',\n",
       " 'Img_020_0709.jpg',\n",
       " 'Img_020_0084.jpg',\n",
       " 'Img_020_0090.jpg',\n",
       " 'Img_020_0906.jpg',\n",
       " 'Img_020_0912.jpg',\n",
       " 'Img_020_0523.jpg',\n",
       " 'Img_020_0245.jpg',\n",
       " 'Img_020_0251.jpg',\n",
       " 'Img_020_0537.jpg',\n",
       " 'Img_020_0279.jpg',\n",
       " 'Img_020_0286.jpg',\n",
       " 'Img_020_0292.jpg',\n",
       " 'Img_020_0457.jpg',\n",
       " 'Img_020_0331.jpg',\n",
       " 'Img_020_0325.jpg',\n",
       " 'Img_020_0443.jpg',\n",
       " 'Img_020_0319.jpg',\n",
       " 'Img_020_0494.jpg',\n",
       " 'Img_020_0480.jpg',\n",
       " 'Img_020_0133.jpg',\n",
       " 'Img_020_0655.jpg',\n",
       " 'Img_020_0899.jpg',\n",
       " 'Img_020_0641.jpg',\n",
       " 'Img_020_0127.jpg',\n",
       " 'Img_020_0669.jpg',\n",
       " 'Img_020_0696.jpg',\n",
       " 'Img_020_0682.jpg',\n",
       " 'Img_020_0872.jpg',\n",
       " 'Img_020_0866.jpg',\n",
       " 'Img_020_0867.jpg',\n",
       " 'Img_020_0873.jpg',\n",
       " 'Img_020_0683.jpg',\n",
       " 'Img_020_0697.jpg',\n",
       " 'Img_020_0668.jpg',\n",
       " 'Img_020_0640.jpg',\n",
       " 'Img_020_0898.jpg',\n",
       " 'Img_020_0126.jpg',\n",
       " 'Img_020_0132.jpg',\n",
       " 'Img_020_0654.jpg',\n",
       " 'Img_020_0481.jpg',\n",
       " 'Img_020_0495.jpg',\n",
       " 'Img_020_0318.jpg',\n",
       " 'Img_020_0324.jpg',\n",
       " 'Img_020_0442.jpg',\n",
       " 'Img_020_0456.jpg',\n",
       " 'Img_020_0330.jpg',\n",
       " 'Img_020_0293.jpg',\n",
       " 'Img_020_0287.jpg',\n",
       " 'Img_020_0278.jpg',\n",
       " 'Img_020_0250.jpg',\n",
       " 'Img_020_0536.jpg',\n",
       " 'Img_020_0522.jpg',\n",
       " 'Img_020_0244.jpg',\n",
       " 'Img_020_0913.jpg',\n",
       " 'Img_020_0907.jpg',\n",
       " 'Img_020_0091.jpg',\n",
       " 'Img_020_0085.jpg',\n",
       " 'Img_020_0708.jpg',\n",
       " 'Img_020_0734.jpg',\n",
       " 'Img_020_0052.jpg',\n",
       " 'Img_020_0046.jpg',\n",
       " 'Img_020_0720.jpg',\n",
       " 'Img_020_0718.jpg',\n",
       " 'Img_020_0724.jpg',\n",
       " 'Img_020_0042.jpg',\n",
       " 'Img_020_0056.jpg',\n",
       " 'Img_020_0730.jpg',\n",
       " 'Img_020_0903.jpg',\n",
       " 'Img_020_0917.jpg',\n",
       " 'Img_020_0081.jpg',\n",
       " 'Img_020_0095.jpg',\n",
       " 'Img_020_0268.jpg',\n",
       " 'Img_020_0240.jpg',\n",
       " 'Img_020_0526.jpg',\n",
       " 'Img_020_0532.jpg',\n",
       " 'Img_020_0254.jpg',\n",
       " 'Img_020_0283.jpg',\n",
       " 'Img_020_0297.jpg',\n",
       " 'Img_020_0308.jpg',\n",
       " 'Img_020_0334.jpg',\n",
       " 'Img_020_0452.jpg',\n",
       " 'Img_020_0446.jpg',\n",
       " 'Img_020_0320.jpg',\n",
       " 'Img_020_0491.jpg',\n",
       " 'Img_020_0485.jpg',\n",
       " 'Img_020_0678.jpg',\n",
       " 'Img_020_0888.jpg',\n",
       " 'Img_020_0650.jpg',\n",
       " 'Img_020_0136.jpg',\n",
       " 'Img_020_0122.jpg',\n",
       " 'Img_020_0644.jpg',\n",
       " 'Img_020_0877.jpg',\n",
       " 'Img_020_0863.jpg',\n",
       " 'Img_020_0693.jpg',\n",
       " 'Img_020_0687.jpg',\n",
       " 'Img_020_0686.jpg',\n",
       " 'Img_020_0692.jpg',\n",
       " 'Img_020_0862.jpg',\n",
       " 'Img_020_0876.jpg',\n",
       " 'Img_020_0123.jpg',\n",
       " 'Img_020_0645.jpg',\n",
       " 'Img_020_0651.jpg',\n",
       " 'Img_020_0889.jpg',\n",
       " 'Img_020_0137.jpg',\n",
       " 'Img_020_0679.jpg',\n",
       " 'Img_020_0484.jpg',\n",
       " 'Img_020_0490.jpg',\n",
       " 'Img_020_0447.jpg',\n",
       " 'Img_020_0321.jpg',\n",
       " 'Img_020_0335.jpg',\n",
       " 'Img_020_0453.jpg',\n",
       " 'Img_020_0309.jpg',\n",
       " 'Img_020_0296.jpg',\n",
       " 'Img_020_0282.jpg',\n",
       " 'Img_020_0533.jpg',\n",
       " 'Img_020_0255.jpg',\n",
       " 'Img_020_0241.jpg',\n",
       " 'Img_020_0527.jpg',\n",
       " 'Img_020_0269.jpg',\n",
       " 'Img_020_0094.jpg',\n",
       " 'Img_020_0080.jpg',\n",
       " 'Img_020_0916.jpg',\n",
       " 'Img_020_0902.jpg',\n",
       " 'Img_020_0057.jpg',\n",
       " 'Img_020_0731.jpg',\n",
       " 'Img_020_0725.jpg',\n",
       " 'Img_020_0043.jpg',\n",
       " 'Img_020_0719.jpg',\n",
       " 'Img_020_0069.jpg',\n",
       " 'Img_020_0733.jpg',\n",
       " 'Img_020_0055.jpg',\n",
       " 'Img_020_0041.jpg',\n",
       " 'Img_020_0727.jpg',\n",
       " 'Img_020_0914.jpg',\n",
       " 'Img_020_0900.jpg',\n",
       " 'Img_020_0928.jpg',\n",
       " 'Img_020_0096.jpg',\n",
       " 'Img_020_0082.jpg',\n",
       " 'Img_020_0519.jpg',\n",
       " 'Img_020_0257.jpg',\n",
       " 'Img_020_0531.jpg',\n",
       " 'Img_020_0525.jpg',\n",
       " 'Img_020_0243.jpg',\n",
       " 'Img_020_0294.jpg',\n",
       " 'Img_020_0280.jpg',\n",
       " 'Img_020_0479.jpg',\n",
       " 'Img_020_0323.jpg',\n",
       " 'Img_020_0445.jpg',\n",
       " 'Img_020_0451.jpg',\n",
       " 'Img_020_0337.jpg',\n",
       " 'Img_020_0486.jpg',\n",
       " 'Img_020_0492.jpg',\n",
       " 'Img_020_0109.jpg',\n",
       " 'Img_020_0647.jpg',\n",
       " 'Img_020_0121.jpg',\n",
       " 'Img_020_0135.jpg',\n",
       " 'Img_020_0653.jpg',\n",
       " 'Img_020_0860.jpg',\n",
       " 'Img_020_0874.jpg',\n",
       " 'Img_020_0684.jpg',\n",
       " 'Img_020_0690.jpg',\n",
       " 'Img_020_0848.jpg',\n",
       " 'Img_020_0849.jpg',\n",
       " 'Img_020_0691.jpg',\n",
       " 'Img_020_0685.jpg',\n",
       " 'Img_020_0875.jpg',\n",
       " 'Img_020_0861.jpg',\n",
       " 'Img_020_0134.jpg',\n",
       " 'Img_020_0652.jpg',\n",
       " 'Img_020_0646.jpg',\n",
       " 'Img_020_0120.jpg',\n",
       " 'Img_020_0108.jpg',\n",
       " 'Img_020_0493.jpg',\n",
       " 'Img_020_0487.jpg',\n",
       " 'Img_020_0450.jpg',\n",
       " 'Img_020_0336.jpg',\n",
       " 'Img_020_0322.jpg',\n",
       " 'Img_020_0444.jpg',\n",
       " 'Img_020_0478.jpg',\n",
       " 'Img_020_0281.jpg',\n",
       " 'Img_020_0295.jpg',\n",
       " 'Img_020_0524.jpg',\n",
       " 'Img_020_0242.jpg',\n",
       " 'Img_020_0256.jpg',\n",
       " 'Img_020_0530.jpg',\n",
       " 'Img_020_0518.jpg',\n",
       " 'Img_020_0083.jpg',\n",
       " 'Img_020_0929.jpg',\n",
       " 'Img_020_0097.jpg',\n",
       " 'Img_020_0901.jpg',\n",
       " 'Img_020_0915.jpg',\n",
       " 'Img_020_0040.jpg',\n",
       " 'Img_020_0726.jpg',\n",
       " 'Img_020_0732.jpg',\n",
       " 'Img_020_0054.jpg',\n",
       " 'Img_020_0068.jpg',\n",
       " 'Img_020_0755.jpg',\n",
       " 'Img_020_0027.jpg',\n",
       " 'Img_020_0741.jpg',\n",
       " 'Img_020_0769.jpg',\n",
       " 'Img_020_0796.jpg',\n",
       " 'Img_020_0782.jpg',\n",
       " 'Img_020_0972.jpg',\n",
       " 'Img_020_0966.jpg',\n",
       " 'Img_020_0231.jpg',\n",
       " 'Img_020_0557.jpg',\n",
       " 'Img_020_0543.jpg',\n",
       " 'Img_020_0225.jpg',\n",
       " 'Img_020_0219.jpg',\n",
       " 'Img_020_0594.jpg',\n",
       " 'Img_020_0580.jpg',\n",
       " 'Img_020_0345.jpg',\n",
       " 'Img_020_0423.jpg',\n",
       " 'Img_020_0437.jpg',\n",
       " 'Img_020_0351.jpg',\n",
       " 'Img_020_0379.jpg',\n",
       " 'Img_020_0386.jpg',\n",
       " 'Img_020_0392.jpg',\n",
       " 'Img_020_0621.jpg',\n",
       " 'Img_020_0147.jpg',\n",
       " 'Img_020_0153.jpg',\n",
       " 'Img_020_0635.jpg',\n",
       " 'Img_020_0609.jpg',\n",
       " 'Img_020_0184.jpg',\n",
       " 'Img_020_0190.jpg',\n",
       " 'Img_020_0806.jpg',\n",
       " 'Img_020_0812.jpg',\n",
       " 'Img_020_0813.jpg',\n",
       " 'Img_020_0807.jpg',\n",
       " 'Img_020_0191.jpg',\n",
       " 'Img_020_0185.jpg',\n",
       " 'Img_020_0608.jpg',\n",
       " 'Img_020_0152.jpg',\n",
       " 'Img_020_0634.jpg',\n",
       " 'Img_020_0620.jpg',\n",
       " 'Img_020_0146.jpg',\n",
       " 'Img_020_0393.jpg',\n",
       " 'Img_020_0387.jpg',\n",
       " 'Img_020_0378.jpg',\n",
       " 'Img_020_0436.jpg',\n",
       " 'Img_020_0350.jpg',\n",
       " 'Img_020_0344.jpg',\n",
       " 'Img_020_0422.jpg',\n",
       " 'Img_020_0581.jpg',\n",
       " 'Img_020_0595.jpg',\n",
       " 'Img_020_0218.jpg',\n",
       " 'Img_020_0542.jpg',\n",
       " 'Img_020_0224.jpg',\n",
       " 'Img_020_0230.jpg',\n",
       " 'Img_020_0556.jpg',\n",
       " 'Img_020_0967.jpg',\n",
       " 'Img_020_0973.jpg',\n",
       " 'Img_020_0783.jpg',\n",
       " 'Img_020_0797.jpg',\n",
       " 'Img_020_0768.jpg',\n",
       " 'Img_020_0026.jpg',\n",
       " 'Img_020_0998.jpg',\n",
       " 'Img_020_0740.jpg',\n",
       " 'Img_020_0754.jpg',\n",
       " 'Img_020_0032.jpg',\n",
       " 'Img_020_0742.jpg',\n",
       " 'Img_020_0024.jpg',\n",
       " 'Img_020_0030.jpg',\n",
       " 'Img_020_0756.jpg',\n",
       " 'Img_020_0018.jpg',\n",
       " 'Img_020_0959.jpg',\n",
       " 'Img_020_0781.jpg',\n",
       " 'Img_020_0795.jpg',\n",
       " 'Img_020_0965.jpg',\n",
       " 'Img_020_0971.jpg',\n",
       " 'Img_020_0226.jpg',\n",
       " 'Img_020_0540.jpg',\n",
       " 'Img_020_0554.jpg',\n",
       " 'Img_020_0232.jpg',\n",
       " 'Img_020_0568.jpg',\n",
       " 'Img_020_0583.jpg',\n",
       " 'Img_020_0597.jpg',\n",
       " 'Img_020_0352.jpg',\n",
       " 'Img_020_0434.jpg',\n",
       " 'Img_020_0420.jpg',\n",
       " 'Img_020_0346.jpg',\n",
       " 'Img_020_0408.jpg',\n",
       " 'Img_020_0391.jpg',\n",
       " 'Img_020_0385.jpg',\n",
       " 'Img_020_0636.jpg',\n",
       " 'Img_020_0150.jpg',\n",
       " 'Img_020_0144.jpg',\n",
       " 'Img_020_0622.jpg',\n",
       " 'Img_020_0178.jpg',\n",
       " 'Img_020_0193.jpg',\n",
       " 'Img_020_0187.jpg',\n",
       " 'Img_020_0839.jpg',\n",
       " 'Img_020_0811.jpg',\n",
       " 'Img_020_0805.jpg',\n",
       " 'Img_020_0804.jpg',\n",
       " 'Img_020_0810.jpg',\n",
       " 'Img_020_0186.jpg',\n",
       " 'Img_020_0838.jpg',\n",
       " 'Img_020_0192.jpg',\n",
       " 'Img_020_0179.jpg',\n",
       " 'Img_020_0145.jpg',\n",
       " 'Img_020_0623.jpg',\n",
       " 'Img_020_0637.jpg',\n",
       " 'Img_020_0151.jpg',\n",
       " 'Img_020_0384.jpg',\n",
       " 'Img_020_0390.jpg',\n",
       " 'Img_020_0409.jpg',\n",
       " 'Img_020_0421.jpg',\n",
       " 'Img_020_0347.jpg',\n",
       " 'Img_020_0353.jpg',\n",
       " 'Img_020_0435.jpg',\n",
       " 'Img_020_0596.jpg',\n",
       " 'Img_020_0582.jpg',\n",
       " 'Img_020_0569.jpg',\n",
       " 'Img_020_0555.jpg',\n",
       " 'Img_020_0233.jpg',\n",
       " 'Img_020_0227.jpg',\n",
       " 'Img_020_0541.jpg',\n",
       " 'Img_020_0970.jpg',\n",
       " 'Img_020_0964.jpg',\n",
       " 'Img_020_0794.jpg',\n",
       " 'Img_020_0780.jpg',\n",
       " 'Img_020_0958.jpg',\n",
       " 'Img_020_0019.jpg',\n",
       " 'Img_020_0031.jpg',\n",
       " 'Img_020_0757.jpg',\n",
       " 'Img_020_0743.jpg',\n",
       " 'Img_020_0025.jpg',\n",
       " 'Img_020_0009.jpg',\n",
       " 'Img_020_0021.jpg',\n",
       " 'Img_020_0747.jpg',\n",
       " 'Img_020_0753.jpg',\n",
       " 'Img_020_0035.jpg',\n",
       " 'Img_020_0960.jpg',\n",
       " 'Img_020_0974.jpg',\n",
       " 'Img_020_0784.jpg',\n",
       " 'Img_020_0948.jpg',\n",
       " 'Img_020_0790.jpg',\n",
       " 'Img_020_0579.jpg',\n",
       " 'Img_020_0545.jpg',\n",
       " 'Img_020_0223.jpg',\n",
       " 'Img_020_0237.jpg',\n",
       " 'Img_020_0551.jpg',\n",
       " 'Img_020_0586.jpg',\n",
       " 'Img_020_0592.jpg',\n",
       " 'Img_020_0419.jpg',\n",
       " 'Img_020_0431.jpg',\n",
       " 'Img_020_0357.jpg',\n",
       " 'Img_020_0343.jpg',\n",
       " 'Img_020_0425.jpg',\n",
       " 'Img_020_0394.jpg',\n",
       " 'Img_020_0380.jpg',\n",
       " 'Img_020_0169.jpg',\n",
       " 'Img_020_0155.jpg',\n",
       " 'Img_020_0633.jpg',\n",
       " 'Img_020_0627.jpg',\n",
       " 'Img_020_0141.jpg',\n",
       " 'Img_020_0814.jpg',\n",
       " 'Img_020_0800.jpg',\n",
       " 'Img_020_0196.jpg',\n",
       " 'Img_020_0828.jpg',\n",
       " 'Img_020_0182.jpg',\n",
       " 'Img_020_0183.jpg',\n",
       " 'Img_020_0197.jpg',\n",
       " 'Img_020_0829.jpg',\n",
       " 'Img_020_0801.jpg',\n",
       " 'Img_020_0815.jpg',\n",
       " 'Img_020_0626.jpg',\n",
       " 'Img_020_0140.jpg',\n",
       " 'Img_020_0154.jpg',\n",
       " 'Img_020_0632.jpg',\n",
       " 'Img_020_0168.jpg',\n",
       " 'Img_020_0381.jpg',\n",
       " 'Img_020_0395.jpg',\n",
       " 'Img_020_0342.jpg',\n",
       " 'Img_020_0424.jpg',\n",
       " 'Img_020_0430.jpg',\n",
       " 'Img_020_0356.jpg',\n",
       " 'Img_020_0418.jpg',\n",
       " 'Img_020_0593.jpg',\n",
       " 'Img_020_0587.jpg',\n",
       " 'Img_020_0236.jpg',\n",
       " 'Img_020_0550.jpg',\n",
       " 'Img_020_0544.jpg',\n",
       " 'Img_020_0222.jpg',\n",
       " 'Img_020_0578.jpg',\n",
       " 'Img_020_0791.jpg',\n",
       " 'Img_020_0949.jpg',\n",
       " 'Img_020_0785.jpg',\n",
       " 'Img_020_0975.jpg',\n",
       " 'Img_020_0961.jpg',\n",
       " 'Img_020_0752.jpg',\n",
       " 'Img_020_0034.jpg',\n",
       " 'Img_020_0020.jpg',\n",
       " 'Img_020_0746.jpg',\n",
       " 'Img_020_0008.jpg',\n",
       " 'Img_020_0778.jpg',\n",
       " 'Img_020_0036.jpg',\n",
       " 'Img_020_0750.jpg',\n",
       " 'Img_020_0988.jpg',\n",
       " 'Img_020_0744.jpg',\n",
       " 'Img_020_0022.jpg',\n",
       " 'Img_020_0977.jpg',\n",
       " 'Img_020_0963.jpg',\n",
       " 'Img_020_0793.jpg',\n",
       " 'Img_020_0787.jpg',\n",
       " 'Img_020_0208.jpg',\n",
       " 'Img_020_0552.jpg',\n",
       " 'Img_020_0234.jpg',\n",
       " 'Img_020_0220.jpg',\n",
       " 'Img_020_0546.jpg',\n",
       " 'Img_020_0591.jpg',\n",
       " 'Img_020_0585.jpg',\n",
       " 'Img_020_0368.jpg',\n",
       " 'Img_020_0426.jpg',\n",
       " 'Img_020_0340.jpg',\n",
       " 'Img_020_0354.jpg',\n",
       " 'Img_020_0432.jpg',\n",
       " 'Img_020_0383.jpg',\n",
       " 'Img_020_0397.jpg',\n",
       " 'Img_020_0618.jpg',\n",
       " 'Img_020_0142.jpg',\n",
       " 'Img_020_0624.jpg',\n",
       " 'Img_020_0630.jpg',\n",
       " 'Img_020_0156.jpg',\n",
       " 'Img_020_0803.jpg',\n",
       " 'Img_020_0817.jpg',\n",
       " 'Img_020_0181.jpg',\n",
       " 'Img_020_0195.jpg',\n",
       " 'Img_020_0194.jpg',\n",
       " 'Img_020_0180.jpg',\n",
       " 'Img_020_0816.jpg',\n",
       " 'Img_020_0802.jpg',\n",
       " 'Img_020_0631.jpg',\n",
       " 'Img_020_0157.jpg',\n",
       " 'Img_020_0143.jpg',\n",
       " 'Img_020_0625.jpg',\n",
       " 'Img_020_0619.jpg',\n",
       " 'Img_020_0396.jpg',\n",
       " 'Img_020_0382.jpg',\n",
       " 'Img_020_0355.jpg',\n",
       " 'Img_020_0433.jpg',\n",
       " 'Img_020_0427.jpg',\n",
       " 'Img_020_0341.jpg',\n",
       " 'Img_020_0369.jpg',\n",
       " 'Img_020_0584.jpg',\n",
       " 'Img_020_0590.jpg',\n",
       " 'Img_020_0221.jpg',\n",
       " 'Img_020_0547.jpg',\n",
       " 'Img_020_0553.jpg',\n",
       " 'Img_020_0235.jpg',\n",
       " 'Img_020_0209.jpg',\n",
       " 'Img_020_0786.jpg',\n",
       " 'Img_020_0792.jpg',\n",
       " 'Img_020_0962.jpg',\n",
       " 'Img_020_0976.jpg',\n",
       " 'Img_020_0745.jpg',\n",
       " 'Img_020_0023.jpg',\n",
       " 'Img_020_0037.jpg',\n",
       " 'Img_020_0989.jpg',\n",
       " 'Img_020_0751.jpg',\n",
       " 'Img_020_0779.jpg',\n",
       " 'Img_005_0488.jpg',\n",
       " 'Img_005_0339.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d614023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x100 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.img_path\n",
    "train_dataset.img_dir , train_dataset.img_path\n",
    "\n",
    "#image_datasets = {x : datasets.Image}\n",
    "\n",
    "print(train_dataset.__getitem__(3)['gt'].size())\n",
    "\n",
    "pltsize = 1\n",
    "plt.figure(figsize= (10 * pltsize, pltsize))\n",
    "\n",
    "for i in range(10) :\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(train_dataset.__getitem__(3)['gt'], (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b5e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83c4813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "batch = 64\n",
    "valid_size = 0.2\n",
    "num = train_data.__len__()\n",
    "# Dividing the indices for train and cross validation\n",
    "indices = list(range(num))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size*num))\n",
    "train_idx,valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "#Create Samplers\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch, sampler = train_sampler)\n",
    "valid_loader = DataLoader(train_dataset, batch_size = batch, sampler = valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581403b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "387fc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "dataset_sizes = {}\n",
    "dataloaders['train'] = train_loader\n",
    "dataloaders['val'] = valid_loader\n",
    "dataset_sizes['train'] = train_sampler.__len__()\n",
    "dataset_sizes['val'] = valid_sampler.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3b29445",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 6. 불러온 특정 모델에 대하여 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, item in enumerate(train_loader) :\n",
    "        image = item['gt'].to(DEVICE)\n",
    "        label = item['label'].to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        image = image.to(torch.float32)\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157c7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6558ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 7. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for batch_idx, item in enumerate(train_loader) :\n",
    "            image = item['gt'].to(DEVICE)\n",
    "            label = item['label'].to(DEVICE)\n",
    "            image = image.to(torch.float32)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bfcc4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' 8. PyTorch 내에서 제공하는 미리 학습되지 않은 ResNet18 모델 불러온 후 Output 크기 설정하기 '''\n",
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained = False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 101)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf1eec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=101, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "''' 9. Optimizer, Objective Function 설정하기 '''\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b80900c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5152f8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataloaders\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"
     ]
    }
   ],
   "source": [
    "dataloaders[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdbc7c09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 2 (470168896.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    train(model.to(DEVICE), dataloaders[\"train\"], optimizer, log_interval = 5)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 2\n"
     ]
    }
   ],
   "source": [
    "    EPOCHS = 1\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model.to(DEVICE), dataloaders[\"train\"], optimizer, log_interval = 5)\n",
    "    test_loss, test_accuracy = evaluate(model.to(DEVICE), dataloaders[\"val\"])\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4936b105",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     train(model, \u001b[43mdataloaders\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], optimizer, log_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     10\u001b[0m     valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, dataloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[EPOCH: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     12\u001b[0m         epoch, valid_loss, valid_accuracy))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained = True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 101)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "EPOCHS = 30\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, dataloaders[\"train\"], optimizer, log_interval = 5)\n",
    "    valid_loss, valid_accuracy = evaluate(model, dataloaders[\"val\"])\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, valid_loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb51d698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/75750 (0%)]\tTrain Loss: 4.826594\n",
      "Train Epoch: 1 [320/75750 (1%)]\tTrain Loss: 4.617962\n",
      "Train Epoch: 1 [640/75750 (1%)]\tTrain Loss: 4.457331\n",
      "Train Epoch: 1 [960/75750 (2%)]\tTrain Loss: 4.179923\n",
      "Train Epoch: 1 [1280/75750 (2%)]\tTrain Loss: 4.487531\n",
      "Train Epoch: 1 [1600/75750 (3%)]\tTrain Loss: 3.927227\n",
      "Train Epoch: 1 [1920/75750 (3%)]\tTrain Loss: 4.277585\n",
      "Train Epoch: 1 [2240/75750 (4%)]\tTrain Loss: 3.947874\n",
      "Train Epoch: 1 [2560/75750 (4%)]\tTrain Loss: 4.079782\n",
      "Train Epoch: 1 [2880/75750 (5%)]\tTrain Loss: 3.573799\n",
      "Train Epoch: 1 [3200/75750 (5%)]\tTrain Loss: 3.888764\n",
      "Train Epoch: 1 [3520/75750 (6%)]\tTrain Loss: 3.655310\n",
      "Train Epoch: 1 [3840/75750 (6%)]\tTrain Loss: 3.820575\n",
      "Train Epoch: 1 [4160/75750 (7%)]\tTrain Loss: 3.827345\n",
      "Train Epoch: 1 [4480/75750 (7%)]\tTrain Loss: 3.699093\n",
      "Train Epoch: 1 [4800/75750 (8%)]\tTrain Loss: 3.723771\n",
      "Train Epoch: 1 [5120/75750 (8%)]\tTrain Loss: 3.649198\n",
      "Train Epoch: 1 [5440/75750 (9%)]\tTrain Loss: 3.500782\n",
      "Train Epoch: 1 [5760/75750 (10%)]\tTrain Loss: 3.035061\n",
      "Train Epoch: 1 [6080/75750 (10%)]\tTrain Loss: 3.465385\n",
      "Train Epoch: 1 [6400/75750 (11%)]\tTrain Loss: 3.787429\n",
      "Train Epoch: 1 [6720/75750 (11%)]\tTrain Loss: 3.735663\n",
      "Train Epoch: 1 [7040/75750 (12%)]\tTrain Loss: 3.235920\n",
      "Train Epoch: 1 [7360/75750 (12%)]\tTrain Loss: 3.478718\n",
      "Train Epoch: 1 [7680/75750 (13%)]\tTrain Loss: 3.297401\n",
      "Train Epoch: 1 [8000/75750 (13%)]\tTrain Loss: 3.605348\n",
      "Train Epoch: 1 [8320/75750 (14%)]\tTrain Loss: 3.361177\n",
      "Train Epoch: 1 [8640/75750 (14%)]\tTrain Loss: 3.042496\n",
      "Train Epoch: 1 [8960/75750 (15%)]\tTrain Loss: 3.272681\n",
      "Train Epoch: 1 [9280/75750 (15%)]\tTrain Loss: 3.484331\n",
      "Train Epoch: 1 [9600/75750 (16%)]\tTrain Loss: 3.471983\n",
      "Train Epoch: 1 [9920/75750 (16%)]\tTrain Loss: 3.620039\n",
      "Train Epoch: 1 [10240/75750 (17%)]\tTrain Loss: 3.309374\n",
      "Train Epoch: 1 [10560/75750 (17%)]\tTrain Loss: 3.272348\n",
      "Train Epoch: 1 [10880/75750 (18%)]\tTrain Loss: 3.517256\n",
      "Train Epoch: 1 [11200/75750 (18%)]\tTrain Loss: 3.057160\n",
      "Train Epoch: 1 [11520/75750 (19%)]\tTrain Loss: 3.333489\n",
      "Train Epoch: 1 [11840/75750 (20%)]\tTrain Loss: 2.843262\n",
      "Train Epoch: 1 [12160/75750 (20%)]\tTrain Loss: 3.134150\n",
      "Train Epoch: 1 [12480/75750 (21%)]\tTrain Loss: 3.295233\n",
      "Train Epoch: 1 [12800/75750 (21%)]\tTrain Loss: 3.120453\n",
      "Train Epoch: 1 [13120/75750 (22%)]\tTrain Loss: 2.997426\n",
      "Train Epoch: 1 [13440/75750 (22%)]\tTrain Loss: 3.224962\n",
      "Train Epoch: 1 [13760/75750 (23%)]\tTrain Loss: 3.268368\n",
      "Train Epoch: 1 [14080/75750 (23%)]\tTrain Loss: 3.177763\n",
      "Train Epoch: 1 [14400/75750 (24%)]\tTrain Loss: 3.040797\n",
      "Train Epoch: 1 [14720/75750 (24%)]\tTrain Loss: 3.009227\n",
      "Train Epoch: 1 [15040/75750 (25%)]\tTrain Loss: 3.146103\n",
      "Train Epoch: 1 [15360/75750 (25%)]\tTrain Loss: 2.656759\n",
      "Train Epoch: 1 [15680/75750 (26%)]\tTrain Loss: 3.627908\n",
      "Train Epoch: 1 [16000/75750 (26%)]\tTrain Loss: 2.499652\n",
      "Train Epoch: 1 [16320/75750 (27%)]\tTrain Loss: 3.653864\n",
      "Train Epoch: 1 [16640/75750 (27%)]\tTrain Loss: 3.166879\n",
      "Train Epoch: 1 [16960/75750 (28%)]\tTrain Loss: 2.783132\n",
      "Train Epoch: 1 [17280/75750 (29%)]\tTrain Loss: 3.183717\n",
      "Train Epoch: 1 [17600/75750 (29%)]\tTrain Loss: 3.111121\n",
      "Train Epoch: 1 [17920/75750 (30%)]\tTrain Loss: 3.178228\n",
      "Train Epoch: 1 [18240/75750 (30%)]\tTrain Loss: 3.212321\n",
      "Train Epoch: 1 [18560/75750 (31%)]\tTrain Loss: 2.790401\n",
      "Train Epoch: 1 [18880/75750 (31%)]\tTrain Loss: 2.975124\n",
      "Train Epoch: 1 [19200/75750 (32%)]\tTrain Loss: 2.728161\n",
      "Train Epoch: 1 [19520/75750 (32%)]\tTrain Loss: 3.091603\n",
      "Train Epoch: 1 [19840/75750 (33%)]\tTrain Loss: 2.908819\n",
      "Train Epoch: 1 [20160/75750 (33%)]\tTrain Loss: 2.667436\n",
      "Train Epoch: 1 [20480/75750 (34%)]\tTrain Loss: 2.919442\n",
      "Train Epoch: 1 [20800/75750 (34%)]\tTrain Loss: 3.153234\n",
      "Train Epoch: 1 [21120/75750 (35%)]\tTrain Loss: 2.896008\n",
      "Train Epoch: 1 [21440/75750 (35%)]\tTrain Loss: 3.013345\n",
      "Train Epoch: 1 [21760/75750 (36%)]\tTrain Loss: 2.859960\n",
      "Train Epoch: 1 [22080/75750 (36%)]\tTrain Loss: 3.103087\n",
      "Train Epoch: 1 [22400/75750 (37%)]\tTrain Loss: 2.874580\n",
      "Train Epoch: 1 [22720/75750 (37%)]\tTrain Loss: 3.194450\n",
      "Train Epoch: 1 [23040/75750 (38%)]\tTrain Loss: 2.821148\n",
      "Train Epoch: 1 [23360/75750 (39%)]\tTrain Loss: 2.924429\n",
      "Train Epoch: 1 [23680/75750 (39%)]\tTrain Loss: 2.407932\n",
      "Train Epoch: 1 [24000/75750 (40%)]\tTrain Loss: 2.661786\n",
      "Train Epoch: 1 [24320/75750 (40%)]\tTrain Loss: 2.611866\n",
      "Train Epoch: 1 [24640/75750 (41%)]\tTrain Loss: 2.566724\n",
      "Train Epoch: 1 [24960/75750 (41%)]\tTrain Loss: 3.071906\n",
      "Train Epoch: 1 [25280/75750 (42%)]\tTrain Loss: 2.966581\n",
      "Train Epoch: 1 [25600/75750 (42%)]\tTrain Loss: 2.677365\n",
      "Train Epoch: 1 [25920/75750 (43%)]\tTrain Loss: 2.877909\n",
      "Train Epoch: 1 [26240/75750 (43%)]\tTrain Loss: 2.917547\n",
      "Train Epoch: 1 [26560/75750 (44%)]\tTrain Loss: 2.802412\n",
      "Train Epoch: 1 [26880/75750 (44%)]\tTrain Loss: 2.193452\n",
      "Train Epoch: 1 [27200/75750 (45%)]\tTrain Loss: 3.476543\n",
      "Train Epoch: 1 [27520/75750 (45%)]\tTrain Loss: 3.066794\n",
      "Train Epoch: 1 [27840/75750 (46%)]\tTrain Loss: 2.555175\n",
      "Train Epoch: 1 [28160/75750 (46%)]\tTrain Loss: 2.373912\n",
      "Train Epoch: 1 [28480/75750 (47%)]\tTrain Loss: 2.766498\n",
      "Train Epoch: 1 [28800/75750 (48%)]\tTrain Loss: 2.656140\n",
      "Train Epoch: 1 [29120/75750 (48%)]\tTrain Loss: 2.724536\n",
      "Train Epoch: 1 [29440/75750 (49%)]\tTrain Loss: 2.923976\n",
      "Train Epoch: 1 [29760/75750 (49%)]\tTrain Loss: 2.431909\n",
      "Train Epoch: 1 [30080/75750 (50%)]\tTrain Loss: 2.625139\n",
      "Train Epoch: 1 [30400/75750 (50%)]\tTrain Loss: 3.069817\n",
      "Train Epoch: 1 [30720/75750 (51%)]\tTrain Loss: 2.707768\n",
      "Train Epoch: 1 [31040/75750 (51%)]\tTrain Loss: 2.623373\n",
      "Train Epoch: 1 [31360/75750 (52%)]\tTrain Loss: 2.521293\n",
      "Train Epoch: 1 [31680/75750 (52%)]\tTrain Loss: 2.242217\n",
      "Train Epoch: 1 [32000/75750 (53%)]\tTrain Loss: 2.623878\n",
      "Train Epoch: 1 [32320/75750 (53%)]\tTrain Loss: 2.703230\n",
      "Train Epoch: 1 [32640/75750 (54%)]\tTrain Loss: 2.596047\n",
      "Train Epoch: 1 [32960/75750 (54%)]\tTrain Loss: 3.010347\n",
      "Train Epoch: 1 [33280/75750 (55%)]\tTrain Loss: 2.653190\n",
      "Train Epoch: 1 [33600/75750 (55%)]\tTrain Loss: 2.520973\n",
      "Train Epoch: 1 [33920/75750 (56%)]\tTrain Loss: 2.694397\n",
      "Train Epoch: 1 [34240/75750 (56%)]\tTrain Loss: 2.558834\n",
      "Train Epoch: 1 [34560/75750 (57%)]\tTrain Loss: 2.680612\n",
      "Train Epoch: 1 [34880/75750 (58%)]\tTrain Loss: 2.332829\n",
      "Train Epoch: 1 [35200/75750 (58%)]\tTrain Loss: 2.745574\n",
      "Train Epoch: 1 [35520/75750 (59%)]\tTrain Loss: 2.214873\n",
      "Train Epoch: 1 [35840/75750 (59%)]\tTrain Loss: 2.014403\n",
      "Train Epoch: 1 [36160/75750 (60%)]\tTrain Loss: 3.153040\n",
      "Train Epoch: 1 [36480/75750 (60%)]\tTrain Loss: 2.538429\n",
      "Train Epoch: 1 [36800/75750 (61%)]\tTrain Loss: 2.534111\n",
      "Train Epoch: 1 [37120/75750 (61%)]\tTrain Loss: 2.518265\n",
      "Train Epoch: 1 [37440/75750 (62%)]\tTrain Loss: 2.489234\n",
      "Train Epoch: 1 [37760/75750 (62%)]\tTrain Loss: 2.435707\n",
      "Train Epoch: 1 [38080/75750 (63%)]\tTrain Loss: 2.636512\n",
      "Train Epoch: 1 [38400/75750 (63%)]\tTrain Loss: 2.272055\n",
      "Train Epoch: 1 [38720/75750 (64%)]\tTrain Loss: 2.792150\n",
      "Train Epoch: 1 [39040/75750 (64%)]\tTrain Loss: 2.626969\n",
      "Train Epoch: 1 [39360/75750 (65%)]\tTrain Loss: 2.302453\n",
      "Train Epoch: 1 [39680/75750 (65%)]\tTrain Loss: 2.656962\n",
      "Train Epoch: 1 [40000/75750 (66%)]\tTrain Loss: 2.691321\n",
      "Train Epoch: 1 [40320/75750 (67%)]\tTrain Loss: 2.261974\n",
      "Train Epoch: 1 [40640/75750 (67%)]\tTrain Loss: 2.493284\n",
      "Train Epoch: 1 [40960/75750 (68%)]\tTrain Loss: 2.834988\n",
      "Train Epoch: 1 [41280/75750 (68%)]\tTrain Loss: 2.335428\n",
      "Train Epoch: 1 [41600/75750 (69%)]\tTrain Loss: 2.774637\n",
      "Train Epoch: 1 [41920/75750 (69%)]\tTrain Loss: 2.672214\n",
      "Train Epoch: 1 [42240/75750 (70%)]\tTrain Loss: 2.691769\n",
      "Train Epoch: 1 [42560/75750 (70%)]\tTrain Loss: 2.352513\n",
      "Train Epoch: 1 [42880/75750 (71%)]\tTrain Loss: 2.385297\n",
      "Train Epoch: 1 [43200/75750 (71%)]\tTrain Loss: 2.789753\n",
      "Train Epoch: 1 [43520/75750 (72%)]\tTrain Loss: 2.636129\n",
      "Train Epoch: 1 [43840/75750 (72%)]\tTrain Loss: 2.044397\n",
      "Train Epoch: 1 [44160/75750 (73%)]\tTrain Loss: 2.686367\n",
      "Train Epoch: 1 [44480/75750 (73%)]\tTrain Loss: 2.988674\n",
      "Train Epoch: 1 [44800/75750 (74%)]\tTrain Loss: 2.651491\n",
      "Train Epoch: 1 [45120/75750 (74%)]\tTrain Loss: 2.106049\n",
      "Train Epoch: 1 [45440/75750 (75%)]\tTrain Loss: 2.942279\n",
      "Train Epoch: 1 [45760/75750 (76%)]\tTrain Loss: 2.736265\n",
      "Train Epoch: 1 [46080/75750 (76%)]\tTrain Loss: 2.334420\n",
      "Train Epoch: 1 [46400/75750 (77%)]\tTrain Loss: 1.938123\n",
      "Train Epoch: 1 [46720/75750 (77%)]\tTrain Loss: 2.399619\n",
      "Train Epoch: 1 [47040/75750 (78%)]\tTrain Loss: 2.556918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [47360/75750 (78%)]\tTrain Loss: 2.279263\n",
      "Train Epoch: 1 [47680/75750 (79%)]\tTrain Loss: 2.227805\n",
      "Train Epoch: 1 [48000/75750 (79%)]\tTrain Loss: 2.260692\n",
      "Train Epoch: 1 [48320/75750 (80%)]\tTrain Loss: 2.145211\n",
      "Train Epoch: 1 [48640/75750 (80%)]\tTrain Loss: 2.350398\n",
      "Train Epoch: 1 [48960/75750 (81%)]\tTrain Loss: 2.509999\n",
      "Train Epoch: 1 [49280/75750 (81%)]\tTrain Loss: 2.408856\n",
      "Train Epoch: 1 [49600/75750 (82%)]\tTrain Loss: 2.340545\n",
      "Train Epoch: 1 [49920/75750 (82%)]\tTrain Loss: 2.523020\n",
      "Train Epoch: 1 [50240/75750 (83%)]\tTrain Loss: 2.233904\n",
      "Train Epoch: 1 [50560/75750 (83%)]\tTrain Loss: 2.389831\n",
      "Train Epoch: 1 [50880/75750 (84%)]\tTrain Loss: 2.321275\n",
      "Train Epoch: 1 [51200/75750 (84%)]\tTrain Loss: 2.067477\n",
      "Train Epoch: 1 [51520/75750 (85%)]\tTrain Loss: 2.632035\n",
      "Train Epoch: 1 [51840/75750 (86%)]\tTrain Loss: 2.653159\n",
      "Train Epoch: 1 [52160/75750 (86%)]\tTrain Loss: 2.212014\n",
      "Train Epoch: 1 [52480/75750 (87%)]\tTrain Loss: 2.341551\n",
      "Train Epoch: 1 [52800/75750 (87%)]\tTrain Loss: 2.189586\n",
      "Train Epoch: 1 [53120/75750 (88%)]\tTrain Loss: 2.478901\n",
      "Train Epoch: 1 [53440/75750 (88%)]\tTrain Loss: 2.574733\n",
      "Train Epoch: 1 [53760/75750 (89%)]\tTrain Loss: 1.953110\n",
      "Train Epoch: 1 [54080/75750 (89%)]\tTrain Loss: 2.082684\n",
      "Train Epoch: 1 [54400/75750 (90%)]\tTrain Loss: 2.216095\n",
      "Train Epoch: 1 [54720/75750 (90%)]\tTrain Loss: 2.138664\n",
      "Train Epoch: 1 [55040/75750 (91%)]\tTrain Loss: 2.120931\n",
      "Train Epoch: 1 [55360/75750 (91%)]\tTrain Loss: 2.543360\n",
      "Train Epoch: 1 [55680/75750 (92%)]\tTrain Loss: 2.204145\n",
      "Train Epoch: 1 [56000/75750 (92%)]\tTrain Loss: 2.235313\n",
      "Train Epoch: 1 [56320/75750 (93%)]\tTrain Loss: 2.399215\n",
      "Train Epoch: 1 [56640/75750 (93%)]\tTrain Loss: 2.206052\n",
      "Train Epoch: 1 [56960/75750 (94%)]\tTrain Loss: 2.610493\n",
      "Train Epoch: 1 [57280/75750 (95%)]\tTrain Loss: 2.449751\n",
      "Train Epoch: 1 [57600/75750 (95%)]\tTrain Loss: 2.106841\n",
      "Train Epoch: 1 [57920/75750 (96%)]\tTrain Loss: 2.401111\n",
      "Train Epoch: 1 [58240/75750 (96%)]\tTrain Loss: 2.192121\n",
      "Train Epoch: 1 [58560/75750 (97%)]\tTrain Loss: 2.329873\n",
      "Train Epoch: 1 [58880/75750 (97%)]\tTrain Loss: 2.419377\n",
      "Train Epoch: 1 [59200/75750 (98%)]\tTrain Loss: 2.068985\n",
      "Train Epoch: 1 [59520/75750 (98%)]\tTrain Loss: 2.167041\n",
      "Train Epoch: 1 [59840/75750 (99%)]\tTrain Loss: 2.269806\n",
      "Train Epoch: 1 [60160/75750 (99%)]\tTrain Loss: 1.957350\n",
      "Train Epoch: 1 [60480/75750 (100%)]\tTrain Loss: 2.463926\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 1.0222, \tTest Accuracy: 29.45 % \n",
      "\n",
      "Train Epoch: 2 [0/75750 (0%)]\tTrain Loss: 2.162079\n",
      "Train Epoch: 2 [320/75750 (1%)]\tTrain Loss: 2.178397\n",
      "Train Epoch: 2 [640/75750 (1%)]\tTrain Loss: 2.257854\n",
      "Train Epoch: 2 [960/75750 (2%)]\tTrain Loss: 2.575888\n",
      "Train Epoch: 2 [1280/75750 (2%)]\tTrain Loss: 2.146626\n",
      "Train Epoch: 2 [1600/75750 (3%)]\tTrain Loss: 2.424909\n",
      "Train Epoch: 2 [1920/75750 (3%)]\tTrain Loss: 2.418103\n",
      "Train Epoch: 2 [2240/75750 (4%)]\tTrain Loss: 2.079736\n",
      "Train Epoch: 2 [2560/75750 (4%)]\tTrain Loss: 1.797140\n",
      "Train Epoch: 2 [2880/75750 (5%)]\tTrain Loss: 2.121476\n",
      "Train Epoch: 2 [3200/75750 (5%)]\tTrain Loss: 2.369454\n",
      "Train Epoch: 2 [3520/75750 (6%)]\tTrain Loss: 2.065280\n",
      "Train Epoch: 2 [3840/75750 (6%)]\tTrain Loss: 2.596638\n",
      "Train Epoch: 2 [4160/75750 (7%)]\tTrain Loss: 2.349180\n",
      "Train Epoch: 2 [4480/75750 (7%)]\tTrain Loss: 1.932910\n",
      "Train Epoch: 2 [4800/75750 (8%)]\tTrain Loss: 2.526193\n",
      "Train Epoch: 2 [5120/75750 (8%)]\tTrain Loss: 1.827938\n",
      "Train Epoch: 2 [5440/75750 (9%)]\tTrain Loss: 2.228471\n",
      "Train Epoch: 2 [5760/75750 (10%)]\tTrain Loss: 2.279870\n",
      "Train Epoch: 2 [6080/75750 (10%)]\tTrain Loss: 2.120479\n",
      "Train Epoch: 2 [6400/75750 (11%)]\tTrain Loss: 2.471126\n",
      "Train Epoch: 2 [6720/75750 (11%)]\tTrain Loss: 1.876296\n",
      "Train Epoch: 2 [7040/75750 (12%)]\tTrain Loss: 2.489762\n",
      "Train Epoch: 2 [7360/75750 (12%)]\tTrain Loss: 2.005640\n",
      "Train Epoch: 2 [7680/75750 (13%)]\tTrain Loss: 2.914236\n",
      "Train Epoch: 2 [8000/75750 (13%)]\tTrain Loss: 2.108739\n",
      "Train Epoch: 2 [8320/75750 (14%)]\tTrain Loss: 2.096325\n",
      "Train Epoch: 2 [8640/75750 (14%)]\tTrain Loss: 1.764658\n",
      "Train Epoch: 2 [8960/75750 (15%)]\tTrain Loss: 2.254001\n",
      "Train Epoch: 2 [9280/75750 (15%)]\tTrain Loss: 2.086316\n",
      "Train Epoch: 2 [9600/75750 (16%)]\tTrain Loss: 2.144861\n",
      "Train Epoch: 2 [9920/75750 (16%)]\tTrain Loss: 2.253023\n",
      "Train Epoch: 2 [10240/75750 (17%)]\tTrain Loss: 2.286024\n",
      "Train Epoch: 2 [10560/75750 (17%)]\tTrain Loss: 2.033013\n",
      "Train Epoch: 2 [10880/75750 (18%)]\tTrain Loss: 2.468792\n",
      "Train Epoch: 2 [11200/75750 (18%)]\tTrain Loss: 2.057884\n",
      "Train Epoch: 2 [11520/75750 (19%)]\tTrain Loss: 2.090371\n",
      "Train Epoch: 2 [11840/75750 (20%)]\tTrain Loss: 2.111766\n",
      "Train Epoch: 2 [12160/75750 (20%)]\tTrain Loss: 2.223010\n",
      "Train Epoch: 2 [12480/75750 (21%)]\tTrain Loss: 2.297314\n",
      "Train Epoch: 2 [12800/75750 (21%)]\tTrain Loss: 1.923468\n",
      "Train Epoch: 2 [13120/75750 (22%)]\tTrain Loss: 1.932782\n",
      "Train Epoch: 2 [13440/75750 (22%)]\tTrain Loss: 2.076878\n",
      "Train Epoch: 2 [13760/75750 (23%)]\tTrain Loss: 2.391304\n",
      "Train Epoch: 2 [14080/75750 (23%)]\tTrain Loss: 2.398150\n",
      "Train Epoch: 2 [14400/75750 (24%)]\tTrain Loss: 2.114373\n",
      "Train Epoch: 2 [14720/75750 (24%)]\tTrain Loss: 2.069849\n",
      "Train Epoch: 2 [15040/75750 (25%)]\tTrain Loss: 1.656470\n",
      "Train Epoch: 2 [15360/75750 (25%)]\tTrain Loss: 2.027727\n",
      "Train Epoch: 2 [15680/75750 (26%)]\tTrain Loss: 1.619856\n",
      "Train Epoch: 2 [16000/75750 (26%)]\tTrain Loss: 1.918704\n",
      "Train Epoch: 2 [16320/75750 (27%)]\tTrain Loss: 1.861794\n",
      "Train Epoch: 2 [16640/75750 (27%)]\tTrain Loss: 2.131814\n",
      "Train Epoch: 2 [16960/75750 (28%)]\tTrain Loss: 2.354549\n",
      "Train Epoch: 2 [17280/75750 (29%)]\tTrain Loss: 1.700173\n",
      "Train Epoch: 2 [17600/75750 (29%)]\tTrain Loss: 1.654251\n",
      "Train Epoch: 2 [17920/75750 (30%)]\tTrain Loss: 2.068795\n",
      "Train Epoch: 2 [18240/75750 (30%)]\tTrain Loss: 2.760967\n",
      "Train Epoch: 2 [18560/75750 (31%)]\tTrain Loss: 2.251478\n",
      "Train Epoch: 2 [18880/75750 (31%)]\tTrain Loss: 1.956578\n",
      "Train Epoch: 2 [19200/75750 (32%)]\tTrain Loss: 2.210788\n",
      "Train Epoch: 2 [19520/75750 (32%)]\tTrain Loss: 2.240576\n",
      "Train Epoch: 2 [19840/75750 (33%)]\tTrain Loss: 2.004300\n",
      "Train Epoch: 2 [20160/75750 (33%)]\tTrain Loss: 1.768326\n",
      "Train Epoch: 2 [20480/75750 (34%)]\tTrain Loss: 2.078897\n",
      "Train Epoch: 2 [20800/75750 (34%)]\tTrain Loss: 1.832397\n",
      "Train Epoch: 2 [21120/75750 (35%)]\tTrain Loss: 2.595427\n",
      "Train Epoch: 2 [21440/75750 (35%)]\tTrain Loss: 1.913042\n",
      "Train Epoch: 2 [21760/75750 (36%)]\tTrain Loss: 2.174038\n",
      "Train Epoch: 2 [22080/75750 (36%)]\tTrain Loss: 1.966318\n",
      "Train Epoch: 2 [22400/75750 (37%)]\tTrain Loss: 2.357572\n",
      "Train Epoch: 2 [22720/75750 (37%)]\tTrain Loss: 2.264457\n",
      "Train Epoch: 2 [23040/75750 (38%)]\tTrain Loss: 1.865735\n",
      "Train Epoch: 2 [23360/75750 (39%)]\tTrain Loss: 2.290338\n",
      "Train Epoch: 2 [23680/75750 (39%)]\tTrain Loss: 2.368319\n",
      "Train Epoch: 2 [24000/75750 (40%)]\tTrain Loss: 2.039860\n",
      "Train Epoch: 2 [24320/75750 (40%)]\tTrain Loss: 2.263488\n",
      "Train Epoch: 2 [24640/75750 (41%)]\tTrain Loss: 1.943988\n",
      "Train Epoch: 2 [24960/75750 (41%)]\tTrain Loss: 1.998996\n",
      "Train Epoch: 2 [25280/75750 (42%)]\tTrain Loss: 1.702098\n",
      "Train Epoch: 2 [25600/75750 (42%)]\tTrain Loss: 2.425765\n",
      "Train Epoch: 2 [25920/75750 (43%)]\tTrain Loss: 2.313631\n",
      "Train Epoch: 2 [26240/75750 (43%)]\tTrain Loss: 1.963853\n",
      "Train Epoch: 2 [26560/75750 (44%)]\tTrain Loss: 2.148759\n",
      "Train Epoch: 2 [26880/75750 (44%)]\tTrain Loss: 2.328518\n",
      "Train Epoch: 2 [27200/75750 (45%)]\tTrain Loss: 1.900108\n",
      "Train Epoch: 2 [27520/75750 (45%)]\tTrain Loss: 1.948679\n",
      "Train Epoch: 2 [27840/75750 (46%)]\tTrain Loss: 2.070017\n",
      "Train Epoch: 2 [28160/75750 (46%)]\tTrain Loss: 1.826205\n",
      "Train Epoch: 2 [28480/75750 (47%)]\tTrain Loss: 2.107134\n",
      "Train Epoch: 2 [28800/75750 (48%)]\tTrain Loss: 2.018458\n",
      "Train Epoch: 2 [29120/75750 (48%)]\tTrain Loss: 1.971096\n",
      "Train Epoch: 2 [29440/75750 (49%)]\tTrain Loss: 2.168370\n",
      "Train Epoch: 2 [29760/75750 (49%)]\tTrain Loss: 2.314038\n",
      "Train Epoch: 2 [30080/75750 (50%)]\tTrain Loss: 2.292357\n",
      "Train Epoch: 2 [30400/75750 (50%)]\tTrain Loss: 1.922126\n",
      "Train Epoch: 2 [30720/75750 (51%)]\tTrain Loss: 2.018848\n",
      "Train Epoch: 2 [31040/75750 (51%)]\tTrain Loss: 2.064401\n",
      "Train Epoch: 2 [31360/75750 (52%)]\tTrain Loss: 2.111091\n",
      "Train Epoch: 2 [31680/75750 (52%)]\tTrain Loss: 1.955073\n",
      "Train Epoch: 2 [32000/75750 (53%)]\tTrain Loss: 2.039920\n",
      "Train Epoch: 2 [32320/75750 (53%)]\tTrain Loss: 2.138260\n",
      "Train Epoch: 2 [32640/75750 (54%)]\tTrain Loss: 2.257348\n",
      "Train Epoch: 2 [32960/75750 (54%)]\tTrain Loss: 2.571954\n",
      "Train Epoch: 2 [33280/75750 (55%)]\tTrain Loss: 1.886038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [33600/75750 (55%)]\tTrain Loss: 1.732373\n",
      "Train Epoch: 2 [33920/75750 (56%)]\tTrain Loss: 1.826407\n",
      "Train Epoch: 2 [34240/75750 (56%)]\tTrain Loss: 2.319041\n",
      "Train Epoch: 2 [34560/75750 (57%)]\tTrain Loss: 2.373073\n",
      "Train Epoch: 2 [34880/75750 (58%)]\tTrain Loss: 1.684116\n",
      "Train Epoch: 2 [35200/75750 (58%)]\tTrain Loss: 1.932918\n",
      "Train Epoch: 2 [35520/75750 (59%)]\tTrain Loss: 1.643348\n",
      "Train Epoch: 2 [35840/75750 (59%)]\tTrain Loss: 1.973621\n",
      "Train Epoch: 2 [36160/75750 (60%)]\tTrain Loss: 2.086313\n",
      "Train Epoch: 2 [36480/75750 (60%)]\tTrain Loss: 1.914610\n",
      "Train Epoch: 2 [36800/75750 (61%)]\tTrain Loss: 2.036449\n",
      "Train Epoch: 2 [37120/75750 (61%)]\tTrain Loss: 1.781115\n",
      "Train Epoch: 2 [37440/75750 (62%)]\tTrain Loss: 2.102731\n",
      "Train Epoch: 2 [37760/75750 (62%)]\tTrain Loss: 2.292058\n",
      "Train Epoch: 2 [38080/75750 (63%)]\tTrain Loss: 2.248838\n",
      "Train Epoch: 2 [38400/75750 (63%)]\tTrain Loss: 2.284896\n",
      "Train Epoch: 2 [38720/75750 (64%)]\tTrain Loss: 1.809658\n",
      "Train Epoch: 2 [39040/75750 (64%)]\tTrain Loss: 2.057064\n",
      "Train Epoch: 2 [39360/75750 (65%)]\tTrain Loss: 1.912497\n",
      "Train Epoch: 2 [39680/75750 (65%)]\tTrain Loss: 1.777656\n",
      "Train Epoch: 2 [40000/75750 (66%)]\tTrain Loss: 2.187598\n",
      "Train Epoch: 2 [40320/75750 (67%)]\tTrain Loss: 1.980700\n",
      "Train Epoch: 2 [40640/75750 (67%)]\tTrain Loss: 2.125031\n",
      "Train Epoch: 2 [40960/75750 (68%)]\tTrain Loss: 1.955935\n",
      "Train Epoch: 2 [41280/75750 (68%)]\tTrain Loss: 2.173613\n",
      "Train Epoch: 2 [41600/75750 (69%)]\tTrain Loss: 2.002566\n",
      "Train Epoch: 2 [41920/75750 (69%)]\tTrain Loss: 2.403987\n",
      "Train Epoch: 2 [42240/75750 (70%)]\tTrain Loss: 1.958979\n",
      "Train Epoch: 2 [42560/75750 (70%)]\tTrain Loss: 1.867088\n",
      "Train Epoch: 2 [42880/75750 (71%)]\tTrain Loss: 1.516601\n",
      "Train Epoch: 2 [43200/75750 (71%)]\tTrain Loss: 2.031532\n",
      "Train Epoch: 2 [43520/75750 (72%)]\tTrain Loss: 2.500281\n",
      "Train Epoch: 2 [43840/75750 (72%)]\tTrain Loss: 1.994954\n",
      "Train Epoch: 2 [44160/75750 (73%)]\tTrain Loss: 2.277515\n",
      "Train Epoch: 2 [44480/75750 (73%)]\tTrain Loss: 1.777072\n",
      "Train Epoch: 2 [44800/75750 (74%)]\tTrain Loss: 2.237671\n",
      "Train Epoch: 2 [45120/75750 (74%)]\tTrain Loss: 2.368726\n",
      "Train Epoch: 2 [45440/75750 (75%)]\tTrain Loss: 1.941038\n",
      "Train Epoch: 2 [45760/75750 (76%)]\tTrain Loss: 1.992226\n",
      "Train Epoch: 2 [46080/75750 (76%)]\tTrain Loss: 1.799563\n",
      "Train Epoch: 2 [46400/75750 (77%)]\tTrain Loss: 2.007954\n",
      "Train Epoch: 2 [46720/75750 (77%)]\tTrain Loss: 2.409199\n",
      "Train Epoch: 2 [47040/75750 (78%)]\tTrain Loss: 1.907568\n",
      "Train Epoch: 2 [47360/75750 (78%)]\tTrain Loss: 2.207388\n",
      "Train Epoch: 2 [47680/75750 (79%)]\tTrain Loss: 1.988766\n",
      "Train Epoch: 2 [48000/75750 (79%)]\tTrain Loss: 2.117213\n",
      "Train Epoch: 2 [48320/75750 (80%)]\tTrain Loss: 2.265044\n",
      "Train Epoch: 2 [48640/75750 (80%)]\tTrain Loss: 1.919770\n",
      "Train Epoch: 2 [48960/75750 (81%)]\tTrain Loss: 1.638197\n",
      "Train Epoch: 2 [49280/75750 (81%)]\tTrain Loss: 1.844367\n",
      "Train Epoch: 2 [49600/75750 (82%)]\tTrain Loss: 1.852847\n",
      "Train Epoch: 2 [49920/75750 (82%)]\tTrain Loss: 2.219393\n",
      "Train Epoch: 2 [50240/75750 (83%)]\tTrain Loss: 1.934760\n",
      "Train Epoch: 2 [50560/75750 (83%)]\tTrain Loss: 1.704729\n",
      "Train Epoch: 2 [50880/75750 (84%)]\tTrain Loss: 2.327242\n",
      "Train Epoch: 2 [51200/75750 (84%)]\tTrain Loss: 1.804584\n",
      "Train Epoch: 2 [51520/75750 (85%)]\tTrain Loss: 1.717626\n",
      "Train Epoch: 2 [51840/75750 (86%)]\tTrain Loss: 1.784913\n",
      "Train Epoch: 2 [52160/75750 (86%)]\tTrain Loss: 1.836920\n",
      "Train Epoch: 2 [52480/75750 (87%)]\tTrain Loss: 1.959187\n",
      "Train Epoch: 2 [52800/75750 (87%)]\tTrain Loss: 2.010227\n",
      "Train Epoch: 2 [53120/75750 (88%)]\tTrain Loss: 1.981410\n",
      "Train Epoch: 2 [53440/75750 (88%)]\tTrain Loss: 2.174785\n",
      "Train Epoch: 2 [53760/75750 (89%)]\tTrain Loss: 1.910643\n",
      "Train Epoch: 2 [54080/75750 (89%)]\tTrain Loss: 1.933372\n",
      "Train Epoch: 2 [54400/75750 (90%)]\tTrain Loss: 1.909529\n",
      "Train Epoch: 2 [54720/75750 (90%)]\tTrain Loss: 1.776427\n",
      "Train Epoch: 2 [55040/75750 (91%)]\tTrain Loss: 1.739195\n",
      "Train Epoch: 2 [55360/75750 (91%)]\tTrain Loss: 1.977152\n",
      "Train Epoch: 2 [55680/75750 (92%)]\tTrain Loss: 2.223506\n",
      "Train Epoch: 2 [56000/75750 (92%)]\tTrain Loss: 1.914750\n",
      "Train Epoch: 2 [56320/75750 (93%)]\tTrain Loss: 1.870008\n",
      "Train Epoch: 2 [56640/75750 (93%)]\tTrain Loss: 1.989141\n",
      "Train Epoch: 2 [56960/75750 (94%)]\tTrain Loss: 1.893683\n",
      "Train Epoch: 2 [57280/75750 (95%)]\tTrain Loss: 2.208015\n",
      "Train Epoch: 2 [57600/75750 (95%)]\tTrain Loss: 1.866772\n",
      "Train Epoch: 2 [57920/75750 (96%)]\tTrain Loss: 1.854694\n",
      "Train Epoch: 2 [58240/75750 (96%)]\tTrain Loss: 1.910165\n",
      "Train Epoch: 2 [58560/75750 (97%)]\tTrain Loss: 1.954083\n",
      "Train Epoch: 2 [58880/75750 (97%)]\tTrain Loss: 2.269851\n",
      "Train Epoch: 2 [59200/75750 (98%)]\tTrain Loss: 1.736956\n",
      "Train Epoch: 2 [59520/75750 (98%)]\tTrain Loss: 1.675449\n",
      "Train Epoch: 2 [59840/75750 (99%)]\tTrain Loss: 1.794457\n",
      "Train Epoch: 2 [60160/75750 (99%)]\tTrain Loss: 2.018495\n",
      "Train Epoch: 2 [60480/75750 (100%)]\tTrain Loss: 2.402571\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.7803, \tTest Accuracy: 40.33 % \n",
      "\n",
      "Train Epoch: 3 [0/75750 (0%)]\tTrain Loss: 1.744215\n",
      "Train Epoch: 3 [320/75750 (1%)]\tTrain Loss: 1.791533\n",
      "Train Epoch: 3 [640/75750 (1%)]\tTrain Loss: 1.910629\n",
      "Train Epoch: 3 [960/75750 (2%)]\tTrain Loss: 1.761759\n",
      "Train Epoch: 3 [1280/75750 (2%)]\tTrain Loss: 1.806214\n",
      "Train Epoch: 3 [1600/75750 (3%)]\tTrain Loss: 1.966821\n",
      "Train Epoch: 3 [1920/75750 (3%)]\tTrain Loss: 2.094750\n",
      "Train Epoch: 3 [2240/75750 (4%)]\tTrain Loss: 2.280921\n",
      "Train Epoch: 3 [2560/75750 (4%)]\tTrain Loss: 1.651630\n",
      "Train Epoch: 3 [2880/75750 (5%)]\tTrain Loss: 1.629802\n",
      "Train Epoch: 3 [3200/75750 (5%)]\tTrain Loss: 1.868160\n",
      "Train Epoch: 3 [3520/75750 (6%)]\tTrain Loss: 1.899275\n",
      "Train Epoch: 3 [3840/75750 (6%)]\tTrain Loss: 2.385235\n",
      "Train Epoch: 3 [4160/75750 (7%)]\tTrain Loss: 1.897301\n",
      "Train Epoch: 3 [4480/75750 (7%)]\tTrain Loss: 1.833970\n",
      "Train Epoch: 3 [4800/75750 (8%)]\tTrain Loss: 1.959355\n",
      "Train Epoch: 3 [5120/75750 (8%)]\tTrain Loss: 1.754203\n",
      "Train Epoch: 3 [5440/75750 (9%)]\tTrain Loss: 2.055860\n",
      "Train Epoch: 3 [5760/75750 (10%)]\tTrain Loss: 1.795213\n",
      "Train Epoch: 3 [6080/75750 (10%)]\tTrain Loss: 1.813102\n",
      "Train Epoch: 3 [6400/75750 (11%)]\tTrain Loss: 1.937135\n",
      "Train Epoch: 3 [6720/75750 (11%)]\tTrain Loss: 1.569537\n",
      "Train Epoch: 3 [7040/75750 (12%)]\tTrain Loss: 2.136746\n",
      "Train Epoch: 3 [7360/75750 (12%)]\tTrain Loss: 1.497776\n",
      "Train Epoch: 3 [7680/75750 (13%)]\tTrain Loss: 2.097542\n",
      "Train Epoch: 3 [8000/75750 (13%)]\tTrain Loss: 1.778798\n",
      "Train Epoch: 3 [8320/75750 (14%)]\tTrain Loss: 1.908568\n",
      "Train Epoch: 3 [8640/75750 (14%)]\tTrain Loss: 1.513232\n",
      "Train Epoch: 3 [8960/75750 (15%)]\tTrain Loss: 2.012591\n",
      "Train Epoch: 3 [9280/75750 (15%)]\tTrain Loss: 2.087855\n",
      "Train Epoch: 3 [9600/75750 (16%)]\tTrain Loss: 1.679664\n",
      "Train Epoch: 3 [9920/75750 (16%)]\tTrain Loss: 1.788962\n",
      "Train Epoch: 3 [10240/75750 (17%)]\tTrain Loss: 1.796813\n",
      "Train Epoch: 3 [10560/75750 (17%)]\tTrain Loss: 1.537627\n",
      "Train Epoch: 3 [10880/75750 (18%)]\tTrain Loss: 1.881143\n",
      "Train Epoch: 3 [11200/75750 (18%)]\tTrain Loss: 1.555837\n",
      "Train Epoch: 3 [11520/75750 (19%)]\tTrain Loss: 2.100749\n",
      "Train Epoch: 3 [11840/75750 (20%)]\tTrain Loss: 1.540204\n",
      "Train Epoch: 3 [12160/75750 (20%)]\tTrain Loss: 2.189399\n",
      "Train Epoch: 3 [12480/75750 (21%)]\tTrain Loss: 2.041041\n",
      "Train Epoch: 3 [12800/75750 (21%)]\tTrain Loss: 1.882316\n",
      "Train Epoch: 3 [13120/75750 (22%)]\tTrain Loss: 1.493219\n",
      "Train Epoch: 3 [13440/75750 (22%)]\tTrain Loss: 1.549307\n",
      "Train Epoch: 3 [13760/75750 (23%)]\tTrain Loss: 2.219945\n",
      "Train Epoch: 3 [14080/75750 (23%)]\tTrain Loss: 1.953250\n",
      "Train Epoch: 3 [14400/75750 (24%)]\tTrain Loss: 2.067280\n",
      "Train Epoch: 3 [14720/75750 (24%)]\tTrain Loss: 1.705438\n",
      "Train Epoch: 3 [15040/75750 (25%)]\tTrain Loss: 2.015676\n",
      "Train Epoch: 3 [15360/75750 (25%)]\tTrain Loss: 1.770541\n",
      "Train Epoch: 3 [15680/75750 (26%)]\tTrain Loss: 1.877875\n",
      "Train Epoch: 3 [16000/75750 (26%)]\tTrain Loss: 1.742678\n",
      "Train Epoch: 3 [16320/75750 (27%)]\tTrain Loss: 1.520835\n",
      "Train Epoch: 3 [16640/75750 (27%)]\tTrain Loss: 1.781649\n",
      "Train Epoch: 3 [16960/75750 (28%)]\tTrain Loss: 1.688725\n",
      "Train Epoch: 3 [17280/75750 (29%)]\tTrain Loss: 1.443080\n",
      "Train Epoch: 3 [17600/75750 (29%)]\tTrain Loss: 1.910434\n",
      "Train Epoch: 3 [17920/75750 (30%)]\tTrain Loss: 1.953773\n",
      "Train Epoch: 3 [18240/75750 (30%)]\tTrain Loss: 1.707623\n",
      "Train Epoch: 3 [18560/75750 (31%)]\tTrain Loss: 1.845094\n",
      "Train Epoch: 3 [18880/75750 (31%)]\tTrain Loss: 1.852489\n",
      "Train Epoch: 3 [19200/75750 (32%)]\tTrain Loss: 1.945384\n",
      "Train Epoch: 3 [19520/75750 (32%)]\tTrain Loss: 1.473572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [19840/75750 (33%)]\tTrain Loss: 1.762158\n",
      "Train Epoch: 3 [20160/75750 (33%)]\tTrain Loss: 1.669842\n",
      "Train Epoch: 3 [20480/75750 (34%)]\tTrain Loss: 1.766939\n",
      "Train Epoch: 3 [20800/75750 (34%)]\tTrain Loss: 2.048336\n",
      "Train Epoch: 3 [21120/75750 (35%)]\tTrain Loss: 1.559013\n",
      "Train Epoch: 3 [21440/75750 (35%)]\tTrain Loss: 1.410000\n",
      "Train Epoch: 3 [21760/75750 (36%)]\tTrain Loss: 1.960907\n",
      "Train Epoch: 3 [22080/75750 (36%)]\tTrain Loss: 1.803806\n",
      "Train Epoch: 3 [22400/75750 (37%)]\tTrain Loss: 1.828249\n",
      "Train Epoch: 3 [22720/75750 (37%)]\tTrain Loss: 1.815055\n",
      "Train Epoch: 3 [23040/75750 (38%)]\tTrain Loss: 1.556192\n",
      "Train Epoch: 3 [23360/75750 (39%)]\tTrain Loss: 1.775580\n",
      "Train Epoch: 3 [23680/75750 (39%)]\tTrain Loss: 1.409483\n",
      "Train Epoch: 3 [24000/75750 (40%)]\tTrain Loss: 1.640868\n",
      "Train Epoch: 3 [24320/75750 (40%)]\tTrain Loss: 1.731039\n",
      "Train Epoch: 3 [24640/75750 (41%)]\tTrain Loss: 1.848732\n",
      "Train Epoch: 3 [24960/75750 (41%)]\tTrain Loss: 1.679904\n",
      "Train Epoch: 3 [25280/75750 (42%)]\tTrain Loss: 1.526512\n",
      "Train Epoch: 3 [25600/75750 (42%)]\tTrain Loss: 1.736157\n",
      "Train Epoch: 3 [25920/75750 (43%)]\tTrain Loss: 1.903299\n",
      "Train Epoch: 3 [26240/75750 (43%)]\tTrain Loss: 1.579456\n",
      "Train Epoch: 3 [26560/75750 (44%)]\tTrain Loss: 1.888679\n",
      "Train Epoch: 3 [26880/75750 (44%)]\tTrain Loss: 2.130074\n",
      "Train Epoch: 3 [27200/75750 (45%)]\tTrain Loss: 1.951449\n",
      "Train Epoch: 3 [27520/75750 (45%)]\tTrain Loss: 1.510829\n",
      "Train Epoch: 3 [27840/75750 (46%)]\tTrain Loss: 1.540763\n",
      "Train Epoch: 3 [28160/75750 (46%)]\tTrain Loss: 1.769356\n",
      "Train Epoch: 3 [28480/75750 (47%)]\tTrain Loss: 1.705643\n",
      "Train Epoch: 3 [28800/75750 (48%)]\tTrain Loss: 1.926288\n",
      "Train Epoch: 3 [29120/75750 (48%)]\tTrain Loss: 1.608617\n",
      "Train Epoch: 3 [29440/75750 (49%)]\tTrain Loss: 1.688166\n",
      "Train Epoch: 3 [29760/75750 (49%)]\tTrain Loss: 1.600652\n",
      "Train Epoch: 3 [30080/75750 (50%)]\tTrain Loss: 2.130642\n",
      "Train Epoch: 3 [30400/75750 (50%)]\tTrain Loss: 1.553469\n",
      "Train Epoch: 3 [30720/75750 (51%)]\tTrain Loss: 1.887463\n",
      "Train Epoch: 3 [31040/75750 (51%)]\tTrain Loss: 1.740642\n",
      "Train Epoch: 3 [31360/75750 (52%)]\tTrain Loss: 1.713381\n",
      "Train Epoch: 3 [31680/75750 (52%)]\tTrain Loss: 1.740156\n",
      "Train Epoch: 3 [32000/75750 (53%)]\tTrain Loss: 1.873893\n",
      "Train Epoch: 3 [32320/75750 (53%)]\tTrain Loss: 1.446488\n",
      "Train Epoch: 3 [32640/75750 (54%)]\tTrain Loss: 1.525748\n",
      "Train Epoch: 3 [32960/75750 (54%)]\tTrain Loss: 2.033556\n",
      "Train Epoch: 3 [33280/75750 (55%)]\tTrain Loss: 1.632628\n",
      "Train Epoch: 3 [33600/75750 (55%)]\tTrain Loss: 1.735793\n",
      "Train Epoch: 3 [33920/75750 (56%)]\tTrain Loss: 1.683183\n",
      "Train Epoch: 3 [34240/75750 (56%)]\tTrain Loss: 1.590193\n",
      "Train Epoch: 3 [34560/75750 (57%)]\tTrain Loss: 2.152361\n",
      "Train Epoch: 3 [34880/75750 (58%)]\tTrain Loss: 1.385543\n",
      "Train Epoch: 3 [35200/75750 (58%)]\tTrain Loss: 1.313672\n",
      "Train Epoch: 3 [35520/75750 (59%)]\tTrain Loss: 1.647256\n",
      "Train Epoch: 3 [35840/75750 (59%)]\tTrain Loss: 1.632000\n",
      "Train Epoch: 3 [36160/75750 (60%)]\tTrain Loss: 1.823585\n",
      "Train Epoch: 3 [36480/75750 (60%)]\tTrain Loss: 1.338448\n",
      "Train Epoch: 3 [36800/75750 (61%)]\tTrain Loss: 1.654278\n",
      "Train Epoch: 3 [37120/75750 (61%)]\tTrain Loss: 1.766270\n",
      "Train Epoch: 3 [37440/75750 (62%)]\tTrain Loss: 1.503759\n",
      "Train Epoch: 3 [37760/75750 (62%)]\tTrain Loss: 1.987268\n",
      "Train Epoch: 3 [38080/75750 (63%)]\tTrain Loss: 1.744469\n",
      "Train Epoch: 3 [38400/75750 (63%)]\tTrain Loss: 1.760344\n",
      "Train Epoch: 3 [38720/75750 (64%)]\tTrain Loss: 1.857868\n",
      "Train Epoch: 3 [39040/75750 (64%)]\tTrain Loss: 1.997130\n",
      "Train Epoch: 3 [39360/75750 (65%)]\tTrain Loss: 1.808326\n",
      "Train Epoch: 3 [39680/75750 (65%)]\tTrain Loss: 1.882326\n",
      "Train Epoch: 3 [40000/75750 (66%)]\tTrain Loss: 1.378612\n",
      "Train Epoch: 3 [40320/75750 (67%)]\tTrain Loss: 1.941736\n",
      "Train Epoch: 3 [40640/75750 (67%)]\tTrain Loss: 2.104905\n",
      "Train Epoch: 3 [40960/75750 (68%)]\tTrain Loss: 1.607221\n",
      "Train Epoch: 3 [41280/75750 (68%)]\tTrain Loss: 1.592324\n",
      "Train Epoch: 3 [41600/75750 (69%)]\tTrain Loss: 1.877028\n",
      "Train Epoch: 3 [41920/75750 (69%)]\tTrain Loss: 1.902675\n",
      "Train Epoch: 3 [42240/75750 (70%)]\tTrain Loss: 2.094207\n",
      "Train Epoch: 3 [42560/75750 (70%)]\tTrain Loss: 1.592767\n",
      "Train Epoch: 3 [42880/75750 (71%)]\tTrain Loss: 1.808794\n",
      "Train Epoch: 3 [43200/75750 (71%)]\tTrain Loss: 1.843725\n",
      "Train Epoch: 3 [43520/75750 (72%)]\tTrain Loss: 1.637670\n",
      "Train Epoch: 3 [43840/75750 (72%)]\tTrain Loss: 1.904009\n",
      "Train Epoch: 3 [44160/75750 (73%)]\tTrain Loss: 1.819443\n",
      "Train Epoch: 3 [44480/75750 (73%)]\tTrain Loss: 1.474304\n",
      "Train Epoch: 3 [44800/75750 (74%)]\tTrain Loss: 1.863108\n",
      "Train Epoch: 3 [45120/75750 (74%)]\tTrain Loss: 1.989037\n",
      "Train Epoch: 3 [45440/75750 (75%)]\tTrain Loss: 1.284912\n",
      "Train Epoch: 3 [45760/75750 (76%)]\tTrain Loss: 1.452384\n",
      "Train Epoch: 3 [46080/75750 (76%)]\tTrain Loss: 1.880072\n",
      "Train Epoch: 3 [46400/75750 (77%)]\tTrain Loss: 1.942599\n",
      "Train Epoch: 3 [46720/75750 (77%)]\tTrain Loss: 1.631589\n",
      "Train Epoch: 3 [47040/75750 (78%)]\tTrain Loss: 1.570634\n",
      "Train Epoch: 3 [47360/75750 (78%)]\tTrain Loss: 2.075511\n",
      "Train Epoch: 3 [47680/75750 (79%)]\tTrain Loss: 1.543476\n",
      "Train Epoch: 3 [48000/75750 (79%)]\tTrain Loss: 1.550772\n",
      "Train Epoch: 3 [48320/75750 (80%)]\tTrain Loss: 1.333436\n",
      "Train Epoch: 3 [48640/75750 (80%)]\tTrain Loss: 1.701446\n",
      "Train Epoch: 3 [48960/75750 (81%)]\tTrain Loss: 1.596477\n",
      "Train Epoch: 3 [49280/75750 (81%)]\tTrain Loss: 1.725051\n",
      "Train Epoch: 3 [49600/75750 (82%)]\tTrain Loss: 1.746736\n",
      "Train Epoch: 3 [49920/75750 (82%)]\tTrain Loss: 1.408085\n",
      "Train Epoch: 3 [50240/75750 (83%)]\tTrain Loss: 1.790569\n",
      "Train Epoch: 3 [50560/75750 (83%)]\tTrain Loss: 1.557817\n",
      "Train Epoch: 3 [50880/75750 (84%)]\tTrain Loss: 1.651108\n",
      "Train Epoch: 3 [51200/75750 (84%)]\tTrain Loss: 1.442813\n",
      "Train Epoch: 3 [51520/75750 (85%)]\tTrain Loss: 2.039608\n",
      "Train Epoch: 3 [51840/75750 (86%)]\tTrain Loss: 2.121997\n",
      "Train Epoch: 3 [52160/75750 (86%)]\tTrain Loss: 2.190133\n",
      "Train Epoch: 3 [52480/75750 (87%)]\tTrain Loss: 1.922698\n",
      "Train Epoch: 3 [52800/75750 (87%)]\tTrain Loss: 1.642501\n",
      "Train Epoch: 3 [53120/75750 (88%)]\tTrain Loss: 1.897702\n",
      "Train Epoch: 3 [53440/75750 (88%)]\tTrain Loss: 2.080556\n",
      "Train Epoch: 3 [53760/75750 (89%)]\tTrain Loss: 1.392951\n",
      "Train Epoch: 3 [54080/75750 (89%)]\tTrain Loss: 1.650891\n",
      "Train Epoch: 3 [54400/75750 (90%)]\tTrain Loss: 1.532042\n",
      "Train Epoch: 3 [54720/75750 (90%)]\tTrain Loss: 1.779926\n",
      "Train Epoch: 3 [55040/75750 (91%)]\tTrain Loss: 1.720074\n",
      "Train Epoch: 3 [55360/75750 (91%)]\tTrain Loss: 1.414983\n",
      "Train Epoch: 3 [55680/75750 (92%)]\tTrain Loss: 1.761446\n",
      "Train Epoch: 3 [56000/75750 (92%)]\tTrain Loss: 2.090829\n",
      "Train Epoch: 3 [56320/75750 (93%)]\tTrain Loss: 2.184173\n",
      "Train Epoch: 3 [56640/75750 (93%)]\tTrain Loss: 1.750746\n",
      "Train Epoch: 3 [56960/75750 (94%)]\tTrain Loss: 2.089738\n",
      "Train Epoch: 3 [57280/75750 (95%)]\tTrain Loss: 1.736565\n",
      "Train Epoch: 3 [57600/75750 (95%)]\tTrain Loss: 1.727956\n",
      "Train Epoch: 3 [57920/75750 (96%)]\tTrain Loss: 1.789777\n",
      "Train Epoch: 3 [58240/75750 (96%)]\tTrain Loss: 2.116721\n",
      "Train Epoch: 3 [58560/75750 (97%)]\tTrain Loss: 1.384563\n",
      "Train Epoch: 3 [58880/75750 (97%)]\tTrain Loss: 1.754667\n",
      "Train Epoch: 3 [59200/75750 (98%)]\tTrain Loss: 1.502511\n",
      "Train Epoch: 3 [59520/75750 (98%)]\tTrain Loss: 1.845283\n",
      "Train Epoch: 3 [59840/75750 (99%)]\tTrain Loss: 1.855562\n",
      "Train Epoch: 3 [60160/75750 (99%)]\tTrain Loss: 1.912825\n",
      "Train Epoch: 3 [60480/75750 (100%)]\tTrain Loss: 1.797392\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.7007, \tTest Accuracy: 43.93 % \n",
      "\n",
      "Train Epoch: 4 [0/75750 (0%)]\tTrain Loss: 1.538570\n",
      "Train Epoch: 4 [320/75750 (1%)]\tTrain Loss: 1.992236\n",
      "Train Epoch: 4 [640/75750 (1%)]\tTrain Loss: 1.216957\n",
      "Train Epoch: 4 [960/75750 (2%)]\tTrain Loss: 1.162575\n",
      "Train Epoch: 4 [1280/75750 (2%)]\tTrain Loss: 1.441336\n",
      "Train Epoch: 4 [1600/75750 (3%)]\tTrain Loss: 1.656971\n",
      "Train Epoch: 4 [1920/75750 (3%)]\tTrain Loss: 2.251309\n",
      "Train Epoch: 4 [2240/75750 (4%)]\tTrain Loss: 1.841768\n",
      "Train Epoch: 4 [2560/75750 (4%)]\tTrain Loss: 1.833605\n",
      "Train Epoch: 4 [2880/75750 (5%)]\tTrain Loss: 1.459502\n",
      "Train Epoch: 4 [3200/75750 (5%)]\tTrain Loss: 1.340382\n",
      "Train Epoch: 4 [3520/75750 (6%)]\tTrain Loss: 1.457782\n",
      "Train Epoch: 4 [3840/75750 (6%)]\tTrain Loss: 1.628995\n",
      "Train Epoch: 4 [4160/75750 (7%)]\tTrain Loss: 1.377300\n",
      "Train Epoch: 4 [4480/75750 (7%)]\tTrain Loss: 1.937345\n",
      "Train Epoch: 4 [4800/75750 (8%)]\tTrain Loss: 1.257223\n",
      "Train Epoch: 4 [5120/75750 (8%)]\tTrain Loss: 1.472250\n",
      "Train Epoch: 4 [5440/75750 (9%)]\tTrain Loss: 1.798496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [5760/75750 (10%)]\tTrain Loss: 1.597026\n",
      "Train Epoch: 4 [6080/75750 (10%)]\tTrain Loss: 1.633992\n",
      "Train Epoch: 4 [6400/75750 (11%)]\tTrain Loss: 1.420391\n",
      "Train Epoch: 4 [6720/75750 (11%)]\tTrain Loss: 1.537864\n",
      "Train Epoch: 4 [7040/75750 (12%)]\tTrain Loss: 1.284762\n",
      "Train Epoch: 4 [7360/75750 (12%)]\tTrain Loss: 1.430120\n",
      "Train Epoch: 4 [7680/75750 (13%)]\tTrain Loss: 1.399126\n",
      "Train Epoch: 4 [8000/75750 (13%)]\tTrain Loss: 2.116316\n",
      "Train Epoch: 4 [8320/75750 (14%)]\tTrain Loss: 1.649486\n",
      "Train Epoch: 4 [8640/75750 (14%)]\tTrain Loss: 1.706767\n",
      "Train Epoch: 4 [8960/75750 (15%)]\tTrain Loss: 1.505720\n",
      "Train Epoch: 4 [9280/75750 (15%)]\tTrain Loss: 1.429885\n",
      "Train Epoch: 4 [9600/75750 (16%)]\tTrain Loss: 1.511502\n",
      "Train Epoch: 4 [9920/75750 (16%)]\tTrain Loss: 1.539268\n",
      "Train Epoch: 4 [10240/75750 (17%)]\tTrain Loss: 1.550983\n",
      "Train Epoch: 4 [10560/75750 (17%)]\tTrain Loss: 1.690538\n",
      "Train Epoch: 4 [10880/75750 (18%)]\tTrain Loss: 1.651629\n",
      "Train Epoch: 4 [11200/75750 (18%)]\tTrain Loss: 1.636785\n",
      "Train Epoch: 4 [11520/75750 (19%)]\tTrain Loss: 1.771404\n",
      "Train Epoch: 4 [11840/75750 (20%)]\tTrain Loss: 1.501288\n",
      "Train Epoch: 4 [12160/75750 (20%)]\tTrain Loss: 1.355949\n",
      "Train Epoch: 4 [12480/75750 (21%)]\tTrain Loss: 2.124611\n",
      "Train Epoch: 4 [12800/75750 (21%)]\tTrain Loss: 1.221314\n",
      "Train Epoch: 4 [13120/75750 (22%)]\tTrain Loss: 1.632927\n",
      "Train Epoch: 4 [13440/75750 (22%)]\tTrain Loss: 1.370244\n",
      "Train Epoch: 4 [13760/75750 (23%)]\tTrain Loss: 1.610099\n",
      "Train Epoch: 4 [14080/75750 (23%)]\tTrain Loss: 1.468580\n",
      "Train Epoch: 4 [14400/75750 (24%)]\tTrain Loss: 1.350521\n",
      "Train Epoch: 4 [14720/75750 (24%)]\tTrain Loss: 1.637007\n",
      "Train Epoch: 4 [15040/75750 (25%)]\tTrain Loss: 1.478950\n",
      "Train Epoch: 4 [15360/75750 (25%)]\tTrain Loss: 1.115806\n",
      "Train Epoch: 4 [15680/75750 (26%)]\tTrain Loss: 1.533284\n",
      "Train Epoch: 4 [16000/75750 (26%)]\tTrain Loss: 1.944938\n",
      "Train Epoch: 4 [16320/75750 (27%)]\tTrain Loss: 1.812448\n",
      "Train Epoch: 4 [16640/75750 (27%)]\tTrain Loss: 1.519061\n",
      "Train Epoch: 4 [16960/75750 (28%)]\tTrain Loss: 2.048345\n",
      "Train Epoch: 4 [17280/75750 (29%)]\tTrain Loss: 1.572969\n",
      "Train Epoch: 4 [17600/75750 (29%)]\tTrain Loss: 1.523645\n",
      "Train Epoch: 4 [17920/75750 (30%)]\tTrain Loss: 1.344682\n",
      "Train Epoch: 4 [18240/75750 (30%)]\tTrain Loss: 1.288917\n",
      "Train Epoch: 4 [18560/75750 (31%)]\tTrain Loss: 1.714477\n",
      "Train Epoch: 4 [18880/75750 (31%)]\tTrain Loss: 1.585121\n",
      "Train Epoch: 4 [19200/75750 (32%)]\tTrain Loss: 1.606328\n",
      "Train Epoch: 4 [19520/75750 (32%)]\tTrain Loss: 1.526788\n",
      "Train Epoch: 4 [19840/75750 (33%)]\tTrain Loss: 1.322829\n",
      "Train Epoch: 4 [20160/75750 (33%)]\tTrain Loss: 1.627614\n",
      "Train Epoch: 4 [20480/75750 (34%)]\tTrain Loss: 1.914328\n",
      "Train Epoch: 4 [20800/75750 (34%)]\tTrain Loss: 1.551107\n",
      "Train Epoch: 4 [21120/75750 (35%)]\tTrain Loss: 1.649559\n",
      "Train Epoch: 4 [21440/75750 (35%)]\tTrain Loss: 1.518305\n",
      "Train Epoch: 4 [21760/75750 (36%)]\tTrain Loss: 1.521214\n",
      "Train Epoch: 4 [22080/75750 (36%)]\tTrain Loss: 1.513948\n",
      "Train Epoch: 4 [22400/75750 (37%)]\tTrain Loss: 1.502606\n",
      "Train Epoch: 4 [22720/75750 (37%)]\tTrain Loss: 1.807434\n",
      "Train Epoch: 4 [23040/75750 (38%)]\tTrain Loss: 1.467299\n",
      "Train Epoch: 4 [23360/75750 (39%)]\tTrain Loss: 1.571747\n",
      "Train Epoch: 4 [23680/75750 (39%)]\tTrain Loss: 1.774655\n",
      "Train Epoch: 4 [24000/75750 (40%)]\tTrain Loss: 1.791598\n",
      "Train Epoch: 4 [24320/75750 (40%)]\tTrain Loss: 1.683753\n",
      "Train Epoch: 4 [24640/75750 (41%)]\tTrain Loss: 1.580392\n",
      "Train Epoch: 4 [24960/75750 (41%)]\tTrain Loss: 1.269334\n",
      "Train Epoch: 4 [25280/75750 (42%)]\tTrain Loss: 2.030619\n",
      "Train Epoch: 4 [25600/75750 (42%)]\tTrain Loss: 1.882053\n",
      "Train Epoch: 4 [25920/75750 (43%)]\tTrain Loss: 2.238978\n",
      "Train Epoch: 4 [26240/75750 (43%)]\tTrain Loss: 1.864198\n",
      "Train Epoch: 4 [26560/75750 (44%)]\tTrain Loss: 1.415999\n",
      "Train Epoch: 4 [26880/75750 (44%)]\tTrain Loss: 1.947101\n",
      "Train Epoch: 4 [27200/75750 (45%)]\tTrain Loss: 1.517568\n",
      "Train Epoch: 4 [27520/75750 (45%)]\tTrain Loss: 1.497928\n",
      "Train Epoch: 4 [27840/75750 (46%)]\tTrain Loss: 1.554420\n",
      "Train Epoch: 4 [28160/75750 (46%)]\tTrain Loss: 1.500983\n",
      "Train Epoch: 4 [28480/75750 (47%)]\tTrain Loss: 1.470210\n",
      "Train Epoch: 4 [28800/75750 (48%)]\tTrain Loss: 1.511146\n",
      "Train Epoch: 4 [29120/75750 (48%)]\tTrain Loss: 1.624435\n",
      "Train Epoch: 4 [29440/75750 (49%)]\tTrain Loss: 1.668941\n",
      "Train Epoch: 4 [29760/75750 (49%)]\tTrain Loss: 1.655005\n",
      "Train Epoch: 4 [30080/75750 (50%)]\tTrain Loss: 1.321223\n",
      "Train Epoch: 4 [30400/75750 (50%)]\tTrain Loss: 1.483768\n",
      "Train Epoch: 4 [30720/75750 (51%)]\tTrain Loss: 2.178793\n",
      "Train Epoch: 4 [31040/75750 (51%)]\tTrain Loss: 1.591294\n",
      "Train Epoch: 4 [31360/75750 (52%)]\tTrain Loss: 1.603254\n",
      "Train Epoch: 4 [31680/75750 (52%)]\tTrain Loss: 1.883106\n",
      "Train Epoch: 4 [32000/75750 (53%)]\tTrain Loss: 1.747701\n",
      "Train Epoch: 4 [32320/75750 (53%)]\tTrain Loss: 1.944589\n",
      "Train Epoch: 4 [32640/75750 (54%)]\tTrain Loss: 1.836767\n",
      "Train Epoch: 4 [32960/75750 (54%)]\tTrain Loss: 1.519082\n",
      "Train Epoch: 4 [33280/75750 (55%)]\tTrain Loss: 1.473637\n",
      "Train Epoch: 4 [33600/75750 (55%)]\tTrain Loss: 1.485478\n",
      "Train Epoch: 4 [33920/75750 (56%)]\tTrain Loss: 1.808137\n",
      "Train Epoch: 4 [34240/75750 (56%)]\tTrain Loss: 1.250039\n",
      "Train Epoch: 4 [34560/75750 (57%)]\tTrain Loss: 1.524133\n",
      "Train Epoch: 4 [34880/75750 (58%)]\tTrain Loss: 1.676368\n",
      "Train Epoch: 4 [35200/75750 (58%)]\tTrain Loss: 1.240970\n",
      "Train Epoch: 4 [35520/75750 (59%)]\tTrain Loss: 1.637469\n",
      "Train Epoch: 4 [35840/75750 (59%)]\tTrain Loss: 1.514444\n",
      "Train Epoch: 4 [36160/75750 (60%)]\tTrain Loss: 1.462718\n",
      "Train Epoch: 4 [36480/75750 (60%)]\tTrain Loss: 1.724118\n",
      "Train Epoch: 4 [36800/75750 (61%)]\tTrain Loss: 1.881879\n",
      "Train Epoch: 4 [37120/75750 (61%)]\tTrain Loss: 1.726491\n",
      "Train Epoch: 4 [37440/75750 (62%)]\tTrain Loss: 1.669179\n",
      "Train Epoch: 4 [37760/75750 (62%)]\tTrain Loss: 1.599916\n",
      "Train Epoch: 4 [38080/75750 (63%)]\tTrain Loss: 1.528534\n",
      "Train Epoch: 4 [38400/75750 (63%)]\tTrain Loss: 1.365286\n",
      "Train Epoch: 4 [38720/75750 (64%)]\tTrain Loss: 1.776380\n",
      "Train Epoch: 4 [39040/75750 (64%)]\tTrain Loss: 1.135351\n",
      "Train Epoch: 4 [39360/75750 (65%)]\tTrain Loss: 1.532127\n",
      "Train Epoch: 4 [39680/75750 (65%)]\tTrain Loss: 1.227776\n",
      "Train Epoch: 4 [40000/75750 (66%)]\tTrain Loss: 1.306928\n",
      "Train Epoch: 4 [40320/75750 (67%)]\tTrain Loss: 1.978583\n",
      "Train Epoch: 4 [40640/75750 (67%)]\tTrain Loss: 1.792260\n",
      "Train Epoch: 4 [40960/75750 (68%)]\tTrain Loss: 1.864808\n",
      "Train Epoch: 4 [41280/75750 (68%)]\tTrain Loss: 1.514841\n",
      "Train Epoch: 4 [41600/75750 (69%)]\tTrain Loss: 1.649747\n",
      "Train Epoch: 4 [41920/75750 (69%)]\tTrain Loss: 1.156667\n",
      "Train Epoch: 4 [42240/75750 (70%)]\tTrain Loss: 1.367211\n",
      "Train Epoch: 4 [42560/75750 (70%)]\tTrain Loss: 1.678683\n",
      "Train Epoch: 4 [42880/75750 (71%)]\tTrain Loss: 1.848255\n",
      "Train Epoch: 4 [43200/75750 (71%)]\tTrain Loss: 1.550068\n",
      "Train Epoch: 4 [43520/75750 (72%)]\tTrain Loss: 1.739986\n",
      "Train Epoch: 4 [43840/75750 (72%)]\tTrain Loss: 1.947661\n",
      "Train Epoch: 4 [44160/75750 (73%)]\tTrain Loss: 1.978642\n",
      "Train Epoch: 4 [44480/75750 (73%)]\tTrain Loss: 1.733615\n",
      "Train Epoch: 4 [44800/75750 (74%)]\tTrain Loss: 1.979738\n",
      "Train Epoch: 4 [45120/75750 (74%)]\tTrain Loss: 1.551655\n",
      "Train Epoch: 4 [45440/75750 (75%)]\tTrain Loss: 1.501540\n",
      "Train Epoch: 4 [45760/75750 (76%)]\tTrain Loss: 1.424253\n",
      "Train Epoch: 4 [46080/75750 (76%)]\tTrain Loss: 1.427170\n",
      "Train Epoch: 4 [46400/75750 (77%)]\tTrain Loss: 1.394858\n",
      "Train Epoch: 4 [46720/75750 (77%)]\tTrain Loss: 1.508949\n",
      "Train Epoch: 4 [47040/75750 (78%)]\tTrain Loss: 1.303776\n",
      "Train Epoch: 4 [47360/75750 (78%)]\tTrain Loss: 1.364857\n",
      "Train Epoch: 4 [47680/75750 (79%)]\tTrain Loss: 1.239975\n",
      "Train Epoch: 4 [48000/75750 (79%)]\tTrain Loss: 1.532683\n",
      "Train Epoch: 4 [48320/75750 (80%)]\tTrain Loss: 1.489811\n",
      "Train Epoch: 4 [48640/75750 (80%)]\tTrain Loss: 1.169985\n",
      "Train Epoch: 4 [48960/75750 (81%)]\tTrain Loss: 1.565180\n",
      "Train Epoch: 4 [49280/75750 (81%)]\tTrain Loss: 1.584183\n",
      "Train Epoch: 4 [49600/75750 (82%)]\tTrain Loss: 1.674481\n",
      "Train Epoch: 4 [49920/75750 (82%)]\tTrain Loss: 1.703393\n",
      "Train Epoch: 4 [50240/75750 (83%)]\tTrain Loss: 1.685499\n",
      "Train Epoch: 4 [50560/75750 (83%)]\tTrain Loss: 1.318813\n",
      "Train Epoch: 4 [50880/75750 (84%)]\tTrain Loss: 1.244484\n",
      "Train Epoch: 4 [51200/75750 (84%)]\tTrain Loss: 1.436815\n",
      "Train Epoch: 4 [51520/75750 (85%)]\tTrain Loss: 1.567115\n",
      "Train Epoch: 4 [51840/75750 (86%)]\tTrain Loss: 1.554752\n",
      "Train Epoch: 4 [52160/75750 (86%)]\tTrain Loss: 1.189384\n",
      "Train Epoch: 4 [52480/75750 (87%)]\tTrain Loss: 1.393494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [52800/75750 (87%)]\tTrain Loss: 1.463577\n",
      "Train Epoch: 4 [53120/75750 (88%)]\tTrain Loss: 1.977104\n",
      "Train Epoch: 4 [53440/75750 (88%)]\tTrain Loss: 2.052598\n",
      "Train Epoch: 4 [53760/75750 (89%)]\tTrain Loss: 1.636942\n",
      "Train Epoch: 4 [54080/75750 (89%)]\tTrain Loss: 1.373030\n",
      "Train Epoch: 4 [54400/75750 (90%)]\tTrain Loss: 1.691872\n",
      "Train Epoch: 4 [54720/75750 (90%)]\tTrain Loss: 1.659047\n",
      "Train Epoch: 4 [55040/75750 (91%)]\tTrain Loss: 1.545114\n",
      "Train Epoch: 4 [55360/75750 (91%)]\tTrain Loss: 1.478342\n",
      "Train Epoch: 4 [55680/75750 (92%)]\tTrain Loss: 1.566396\n",
      "Train Epoch: 4 [56000/75750 (92%)]\tTrain Loss: 1.720609\n",
      "Train Epoch: 4 [56320/75750 (93%)]\tTrain Loss: 1.676268\n",
      "Train Epoch: 4 [56640/75750 (93%)]\tTrain Loss: 1.496093\n",
      "Train Epoch: 4 [56960/75750 (94%)]\tTrain Loss: 1.347609\n",
      "Train Epoch: 4 [57280/75750 (95%)]\tTrain Loss: 1.587018\n",
      "Train Epoch: 4 [57600/75750 (95%)]\tTrain Loss: 1.720910\n",
      "Train Epoch: 4 [57920/75750 (96%)]\tTrain Loss: 1.624772\n",
      "Train Epoch: 4 [58240/75750 (96%)]\tTrain Loss: 1.575401\n",
      "Train Epoch: 4 [58560/75750 (97%)]\tTrain Loss: 2.046453\n",
      "Train Epoch: 4 [58880/75750 (97%)]\tTrain Loss: 1.647611\n",
      "Train Epoch: 4 [59200/75750 (98%)]\tTrain Loss: 1.487619\n",
      "Train Epoch: 4 [59520/75750 (98%)]\tTrain Loss: 1.720046\n",
      "Train Epoch: 4 [59840/75750 (99%)]\tTrain Loss: 1.915268\n",
      "Train Epoch: 4 [60160/75750 (99%)]\tTrain Loss: 1.599369\n",
      "Train Epoch: 4 [60480/75750 (100%)]\tTrain Loss: 1.381883\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.5882, \tTest Accuracy: 48.77 % \n",
      "\n",
      "Train Epoch: 5 [0/75750 (0%)]\tTrain Loss: 1.357868\n",
      "Train Epoch: 5 [320/75750 (1%)]\tTrain Loss: 1.499893\n",
      "Train Epoch: 5 [640/75750 (1%)]\tTrain Loss: 1.150512\n",
      "Train Epoch: 5 [960/75750 (2%)]\tTrain Loss: 1.260598\n",
      "Train Epoch: 5 [1280/75750 (2%)]\tTrain Loss: 2.037985\n",
      "Train Epoch: 5 [1600/75750 (3%)]\tTrain Loss: 1.441502\n",
      "Train Epoch: 5 [1920/75750 (3%)]\tTrain Loss: 1.444732\n",
      "Train Epoch: 5 [2240/75750 (4%)]\tTrain Loss: 1.765125\n",
      "Train Epoch: 5 [2560/75750 (4%)]\tTrain Loss: 1.314262\n",
      "Train Epoch: 5 [2880/75750 (5%)]\tTrain Loss: 1.299634\n",
      "Train Epoch: 5 [3200/75750 (5%)]\tTrain Loss: 1.355298\n",
      "Train Epoch: 5 [3520/75750 (6%)]\tTrain Loss: 1.826175\n",
      "Train Epoch: 5 [3840/75750 (6%)]\tTrain Loss: 1.499151\n",
      "Train Epoch: 5 [4160/75750 (7%)]\tTrain Loss: 1.985358\n",
      "Train Epoch: 5 [4480/75750 (7%)]\tTrain Loss: 1.541047\n",
      "Train Epoch: 5 [4800/75750 (8%)]\tTrain Loss: 1.474361\n",
      "Train Epoch: 5 [5120/75750 (8%)]\tTrain Loss: 1.523685\n",
      "Train Epoch: 5 [5440/75750 (9%)]\tTrain Loss: 1.530578\n",
      "Train Epoch: 5 [5760/75750 (10%)]\tTrain Loss: 1.430338\n",
      "Train Epoch: 5 [6080/75750 (10%)]\tTrain Loss: 1.752851\n",
      "Train Epoch: 5 [6400/75750 (11%)]\tTrain Loss: 1.398145\n",
      "Train Epoch: 5 [6720/75750 (11%)]\tTrain Loss: 1.259970\n",
      "Train Epoch: 5 [7040/75750 (12%)]\tTrain Loss: 1.270480\n",
      "Train Epoch: 5 [7360/75750 (12%)]\tTrain Loss: 1.472810\n",
      "Train Epoch: 5 [7680/75750 (13%)]\tTrain Loss: 1.476925\n",
      "Train Epoch: 5 [8000/75750 (13%)]\tTrain Loss: 1.382144\n",
      "Train Epoch: 5 [8320/75750 (14%)]\tTrain Loss: 1.122903\n",
      "Train Epoch: 5 [8640/75750 (14%)]\tTrain Loss: 1.738127\n",
      "Train Epoch: 5 [8960/75750 (15%)]\tTrain Loss: 1.635475\n",
      "Train Epoch: 5 [9280/75750 (15%)]\tTrain Loss: 1.422482\n",
      "Train Epoch: 5 [9600/75750 (16%)]\tTrain Loss: 1.672196\n",
      "Train Epoch: 5 [9920/75750 (16%)]\tTrain Loss: 1.263203\n",
      "Train Epoch: 5 [10240/75750 (17%)]\tTrain Loss: 1.761025\n",
      "Train Epoch: 5 [10560/75750 (17%)]\tTrain Loss: 1.619868\n",
      "Train Epoch: 5 [10880/75750 (18%)]\tTrain Loss: 1.410818\n",
      "Train Epoch: 5 [11200/75750 (18%)]\tTrain Loss: 1.180017\n",
      "Train Epoch: 5 [11520/75750 (19%)]\tTrain Loss: 1.186697\n",
      "Train Epoch: 5 [11840/75750 (20%)]\tTrain Loss: 1.133074\n",
      "Train Epoch: 5 [12160/75750 (20%)]\tTrain Loss: 1.392209\n",
      "Train Epoch: 5 [12480/75750 (21%)]\tTrain Loss: 1.341678\n",
      "Train Epoch: 5 [12800/75750 (21%)]\tTrain Loss: 1.517138\n",
      "Train Epoch: 5 [13120/75750 (22%)]\tTrain Loss: 1.129249\n",
      "Train Epoch: 5 [13440/75750 (22%)]\tTrain Loss: 1.221267\n",
      "Train Epoch: 5 [13760/75750 (23%)]\tTrain Loss: 1.505126\n",
      "Train Epoch: 5 [14080/75750 (23%)]\tTrain Loss: 1.428800\n",
      "Train Epoch: 5 [14400/75750 (24%)]\tTrain Loss: 1.815568\n",
      "Train Epoch: 5 [14720/75750 (24%)]\tTrain Loss: 1.043246\n",
      "Train Epoch: 5 [15040/75750 (25%)]\tTrain Loss: 1.394575\n",
      "Train Epoch: 5 [15360/75750 (25%)]\tTrain Loss: 1.152167\n",
      "Train Epoch: 5 [15680/75750 (26%)]\tTrain Loss: 1.301459\n",
      "Train Epoch: 5 [16000/75750 (26%)]\tTrain Loss: 1.990999\n",
      "Train Epoch: 5 [16320/75750 (27%)]\tTrain Loss: 1.343676\n",
      "Train Epoch: 5 [16640/75750 (27%)]\tTrain Loss: 1.647604\n",
      "Train Epoch: 5 [16960/75750 (28%)]\tTrain Loss: 1.372881\n",
      "Train Epoch: 5 [17280/75750 (29%)]\tTrain Loss: 1.474724\n",
      "Train Epoch: 5 [17600/75750 (29%)]\tTrain Loss: 1.417959\n",
      "Train Epoch: 5 [17920/75750 (30%)]\tTrain Loss: 2.314394\n",
      "Train Epoch: 5 [18240/75750 (30%)]\tTrain Loss: 1.495132\n",
      "Train Epoch: 5 [18560/75750 (31%)]\tTrain Loss: 1.292687\n",
      "Train Epoch: 5 [18880/75750 (31%)]\tTrain Loss: 1.642143\n",
      "Train Epoch: 5 [19200/75750 (32%)]\tTrain Loss: 1.380126\n",
      "Train Epoch: 5 [19520/75750 (32%)]\tTrain Loss: 1.677176\n",
      "Train Epoch: 5 [19840/75750 (33%)]\tTrain Loss: 1.402467\n",
      "Train Epoch: 5 [20160/75750 (33%)]\tTrain Loss: 1.433908\n",
      "Train Epoch: 5 [20480/75750 (34%)]\tTrain Loss: 1.159223\n",
      "Train Epoch: 5 [20800/75750 (34%)]\tTrain Loss: 1.438788\n",
      "Train Epoch: 5 [21120/75750 (35%)]\tTrain Loss: 1.381707\n",
      "Train Epoch: 5 [21440/75750 (35%)]\tTrain Loss: 1.552647\n",
      "Train Epoch: 5 [21760/75750 (36%)]\tTrain Loss: 1.134263\n",
      "Train Epoch: 5 [22080/75750 (36%)]\tTrain Loss: 1.696809\n",
      "Train Epoch: 5 [22400/75750 (37%)]\tTrain Loss: 1.546982\n",
      "Train Epoch: 5 [22720/75750 (37%)]\tTrain Loss: 1.250304\n",
      "Train Epoch: 5 [23040/75750 (38%)]\tTrain Loss: 1.443992\n",
      "Train Epoch: 5 [23360/75750 (39%)]\tTrain Loss: 1.366999\n",
      "Train Epoch: 5 [23680/75750 (39%)]\tTrain Loss: 1.795802\n",
      "Train Epoch: 5 [24000/75750 (40%)]\tTrain Loss: 1.282322\n",
      "Train Epoch: 5 [24320/75750 (40%)]\tTrain Loss: 2.102385\n",
      "Train Epoch: 5 [24640/75750 (41%)]\tTrain Loss: 1.628718\n",
      "Train Epoch: 5 [24960/75750 (41%)]\tTrain Loss: 1.485680\n",
      "Train Epoch: 5 [25280/75750 (42%)]\tTrain Loss: 1.130571\n",
      "Train Epoch: 5 [25600/75750 (42%)]\tTrain Loss: 1.578590\n",
      "Train Epoch: 5 [25920/75750 (43%)]\tTrain Loss: 1.514875\n",
      "Train Epoch: 5 [26240/75750 (43%)]\tTrain Loss: 1.374362\n",
      "Train Epoch: 5 [26560/75750 (44%)]\tTrain Loss: 1.389359\n",
      "Train Epoch: 5 [26880/75750 (44%)]\tTrain Loss: 1.452081\n",
      "Train Epoch: 5 [27200/75750 (45%)]\tTrain Loss: 1.402114\n",
      "Train Epoch: 5 [27520/75750 (45%)]\tTrain Loss: 1.434661\n",
      "Train Epoch: 5 [27840/75750 (46%)]\tTrain Loss: 1.612244\n",
      "Train Epoch: 5 [28160/75750 (46%)]\tTrain Loss: 1.529923\n",
      "Train Epoch: 5 [28480/75750 (47%)]\tTrain Loss: 1.791807\n",
      "Train Epoch: 5 [28800/75750 (48%)]\tTrain Loss: 0.816739\n",
      "Train Epoch: 5 [29120/75750 (48%)]\tTrain Loss: 1.467233\n",
      "Train Epoch: 5 [29440/75750 (49%)]\tTrain Loss: 1.263017\n",
      "Train Epoch: 5 [29760/75750 (49%)]\tTrain Loss: 1.790675\n",
      "Train Epoch: 5 [30080/75750 (50%)]\tTrain Loss: 1.415771\n",
      "Train Epoch: 5 [30400/75750 (50%)]\tTrain Loss: 1.680929\n",
      "Train Epoch: 5 [30720/75750 (51%)]\tTrain Loss: 1.848864\n",
      "Train Epoch: 5 [31040/75750 (51%)]\tTrain Loss: 1.488686\n",
      "Train Epoch: 5 [31360/75750 (52%)]\tTrain Loss: 1.776582\n",
      "Train Epoch: 5 [31680/75750 (52%)]\tTrain Loss: 1.551788\n",
      "Train Epoch: 5 [32000/75750 (53%)]\tTrain Loss: 1.210265\n",
      "Train Epoch: 5 [32320/75750 (53%)]\tTrain Loss: 1.616144\n",
      "Train Epoch: 5 [32640/75750 (54%)]\tTrain Loss: 1.731836\n",
      "Train Epoch: 5 [32960/75750 (54%)]\tTrain Loss: 1.342775\n",
      "Train Epoch: 5 [33280/75750 (55%)]\tTrain Loss: 1.429214\n",
      "Train Epoch: 5 [33600/75750 (55%)]\tTrain Loss: 1.572469\n",
      "Train Epoch: 5 [33920/75750 (56%)]\tTrain Loss: 1.659708\n",
      "Train Epoch: 5 [34240/75750 (56%)]\tTrain Loss: 1.609226\n",
      "Train Epoch: 5 [34560/75750 (57%)]\tTrain Loss: 1.358618\n",
      "Train Epoch: 5 [34880/75750 (58%)]\tTrain Loss: 1.297379\n",
      "Train Epoch: 5 [35200/75750 (58%)]\tTrain Loss: 1.401687\n",
      "Train Epoch: 5 [35520/75750 (59%)]\tTrain Loss: 1.460616\n",
      "Train Epoch: 5 [35840/75750 (59%)]\tTrain Loss: 1.570012\n",
      "Train Epoch: 5 [36160/75750 (60%)]\tTrain Loss: 1.273268\n",
      "Train Epoch: 5 [36480/75750 (60%)]\tTrain Loss: 1.661086\n",
      "Train Epoch: 5 [36800/75750 (61%)]\tTrain Loss: 1.576818\n",
      "Train Epoch: 5 [37120/75750 (61%)]\tTrain Loss: 1.868210\n",
      "Train Epoch: 5 [37440/75750 (62%)]\tTrain Loss: 1.127462\n",
      "Train Epoch: 5 [37760/75750 (62%)]\tTrain Loss: 1.383942\n",
      "Train Epoch: 5 [38080/75750 (63%)]\tTrain Loss: 1.550886\n",
      "Train Epoch: 5 [38400/75750 (63%)]\tTrain Loss: 1.630638\n",
      "Train Epoch: 5 [38720/75750 (64%)]\tTrain Loss: 1.142050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [39040/75750 (64%)]\tTrain Loss: 1.536229\n",
      "Train Epoch: 5 [39360/75750 (65%)]\tTrain Loss: 1.558759\n",
      "Train Epoch: 5 [39680/75750 (65%)]\tTrain Loss: 1.228652\n",
      "Train Epoch: 5 [40000/75750 (66%)]\tTrain Loss: 1.380662\n",
      "Train Epoch: 5 [40320/75750 (67%)]\tTrain Loss: 1.218666\n",
      "Train Epoch: 5 [40640/75750 (67%)]\tTrain Loss: 1.322607\n",
      "Train Epoch: 5 [40960/75750 (68%)]\tTrain Loss: 1.379950\n",
      "Train Epoch: 5 [41280/75750 (68%)]\tTrain Loss: 1.334604\n",
      "Train Epoch: 5 [41600/75750 (69%)]\tTrain Loss: 1.606200\n",
      "Train Epoch: 5 [41920/75750 (69%)]\tTrain Loss: 1.425390\n",
      "Train Epoch: 5 [42240/75750 (70%)]\tTrain Loss: 1.434623\n",
      "Train Epoch: 5 [42560/75750 (70%)]\tTrain Loss: 1.422925\n",
      "Train Epoch: 5 [42880/75750 (71%)]\tTrain Loss: 1.167332\n",
      "Train Epoch: 5 [43200/75750 (71%)]\tTrain Loss: 1.026891\n",
      "Train Epoch: 5 [43520/75750 (72%)]\tTrain Loss: 1.895104\n",
      "Train Epoch: 5 [43840/75750 (72%)]\tTrain Loss: 1.721854\n",
      "Train Epoch: 5 [44160/75750 (73%)]\tTrain Loss: 1.241656\n",
      "Train Epoch: 5 [44480/75750 (73%)]\tTrain Loss: 1.349672\n",
      "Train Epoch: 5 [44800/75750 (74%)]\tTrain Loss: 1.871852\n",
      "Train Epoch: 5 [45120/75750 (74%)]\tTrain Loss: 1.448089\n",
      "Train Epoch: 5 [45440/75750 (75%)]\tTrain Loss: 1.417514\n",
      "Train Epoch: 5 [45760/75750 (76%)]\tTrain Loss: 1.330566\n",
      "Train Epoch: 5 [46080/75750 (76%)]\tTrain Loss: 1.348371\n",
      "Train Epoch: 5 [46400/75750 (77%)]\tTrain Loss: 1.343709\n",
      "Train Epoch: 5 [46720/75750 (77%)]\tTrain Loss: 1.223502\n",
      "Train Epoch: 5 [47040/75750 (78%)]\tTrain Loss: 1.389554\n",
      "Train Epoch: 5 [47360/75750 (78%)]\tTrain Loss: 1.728769\n",
      "Train Epoch: 5 [47680/75750 (79%)]\tTrain Loss: 1.764572\n",
      "Train Epoch: 5 [48000/75750 (79%)]\tTrain Loss: 1.338007\n",
      "Train Epoch: 5 [48320/75750 (80%)]\tTrain Loss: 1.375719\n",
      "Train Epoch: 5 [48640/75750 (80%)]\tTrain Loss: 1.593295\n",
      "Train Epoch: 5 [48960/75750 (81%)]\tTrain Loss: 1.412731\n",
      "Train Epoch: 5 [49280/75750 (81%)]\tTrain Loss: 1.258785\n",
      "Train Epoch: 5 [49600/75750 (82%)]\tTrain Loss: 1.715754\n",
      "Train Epoch: 5 [49920/75750 (82%)]\tTrain Loss: 1.534311\n",
      "Train Epoch: 5 [50240/75750 (83%)]\tTrain Loss: 1.694070\n",
      "Train Epoch: 5 [50560/75750 (83%)]\tTrain Loss: 1.503950\n",
      "Train Epoch: 5 [50880/75750 (84%)]\tTrain Loss: 1.662246\n",
      "Train Epoch: 5 [51200/75750 (84%)]\tTrain Loss: 1.545744\n",
      "Train Epoch: 5 [51520/75750 (85%)]\tTrain Loss: 1.450438\n",
      "Train Epoch: 5 [51840/75750 (86%)]\tTrain Loss: 1.539735\n",
      "Train Epoch: 5 [52160/75750 (86%)]\tTrain Loss: 1.419124\n",
      "Train Epoch: 5 [52480/75750 (87%)]\tTrain Loss: 1.606821\n",
      "Train Epoch: 5 [52800/75750 (87%)]\tTrain Loss: 1.144610\n",
      "Train Epoch: 5 [53120/75750 (88%)]\tTrain Loss: 1.595237\n",
      "Train Epoch: 5 [53440/75750 (88%)]\tTrain Loss: 1.770019\n",
      "Train Epoch: 5 [53760/75750 (89%)]\tTrain Loss: 1.551372\n",
      "Train Epoch: 5 [54080/75750 (89%)]\tTrain Loss: 1.690362\n",
      "Train Epoch: 5 [54400/75750 (90%)]\tTrain Loss: 1.264856\n",
      "Train Epoch: 5 [54720/75750 (90%)]\tTrain Loss: 1.182910\n",
      "Train Epoch: 5 [55040/75750 (91%)]\tTrain Loss: 1.340457\n",
      "Train Epoch: 5 [55360/75750 (91%)]\tTrain Loss: 1.505000\n",
      "Train Epoch: 5 [55680/75750 (92%)]\tTrain Loss: 1.807550\n",
      "Train Epoch: 5 [56000/75750 (92%)]\tTrain Loss: 1.501802\n",
      "Train Epoch: 5 [56320/75750 (93%)]\tTrain Loss: 1.642484\n",
      "Train Epoch: 5 [56640/75750 (93%)]\tTrain Loss: 1.380625\n",
      "Train Epoch: 5 [56960/75750 (94%)]\tTrain Loss: 1.540129\n",
      "Train Epoch: 5 [57280/75750 (95%)]\tTrain Loss: 1.358152\n",
      "Train Epoch: 5 [57600/75750 (95%)]\tTrain Loss: 1.462878\n",
      "Train Epoch: 5 [57920/75750 (96%)]\tTrain Loss: 1.527663\n",
      "Train Epoch: 5 [58240/75750 (96%)]\tTrain Loss: 1.134870\n",
      "Train Epoch: 5 [58560/75750 (97%)]\tTrain Loss: 1.559056\n",
      "Train Epoch: 5 [58880/75750 (97%)]\tTrain Loss: 1.872996\n",
      "Train Epoch: 5 [59200/75750 (98%)]\tTrain Loss: 1.492752\n",
      "Train Epoch: 5 [59520/75750 (98%)]\tTrain Loss: 1.192759\n",
      "Train Epoch: 5 [59840/75750 (99%)]\tTrain Loss: 1.495764\n",
      "Train Epoch: 5 [60160/75750 (99%)]\tTrain Loss: 1.375854\n",
      "Train Epoch: 5 [60480/75750 (100%)]\tTrain Loss: 1.297201\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.5789, \tTest Accuracy: 49.45 % \n",
      "\n",
      "Train Epoch: 6 [0/75750 (0%)]\tTrain Loss: 1.532182\n",
      "Train Epoch: 6 [320/75750 (1%)]\tTrain Loss: 1.546764\n",
      "Train Epoch: 6 [640/75750 (1%)]\tTrain Loss: 1.052481\n",
      "Train Epoch: 6 [960/75750 (2%)]\tTrain Loss: 1.172074\n",
      "Train Epoch: 6 [1280/75750 (2%)]\tTrain Loss: 0.910360\n",
      "Train Epoch: 6 [1600/75750 (3%)]\tTrain Loss: 1.226237\n",
      "Train Epoch: 6 [1920/75750 (3%)]\tTrain Loss: 1.382427\n",
      "Train Epoch: 6 [2240/75750 (4%)]\tTrain Loss: 0.982249\n",
      "Train Epoch: 6 [2560/75750 (4%)]\tTrain Loss: 0.992676\n",
      "Train Epoch: 6 [2880/75750 (5%)]\tTrain Loss: 1.832231\n",
      "Train Epoch: 6 [3200/75750 (5%)]\tTrain Loss: 1.225437\n",
      "Train Epoch: 6 [3520/75750 (6%)]\tTrain Loss: 1.382528\n",
      "Train Epoch: 6 [3840/75750 (6%)]\tTrain Loss: 1.232240\n",
      "Train Epoch: 6 [4160/75750 (7%)]\tTrain Loss: 1.203724\n",
      "Train Epoch: 6 [4480/75750 (7%)]\tTrain Loss: 1.288331\n",
      "Train Epoch: 6 [4800/75750 (8%)]\tTrain Loss: 1.105600\n",
      "Train Epoch: 6 [5120/75750 (8%)]\tTrain Loss: 1.260249\n",
      "Train Epoch: 6 [5440/75750 (9%)]\tTrain Loss: 1.295946\n",
      "Train Epoch: 6 [5760/75750 (10%)]\tTrain Loss: 1.766356\n",
      "Train Epoch: 6 [6080/75750 (10%)]\tTrain Loss: 1.456391\n",
      "Train Epoch: 6 [6400/75750 (11%)]\tTrain Loss: 1.308446\n",
      "Train Epoch: 6 [6720/75750 (11%)]\tTrain Loss: 1.260917\n",
      "Train Epoch: 6 [7040/75750 (12%)]\tTrain Loss: 0.726582\n",
      "Train Epoch: 6 [7360/75750 (12%)]\tTrain Loss: 1.710872\n",
      "Train Epoch: 6 [7680/75750 (13%)]\tTrain Loss: 1.484270\n",
      "Train Epoch: 6 [8000/75750 (13%)]\tTrain Loss: 1.560506\n",
      "Train Epoch: 6 [8320/75750 (14%)]\tTrain Loss: 1.572521\n",
      "Train Epoch: 6 [8640/75750 (14%)]\tTrain Loss: 1.338082\n",
      "Train Epoch: 6 [8960/75750 (15%)]\tTrain Loss: 1.064163\n",
      "Train Epoch: 6 [9280/75750 (15%)]\tTrain Loss: 1.282801\n",
      "Train Epoch: 6 [9600/75750 (16%)]\tTrain Loss: 1.542789\n",
      "Train Epoch: 6 [9920/75750 (16%)]\tTrain Loss: 1.591202\n",
      "Train Epoch: 6 [10240/75750 (17%)]\tTrain Loss: 1.452773\n",
      "Train Epoch: 6 [10560/75750 (17%)]\tTrain Loss: 1.437633\n",
      "Train Epoch: 6 [10880/75750 (18%)]\tTrain Loss: 1.313329\n",
      "Train Epoch: 6 [11200/75750 (18%)]\tTrain Loss: 1.571465\n",
      "Train Epoch: 6 [11520/75750 (19%)]\tTrain Loss: 1.550772\n",
      "Train Epoch: 6 [11840/75750 (20%)]\tTrain Loss: 1.258382\n",
      "Train Epoch: 6 [12160/75750 (20%)]\tTrain Loss: 1.270552\n",
      "Train Epoch: 6 [12480/75750 (21%)]\tTrain Loss: 1.373535\n",
      "Train Epoch: 6 [12800/75750 (21%)]\tTrain Loss: 1.272943\n",
      "Train Epoch: 6 [13120/75750 (22%)]\tTrain Loss: 1.281969\n",
      "Train Epoch: 6 [13440/75750 (22%)]\tTrain Loss: 1.250533\n",
      "Train Epoch: 6 [13760/75750 (23%)]\tTrain Loss: 1.170906\n",
      "Train Epoch: 6 [14080/75750 (23%)]\tTrain Loss: 1.191810\n",
      "Train Epoch: 6 [14400/75750 (24%)]\tTrain Loss: 1.218724\n",
      "Train Epoch: 6 [14720/75750 (24%)]\tTrain Loss: 1.404003\n",
      "Train Epoch: 6 [15040/75750 (25%)]\tTrain Loss: 1.776049\n",
      "Train Epoch: 6 [15360/75750 (25%)]\tTrain Loss: 1.314778\n",
      "Train Epoch: 6 [15680/75750 (26%)]\tTrain Loss: 1.694792\n",
      "Train Epoch: 6 [16000/75750 (26%)]\tTrain Loss: 1.389862\n",
      "Train Epoch: 6 [16320/75750 (27%)]\tTrain Loss: 1.393443\n",
      "Train Epoch: 6 [16640/75750 (27%)]\tTrain Loss: 1.292532\n",
      "Train Epoch: 6 [16960/75750 (28%)]\tTrain Loss: 1.315438\n",
      "Train Epoch: 6 [17280/75750 (29%)]\tTrain Loss: 0.896844\n",
      "Train Epoch: 6 [17600/75750 (29%)]\tTrain Loss: 1.269377\n",
      "Train Epoch: 6 [17920/75750 (30%)]\tTrain Loss: 1.227629\n",
      "Train Epoch: 6 [18240/75750 (30%)]\tTrain Loss: 1.287678\n",
      "Train Epoch: 6 [18560/75750 (31%)]\tTrain Loss: 1.138927\n",
      "Train Epoch: 6 [18880/75750 (31%)]\tTrain Loss: 1.143988\n",
      "Train Epoch: 6 [19200/75750 (32%)]\tTrain Loss: 1.529203\n",
      "Train Epoch: 6 [19520/75750 (32%)]\tTrain Loss: 1.362711\n",
      "Train Epoch: 6 [19840/75750 (33%)]\tTrain Loss: 1.388080\n",
      "Train Epoch: 6 [20160/75750 (33%)]\tTrain Loss: 1.227544\n",
      "Train Epoch: 6 [20480/75750 (34%)]\tTrain Loss: 1.309592\n",
      "Train Epoch: 6 [20800/75750 (34%)]\tTrain Loss: 1.558758\n",
      "Train Epoch: 6 [21120/75750 (35%)]\tTrain Loss: 1.412947\n",
      "Train Epoch: 6 [21440/75750 (35%)]\tTrain Loss: 1.992280\n",
      "Train Epoch: 6 [21760/75750 (36%)]\tTrain Loss: 1.120224\n",
      "Train Epoch: 6 [22080/75750 (36%)]\tTrain Loss: 1.294877\n",
      "Train Epoch: 6 [22400/75750 (37%)]\tTrain Loss: 1.218146\n",
      "Train Epoch: 6 [22720/75750 (37%)]\tTrain Loss: 1.513406\n",
      "Train Epoch: 6 [23040/75750 (38%)]\tTrain Loss: 1.240954\n",
      "Train Epoch: 6 [23360/75750 (39%)]\tTrain Loss: 1.486568\n",
      "Train Epoch: 6 [23680/75750 (39%)]\tTrain Loss: 1.354479\n",
      "Train Epoch: 6 [24000/75750 (40%)]\tTrain Loss: 1.252582\n",
      "Train Epoch: 6 [24320/75750 (40%)]\tTrain Loss: 1.490419\n",
      "Train Epoch: 6 [24640/75750 (41%)]\tTrain Loss: 1.365644\n",
      "Train Epoch: 6 [24960/75750 (41%)]\tTrain Loss: 1.309830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [25280/75750 (42%)]\tTrain Loss: 1.627579\n",
      "Train Epoch: 6 [25600/75750 (42%)]\tTrain Loss: 1.548295\n",
      "Train Epoch: 6 [25920/75750 (43%)]\tTrain Loss: 1.387530\n",
      "Train Epoch: 6 [26240/75750 (43%)]\tTrain Loss: 1.250389\n",
      "Train Epoch: 6 [26560/75750 (44%)]\tTrain Loss: 1.049291\n",
      "Train Epoch: 6 [26880/75750 (44%)]\tTrain Loss: 1.099942\n",
      "Train Epoch: 6 [27200/75750 (45%)]\tTrain Loss: 1.326807\n",
      "Train Epoch: 6 [27520/75750 (45%)]\tTrain Loss: 0.797387\n",
      "Train Epoch: 6 [27840/75750 (46%)]\tTrain Loss: 1.474779\n",
      "Train Epoch: 6 [28160/75750 (46%)]\tTrain Loss: 1.562515\n",
      "Train Epoch: 6 [28480/75750 (47%)]\tTrain Loss: 1.334715\n",
      "Train Epoch: 6 [28800/75750 (48%)]\tTrain Loss: 1.297711\n",
      "Train Epoch: 6 [29120/75750 (48%)]\tTrain Loss: 1.588760\n",
      "Train Epoch: 6 [29440/75750 (49%)]\tTrain Loss: 1.512860\n",
      "Train Epoch: 6 [29760/75750 (49%)]\tTrain Loss: 1.040796\n",
      "Train Epoch: 6 [30080/75750 (50%)]\tTrain Loss: 1.413856\n",
      "Train Epoch: 6 [30400/75750 (50%)]\tTrain Loss: 1.417564\n",
      "Train Epoch: 6 [30720/75750 (51%)]\tTrain Loss: 1.173285\n",
      "Train Epoch: 6 [31040/75750 (51%)]\tTrain Loss: 1.105595\n",
      "Train Epoch: 6 [31360/75750 (52%)]\tTrain Loss: 1.364204\n",
      "Train Epoch: 6 [31680/75750 (52%)]\tTrain Loss: 1.244212\n",
      "Train Epoch: 6 [32000/75750 (53%)]\tTrain Loss: 1.498994\n",
      "Train Epoch: 6 [32320/75750 (53%)]\tTrain Loss: 1.366023\n",
      "Train Epoch: 6 [32640/75750 (54%)]\tTrain Loss: 1.568070\n",
      "Train Epoch: 6 [32960/75750 (54%)]\tTrain Loss: 1.285037\n",
      "Train Epoch: 6 [33280/75750 (55%)]\tTrain Loss: 1.348078\n",
      "Train Epoch: 6 [33600/75750 (55%)]\tTrain Loss: 1.178053\n",
      "Train Epoch: 6 [33920/75750 (56%)]\tTrain Loss: 1.427490\n",
      "Train Epoch: 6 [34240/75750 (56%)]\tTrain Loss: 1.480188\n",
      "Train Epoch: 6 [34560/75750 (57%)]\tTrain Loss: 1.462659\n",
      "Train Epoch: 6 [34880/75750 (58%)]\tTrain Loss: 1.584889\n",
      "Train Epoch: 6 [35200/75750 (58%)]\tTrain Loss: 1.014811\n",
      "Train Epoch: 6 [35520/75750 (59%)]\tTrain Loss: 1.395545\n",
      "Train Epoch: 6 [35840/75750 (59%)]\tTrain Loss: 1.241242\n",
      "Train Epoch: 6 [36160/75750 (60%)]\tTrain Loss: 1.484887\n",
      "Train Epoch: 6 [36480/75750 (60%)]\tTrain Loss: 1.088223\n",
      "Train Epoch: 6 [36800/75750 (61%)]\tTrain Loss: 1.367846\n",
      "Train Epoch: 6 [37120/75750 (61%)]\tTrain Loss: 1.117146\n",
      "Train Epoch: 6 [37440/75750 (62%)]\tTrain Loss: 1.315508\n",
      "Train Epoch: 6 [37760/75750 (62%)]\tTrain Loss: 1.406478\n",
      "Train Epoch: 6 [38080/75750 (63%)]\tTrain Loss: 1.631465\n",
      "Train Epoch: 6 [38400/75750 (63%)]\tTrain Loss: 1.341195\n",
      "Train Epoch: 6 [38720/75750 (64%)]\tTrain Loss: 1.754550\n",
      "Train Epoch: 6 [39040/75750 (64%)]\tTrain Loss: 1.434288\n",
      "Train Epoch: 6 [39360/75750 (65%)]\tTrain Loss: 1.628115\n",
      "Train Epoch: 6 [39680/75750 (65%)]\tTrain Loss: 1.161890\n",
      "Train Epoch: 6 [40000/75750 (66%)]\tTrain Loss: 1.360157\n",
      "Train Epoch: 6 [40320/75750 (67%)]\tTrain Loss: 1.182184\n",
      "Train Epoch: 6 [40640/75750 (67%)]\tTrain Loss: 0.980407\n",
      "Train Epoch: 6 [40960/75750 (68%)]\tTrain Loss: 1.133676\n",
      "Train Epoch: 6 [41280/75750 (68%)]\tTrain Loss: 1.272697\n",
      "Train Epoch: 6 [41600/75750 (69%)]\tTrain Loss: 1.274174\n",
      "Train Epoch: 6 [41920/75750 (69%)]\tTrain Loss: 1.177475\n",
      "Train Epoch: 6 [42240/75750 (70%)]\tTrain Loss: 1.507005\n",
      "Train Epoch: 6 [42560/75750 (70%)]\tTrain Loss: 1.371028\n",
      "Train Epoch: 6 [42880/75750 (71%)]\tTrain Loss: 1.486420\n",
      "Train Epoch: 6 [43200/75750 (71%)]\tTrain Loss: 1.219294\n",
      "Train Epoch: 6 [43520/75750 (72%)]\tTrain Loss: 1.867310\n",
      "Train Epoch: 6 [43840/75750 (72%)]\tTrain Loss: 1.356634\n",
      "Train Epoch: 6 [44160/75750 (73%)]\tTrain Loss: 1.631408\n",
      "Train Epoch: 6 [44480/75750 (73%)]\tTrain Loss: 1.549708\n",
      "Train Epoch: 6 [44800/75750 (74%)]\tTrain Loss: 1.442986\n",
      "Train Epoch: 6 [45120/75750 (74%)]\tTrain Loss: 1.592952\n",
      "Train Epoch: 6 [45440/75750 (75%)]\tTrain Loss: 1.307697\n",
      "Train Epoch: 6 [45760/75750 (76%)]\tTrain Loss: 1.704963\n",
      "Train Epoch: 6 [46080/75750 (76%)]\tTrain Loss: 1.226988\n",
      "Train Epoch: 6 [46400/75750 (77%)]\tTrain Loss: 1.442081\n",
      "Train Epoch: 6 [46720/75750 (77%)]\tTrain Loss: 1.596727\n",
      "Train Epoch: 6 [47040/75750 (78%)]\tTrain Loss: 1.287919\n",
      "Train Epoch: 6 [47360/75750 (78%)]\tTrain Loss: 1.407568\n",
      "Train Epoch: 6 [47680/75750 (79%)]\tTrain Loss: 1.809662\n",
      "Train Epoch: 6 [48000/75750 (79%)]\tTrain Loss: 1.273229\n",
      "Train Epoch: 6 [48320/75750 (80%)]\tTrain Loss: 1.053694\n",
      "Train Epoch: 6 [48640/75750 (80%)]\tTrain Loss: 1.392888\n",
      "Train Epoch: 6 [48960/75750 (81%)]\tTrain Loss: 1.012555\n",
      "Train Epoch: 6 [49280/75750 (81%)]\tTrain Loss: 1.083179\n",
      "Train Epoch: 6 [49600/75750 (82%)]\tTrain Loss: 1.706725\n",
      "Train Epoch: 6 [49920/75750 (82%)]\tTrain Loss: 1.245031\n",
      "Train Epoch: 6 [50240/75750 (83%)]\tTrain Loss: 1.174156\n",
      "Train Epoch: 6 [50560/75750 (83%)]\tTrain Loss: 1.799052\n",
      "Train Epoch: 6 [50880/75750 (84%)]\tTrain Loss: 1.105051\n",
      "Train Epoch: 6 [51200/75750 (84%)]\tTrain Loss: 1.658725\n",
      "Train Epoch: 6 [51520/75750 (85%)]\tTrain Loss: 1.202911\n",
      "Train Epoch: 6 [51840/75750 (86%)]\tTrain Loss: 1.269155\n",
      "Train Epoch: 6 [52160/75750 (86%)]\tTrain Loss: 1.166988\n",
      "Train Epoch: 6 [52480/75750 (87%)]\tTrain Loss: 1.690818\n",
      "Train Epoch: 6 [52800/75750 (87%)]\tTrain Loss: 1.373899\n",
      "Train Epoch: 6 [53120/75750 (88%)]\tTrain Loss: 1.270669\n",
      "Train Epoch: 6 [53440/75750 (88%)]\tTrain Loss: 1.126010\n",
      "Train Epoch: 6 [53760/75750 (89%)]\tTrain Loss: 1.207673\n",
      "Train Epoch: 6 [54080/75750 (89%)]\tTrain Loss: 1.251240\n",
      "Train Epoch: 6 [54400/75750 (90%)]\tTrain Loss: 1.509848\n",
      "Train Epoch: 6 [54720/75750 (90%)]\tTrain Loss: 1.642182\n",
      "Train Epoch: 6 [55040/75750 (91%)]\tTrain Loss: 1.566622\n",
      "Train Epoch: 6 [55360/75750 (91%)]\tTrain Loss: 1.337058\n",
      "Train Epoch: 6 [55680/75750 (92%)]\tTrain Loss: 1.707937\n",
      "Train Epoch: 6 [56000/75750 (92%)]\tTrain Loss: 1.837232\n",
      "Train Epoch: 6 [56320/75750 (93%)]\tTrain Loss: 1.458124\n",
      "Train Epoch: 6 [56640/75750 (93%)]\tTrain Loss: 1.310411\n",
      "Train Epoch: 6 [56960/75750 (94%)]\tTrain Loss: 1.436474\n",
      "Train Epoch: 6 [57280/75750 (95%)]\tTrain Loss: 1.249799\n",
      "Train Epoch: 6 [57600/75750 (95%)]\tTrain Loss: 1.141661\n",
      "Train Epoch: 6 [57920/75750 (96%)]\tTrain Loss: 1.682719\n",
      "Train Epoch: 6 [58240/75750 (96%)]\tTrain Loss: 1.235674\n",
      "Train Epoch: 6 [58560/75750 (97%)]\tTrain Loss: 1.061470\n",
      "Train Epoch: 6 [58880/75750 (97%)]\tTrain Loss: 1.381742\n",
      "Train Epoch: 6 [59200/75750 (98%)]\tTrain Loss: 1.666247\n",
      "Train Epoch: 6 [59520/75750 (98%)]\tTrain Loss: 1.330401\n",
      "Train Epoch: 6 [59840/75750 (99%)]\tTrain Loss: 1.192862\n",
      "Train Epoch: 6 [60160/75750 (99%)]\tTrain Loss: 1.366346\n",
      "Train Epoch: 6 [60480/75750 (100%)]\tTrain Loss: 1.482245\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.4876, \tTest Accuracy: 53.55 % \n",
      "\n",
      "Train Epoch: 7 [0/75750 (0%)]\tTrain Loss: 1.130561\n",
      "Train Epoch: 7 [320/75750 (1%)]\tTrain Loss: 1.464984\n",
      "Train Epoch: 7 [640/75750 (1%)]\tTrain Loss: 0.848410\n",
      "Train Epoch: 7 [960/75750 (2%)]\tTrain Loss: 1.198574\n",
      "Train Epoch: 7 [1280/75750 (2%)]\tTrain Loss: 1.363195\n",
      "Train Epoch: 7 [1600/75750 (3%)]\tTrain Loss: 1.463794\n",
      "Train Epoch: 7 [1920/75750 (3%)]\tTrain Loss: 1.114869\n",
      "Train Epoch: 7 [2240/75750 (4%)]\tTrain Loss: 1.073597\n",
      "Train Epoch: 7 [2560/75750 (4%)]\tTrain Loss: 1.522757\n",
      "Train Epoch: 7 [2880/75750 (5%)]\tTrain Loss: 1.233281\n",
      "Train Epoch: 7 [3200/75750 (5%)]\tTrain Loss: 1.080322\n",
      "Train Epoch: 7 [3520/75750 (6%)]\tTrain Loss: 1.104289\n",
      "Train Epoch: 7 [3840/75750 (6%)]\tTrain Loss: 1.224053\n",
      "Train Epoch: 7 [4160/75750 (7%)]\tTrain Loss: 1.234714\n",
      "Train Epoch: 7 [4480/75750 (7%)]\tTrain Loss: 1.290083\n",
      "Train Epoch: 7 [4800/75750 (8%)]\tTrain Loss: 1.329962\n",
      "Train Epoch: 7 [5120/75750 (8%)]\tTrain Loss: 1.255291\n",
      "Train Epoch: 7 [5440/75750 (9%)]\tTrain Loss: 0.989656\n",
      "Train Epoch: 7 [5760/75750 (10%)]\tTrain Loss: 1.206829\n",
      "Train Epoch: 7 [6080/75750 (10%)]\tTrain Loss: 1.224614\n",
      "Train Epoch: 7 [6400/75750 (11%)]\tTrain Loss: 1.247064\n",
      "Train Epoch: 7 [6720/75750 (11%)]\tTrain Loss: 1.429286\n",
      "Train Epoch: 7 [7040/75750 (12%)]\tTrain Loss: 1.274751\n",
      "Train Epoch: 7 [7360/75750 (12%)]\tTrain Loss: 1.247586\n",
      "Train Epoch: 7 [7680/75750 (13%)]\tTrain Loss: 1.156472\n",
      "Train Epoch: 7 [8000/75750 (13%)]\tTrain Loss: 1.351518\n",
      "Train Epoch: 7 [8320/75750 (14%)]\tTrain Loss: 1.467611\n",
      "Train Epoch: 7 [8640/75750 (14%)]\tTrain Loss: 1.455109\n",
      "Train Epoch: 7 [8960/75750 (15%)]\tTrain Loss: 1.318977\n",
      "Train Epoch: 7 [9280/75750 (15%)]\tTrain Loss: 1.108786\n",
      "Train Epoch: 7 [9600/75750 (16%)]\tTrain Loss: 1.042314\n",
      "Train Epoch: 7 [9920/75750 (16%)]\tTrain Loss: 1.178440\n",
      "Train Epoch: 7 [10240/75750 (17%)]\tTrain Loss: 1.040675\n",
      "Train Epoch: 7 [10560/75750 (17%)]\tTrain Loss: 1.082768\n",
      "Train Epoch: 7 [10880/75750 (18%)]\tTrain Loss: 0.973205\n",
      "Train Epoch: 7 [11200/75750 (18%)]\tTrain Loss: 1.395620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [11520/75750 (19%)]\tTrain Loss: 1.026480\n",
      "Train Epoch: 7 [11840/75750 (20%)]\tTrain Loss: 1.199443\n",
      "Train Epoch: 7 [12160/75750 (20%)]\tTrain Loss: 1.664142\n",
      "Train Epoch: 7 [12480/75750 (21%)]\tTrain Loss: 1.106197\n",
      "Train Epoch: 7 [12800/75750 (21%)]\tTrain Loss: 1.507710\n",
      "Train Epoch: 7 [13120/75750 (22%)]\tTrain Loss: 1.743060\n",
      "Train Epoch: 7 [13440/75750 (22%)]\tTrain Loss: 1.290572\n",
      "Train Epoch: 7 [13760/75750 (23%)]\tTrain Loss: 1.349280\n",
      "Train Epoch: 7 [14080/75750 (23%)]\tTrain Loss: 1.421599\n",
      "Train Epoch: 7 [14400/75750 (24%)]\tTrain Loss: 1.376046\n",
      "Train Epoch: 7 [14720/75750 (24%)]\tTrain Loss: 1.189097\n",
      "Train Epoch: 7 [15040/75750 (25%)]\tTrain Loss: 0.989994\n",
      "Train Epoch: 7 [15360/75750 (25%)]\tTrain Loss: 1.055345\n",
      "Train Epoch: 7 [15680/75750 (26%)]\tTrain Loss: 1.269589\n",
      "Train Epoch: 7 [16000/75750 (26%)]\tTrain Loss: 1.315120\n",
      "Train Epoch: 7 [16320/75750 (27%)]\tTrain Loss: 0.911491\n",
      "Train Epoch: 7 [16640/75750 (27%)]\tTrain Loss: 1.613633\n",
      "Train Epoch: 7 [16960/75750 (28%)]\tTrain Loss: 1.369755\n",
      "Train Epoch: 7 [17280/75750 (29%)]\tTrain Loss: 1.157722\n",
      "Train Epoch: 7 [17600/75750 (29%)]\tTrain Loss: 1.364516\n",
      "Train Epoch: 7 [17920/75750 (30%)]\tTrain Loss: 1.272450\n",
      "Train Epoch: 7 [18240/75750 (30%)]\tTrain Loss: 1.260669\n",
      "Train Epoch: 7 [18560/75750 (31%)]\tTrain Loss: 1.183464\n",
      "Train Epoch: 7 [18880/75750 (31%)]\tTrain Loss: 1.333025\n",
      "Train Epoch: 7 [19200/75750 (32%)]\tTrain Loss: 1.225966\n",
      "Train Epoch: 7 [19520/75750 (32%)]\tTrain Loss: 1.494271\n",
      "Train Epoch: 7 [19840/75750 (33%)]\tTrain Loss: 1.239615\n",
      "Train Epoch: 7 [20160/75750 (33%)]\tTrain Loss: 1.234846\n",
      "Train Epoch: 7 [20480/75750 (34%)]\tTrain Loss: 1.401947\n",
      "Train Epoch: 7 [20800/75750 (34%)]\tTrain Loss: 1.440601\n",
      "Train Epoch: 7 [21120/75750 (35%)]\tTrain Loss: 1.243966\n",
      "Train Epoch: 7 [21440/75750 (35%)]\tTrain Loss: 1.218295\n",
      "Train Epoch: 7 [21760/75750 (36%)]\tTrain Loss: 1.529471\n",
      "Train Epoch: 7 [22080/75750 (36%)]\tTrain Loss: 1.324061\n",
      "Train Epoch: 7 [22400/75750 (37%)]\tTrain Loss: 1.276747\n",
      "Train Epoch: 7 [22720/75750 (37%)]\tTrain Loss: 1.738673\n",
      "Train Epoch: 7 [23040/75750 (38%)]\tTrain Loss: 1.503171\n",
      "Train Epoch: 7 [23360/75750 (39%)]\tTrain Loss: 1.143926\n",
      "Train Epoch: 7 [23680/75750 (39%)]\tTrain Loss: 1.479846\n",
      "Train Epoch: 7 [24000/75750 (40%)]\tTrain Loss: 1.179325\n",
      "Train Epoch: 7 [24320/75750 (40%)]\tTrain Loss: 1.231372\n",
      "Train Epoch: 7 [24640/75750 (41%)]\tTrain Loss: 0.917201\n",
      "Train Epoch: 7 [24960/75750 (41%)]\tTrain Loss: 1.118087\n",
      "Train Epoch: 7 [25280/75750 (42%)]\tTrain Loss: 1.356372\n",
      "Train Epoch: 7 [25600/75750 (42%)]\tTrain Loss: 1.553580\n",
      "Train Epoch: 7 [25920/75750 (43%)]\tTrain Loss: 1.493289\n",
      "Train Epoch: 7 [26240/75750 (43%)]\tTrain Loss: 1.220193\n",
      "Train Epoch: 7 [26560/75750 (44%)]\tTrain Loss: 1.323188\n",
      "Train Epoch: 7 [26880/75750 (44%)]\tTrain Loss: 1.536751\n",
      "Train Epoch: 7 [27200/75750 (45%)]\tTrain Loss: 1.071076\n",
      "Train Epoch: 7 [27520/75750 (45%)]\tTrain Loss: 1.244188\n",
      "Train Epoch: 7 [27840/75750 (46%)]\tTrain Loss: 1.182399\n",
      "Train Epoch: 7 [28160/75750 (46%)]\tTrain Loss: 0.876877\n",
      "Train Epoch: 7 [28480/75750 (47%)]\tTrain Loss: 1.345726\n",
      "Train Epoch: 7 [28800/75750 (48%)]\tTrain Loss: 1.277783\n",
      "Train Epoch: 7 [29120/75750 (48%)]\tTrain Loss: 1.280484\n",
      "Train Epoch: 7 [29440/75750 (49%)]\tTrain Loss: 1.118902\n",
      "Train Epoch: 7 [29760/75750 (49%)]\tTrain Loss: 1.438324\n",
      "Train Epoch: 7 [30080/75750 (50%)]\tTrain Loss: 1.526026\n",
      "Train Epoch: 7 [30400/75750 (50%)]\tTrain Loss: 1.564234\n",
      "Train Epoch: 7 [30720/75750 (51%)]\tTrain Loss: 0.959434\n",
      "Train Epoch: 7 [31040/75750 (51%)]\tTrain Loss: 1.326221\n",
      "Train Epoch: 7 [31360/75750 (52%)]\tTrain Loss: 1.390506\n",
      "Train Epoch: 7 [31680/75750 (52%)]\tTrain Loss: 1.165205\n",
      "Train Epoch: 7 [32000/75750 (53%)]\tTrain Loss: 1.315375\n",
      "Train Epoch: 7 [32320/75750 (53%)]\tTrain Loss: 1.241261\n",
      "Train Epoch: 7 [32640/75750 (54%)]\tTrain Loss: 1.103790\n",
      "Train Epoch: 7 [32960/75750 (54%)]\tTrain Loss: 1.122638\n",
      "Train Epoch: 7 [33280/75750 (55%)]\tTrain Loss: 1.223357\n",
      "Train Epoch: 7 [33600/75750 (55%)]\tTrain Loss: 1.567044\n",
      "Train Epoch: 7 [33920/75750 (56%)]\tTrain Loss: 0.882583\n",
      "Train Epoch: 7 [34240/75750 (56%)]\tTrain Loss: 1.630858\n",
      "Train Epoch: 7 [34560/75750 (57%)]\tTrain Loss: 1.175674\n",
      "Train Epoch: 7 [34880/75750 (58%)]\tTrain Loss: 1.446959\n",
      "Train Epoch: 7 [35200/75750 (58%)]\tTrain Loss: 0.980092\n",
      "Train Epoch: 7 [35520/75750 (59%)]\tTrain Loss: 1.385934\n",
      "Train Epoch: 7 [35840/75750 (59%)]\tTrain Loss: 1.482157\n",
      "Train Epoch: 7 [36160/75750 (60%)]\tTrain Loss: 1.505699\n",
      "Train Epoch: 7 [36480/75750 (60%)]\tTrain Loss: 1.091388\n",
      "Train Epoch: 7 [36800/75750 (61%)]\tTrain Loss: 1.128621\n",
      "Train Epoch: 7 [37120/75750 (61%)]\tTrain Loss: 1.569821\n",
      "Train Epoch: 7 [37440/75750 (62%)]\tTrain Loss: 1.277992\n",
      "Train Epoch: 7 [37760/75750 (62%)]\tTrain Loss: 1.436589\n",
      "Train Epoch: 7 [38080/75750 (63%)]\tTrain Loss: 1.245249\n",
      "Train Epoch: 7 [38400/75750 (63%)]\tTrain Loss: 1.112063\n",
      "Train Epoch: 7 [38720/75750 (64%)]\tTrain Loss: 1.245749\n",
      "Train Epoch: 7 [39040/75750 (64%)]\tTrain Loss: 1.087424\n",
      "Train Epoch: 7 [39360/75750 (65%)]\tTrain Loss: 0.845914\n",
      "Train Epoch: 7 [39680/75750 (65%)]\tTrain Loss: 1.577122\n",
      "Train Epoch: 7 [40000/75750 (66%)]\tTrain Loss: 1.609824\n",
      "Train Epoch: 7 [40320/75750 (67%)]\tTrain Loss: 1.636700\n",
      "Train Epoch: 7 [40640/75750 (67%)]\tTrain Loss: 0.876205\n",
      "Train Epoch: 7 [40960/75750 (68%)]\tTrain Loss: 0.983762\n",
      "Train Epoch: 7 [41280/75750 (68%)]\tTrain Loss: 1.039155\n",
      "Train Epoch: 7 [41600/75750 (69%)]\tTrain Loss: 0.995485\n",
      "Train Epoch: 7 [41920/75750 (69%)]\tTrain Loss: 0.983309\n",
      "Train Epoch: 7 [42240/75750 (70%)]\tTrain Loss: 1.213992\n",
      "Train Epoch: 7 [42560/75750 (70%)]\tTrain Loss: 1.739976\n",
      "Train Epoch: 7 [42880/75750 (71%)]\tTrain Loss: 1.164952\n",
      "Train Epoch: 7 [43200/75750 (71%)]\tTrain Loss: 1.139508\n",
      "Train Epoch: 7 [43520/75750 (72%)]\tTrain Loss: 1.220154\n",
      "Train Epoch: 7 [43840/75750 (72%)]\tTrain Loss: 1.584464\n",
      "Train Epoch: 7 [44160/75750 (73%)]\tTrain Loss: 1.059934\n",
      "Train Epoch: 7 [44480/75750 (73%)]\tTrain Loss: 1.406808\n",
      "Train Epoch: 7 [44800/75750 (74%)]\tTrain Loss: 1.413594\n",
      "Train Epoch: 7 [45120/75750 (74%)]\tTrain Loss: 1.568243\n",
      "Train Epoch: 7 [45440/75750 (75%)]\tTrain Loss: 1.576492\n",
      "Train Epoch: 7 [45760/75750 (76%)]\tTrain Loss: 1.159297\n",
      "Train Epoch: 7 [46080/75750 (76%)]\tTrain Loss: 1.408754\n",
      "Train Epoch: 7 [46400/75750 (77%)]\tTrain Loss: 1.068339\n",
      "Train Epoch: 7 [46720/75750 (77%)]\tTrain Loss: 1.627128\n",
      "Train Epoch: 7 [47040/75750 (78%)]\tTrain Loss: 1.095554\n",
      "Train Epoch: 7 [47360/75750 (78%)]\tTrain Loss: 1.134862\n",
      "Train Epoch: 7 [47680/75750 (79%)]\tTrain Loss: 1.171210\n",
      "Train Epoch: 7 [48000/75750 (79%)]\tTrain Loss: 1.081856\n",
      "Train Epoch: 7 [48320/75750 (80%)]\tTrain Loss: 1.274375\n",
      "Train Epoch: 7 [48640/75750 (80%)]\tTrain Loss: 1.451360\n",
      "Train Epoch: 7 [48960/75750 (81%)]\tTrain Loss: 1.318760\n",
      "Train Epoch: 7 [49280/75750 (81%)]\tTrain Loss: 1.394710\n",
      "Train Epoch: 7 [49600/75750 (82%)]\tTrain Loss: 1.092612\n",
      "Train Epoch: 7 [49920/75750 (82%)]\tTrain Loss: 1.285953\n",
      "Train Epoch: 7 [50240/75750 (83%)]\tTrain Loss: 1.338010\n",
      "Train Epoch: 7 [50560/75750 (83%)]\tTrain Loss: 1.254632\n",
      "Train Epoch: 7 [50880/75750 (84%)]\tTrain Loss: 1.581545\n",
      "Train Epoch: 7 [51200/75750 (84%)]\tTrain Loss: 1.254273\n",
      "Train Epoch: 7 [51520/75750 (85%)]\tTrain Loss: 1.296297\n",
      "Train Epoch: 7 [51840/75750 (86%)]\tTrain Loss: 1.463152\n",
      "Train Epoch: 7 [52160/75750 (86%)]\tTrain Loss: 1.199093\n",
      "Train Epoch: 7 [52480/75750 (87%)]\tTrain Loss: 1.280684\n",
      "Train Epoch: 7 [52800/75750 (87%)]\tTrain Loss: 1.601388\n",
      "Train Epoch: 7 [53120/75750 (88%)]\tTrain Loss: 1.710243\n",
      "Train Epoch: 7 [53440/75750 (88%)]\tTrain Loss: 1.362644\n",
      "Train Epoch: 7 [53760/75750 (89%)]\tTrain Loss: 1.081092\n",
      "Train Epoch: 7 [54080/75750 (89%)]\tTrain Loss: 1.339231\n",
      "Train Epoch: 7 [54400/75750 (90%)]\tTrain Loss: 1.225776\n",
      "Train Epoch: 7 [54720/75750 (90%)]\tTrain Loss: 1.227580\n",
      "Train Epoch: 7 [55040/75750 (91%)]\tTrain Loss: 1.414069\n",
      "Train Epoch: 7 [55360/75750 (91%)]\tTrain Loss: 1.246294\n",
      "Train Epoch: 7 [55680/75750 (92%)]\tTrain Loss: 1.283308\n",
      "Train Epoch: 7 [56000/75750 (92%)]\tTrain Loss: 1.520263\n",
      "Train Epoch: 7 [56320/75750 (93%)]\tTrain Loss: 1.407369\n",
      "Train Epoch: 7 [56640/75750 (93%)]\tTrain Loss: 1.558383\n",
      "Train Epoch: 7 [56960/75750 (94%)]\tTrain Loss: 1.445258\n",
      "Train Epoch: 7 [57280/75750 (95%)]\tTrain Loss: 1.079176\n",
      "Train Epoch: 7 [57600/75750 (95%)]\tTrain Loss: 1.554537\n",
      "Train Epoch: 7 [57920/75750 (96%)]\tTrain Loss: 1.474952\n",
      "Train Epoch: 7 [58240/75750 (96%)]\tTrain Loss: 1.377188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [58560/75750 (97%)]\tTrain Loss: 1.341159\n",
      "Train Epoch: 7 [58880/75750 (97%)]\tTrain Loss: 0.980945\n",
      "Train Epoch: 7 [59200/75750 (98%)]\tTrain Loss: 1.474432\n",
      "Train Epoch: 7 [59520/75750 (98%)]\tTrain Loss: 1.435533\n",
      "Train Epoch: 7 [59840/75750 (99%)]\tTrain Loss: 1.293830\n",
      "Train Epoch: 7 [60160/75750 (99%)]\tTrain Loss: 1.446988\n",
      "Train Epoch: 7 [60480/75750 (100%)]\tTrain Loss: 1.084234\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.4896, \tTest Accuracy: 53.26 % \n",
      "\n",
      "Train Epoch: 8 [0/75750 (0%)]\tTrain Loss: 1.487105\n",
      "Train Epoch: 8 [320/75750 (1%)]\tTrain Loss: 1.231155\n",
      "Train Epoch: 8 [640/75750 (1%)]\tTrain Loss: 0.915757\n",
      "Train Epoch: 8 [960/75750 (2%)]\tTrain Loss: 0.980605\n",
      "Train Epoch: 8 [1280/75750 (2%)]\tTrain Loss: 0.992572\n",
      "Train Epoch: 8 [1600/75750 (3%)]\tTrain Loss: 1.148885\n",
      "Train Epoch: 8 [1920/75750 (3%)]\tTrain Loss: 0.887550\n",
      "Train Epoch: 8 [2240/75750 (4%)]\tTrain Loss: 1.041828\n",
      "Train Epoch: 8 [2560/75750 (4%)]\tTrain Loss: 1.132090\n",
      "Train Epoch: 8 [2880/75750 (5%)]\tTrain Loss: 1.252452\n",
      "Train Epoch: 8 [3200/75750 (5%)]\tTrain Loss: 1.650843\n",
      "Train Epoch: 8 [3520/75750 (6%)]\tTrain Loss: 1.000954\n",
      "Train Epoch: 8 [3840/75750 (6%)]\tTrain Loss: 1.084063\n",
      "Train Epoch: 8 [4160/75750 (7%)]\tTrain Loss: 0.870333\n",
      "Train Epoch: 8 [4480/75750 (7%)]\tTrain Loss: 1.281434\n",
      "Train Epoch: 8 [4800/75750 (8%)]\tTrain Loss: 1.190979\n",
      "Train Epoch: 8 [5120/75750 (8%)]\tTrain Loss: 1.200103\n",
      "Train Epoch: 8 [5440/75750 (9%)]\tTrain Loss: 1.125891\n",
      "Train Epoch: 8 [5760/75750 (10%)]\tTrain Loss: 1.330912\n",
      "Train Epoch: 8 [6080/75750 (10%)]\tTrain Loss: 1.027449\n",
      "Train Epoch: 8 [6400/75750 (11%)]\tTrain Loss: 1.185235\n",
      "Train Epoch: 8 [6720/75750 (11%)]\tTrain Loss: 1.282003\n",
      "Train Epoch: 8 [7040/75750 (12%)]\tTrain Loss: 1.194486\n",
      "Train Epoch: 8 [7360/75750 (12%)]\tTrain Loss: 1.004380\n",
      "Train Epoch: 8 [7680/75750 (13%)]\tTrain Loss: 1.165125\n",
      "Train Epoch: 8 [8000/75750 (13%)]\tTrain Loss: 1.756209\n",
      "Train Epoch: 8 [8320/75750 (14%)]\tTrain Loss: 1.538990\n",
      "Train Epoch: 8 [8640/75750 (14%)]\tTrain Loss: 0.833226\n",
      "Train Epoch: 8 [8960/75750 (15%)]\tTrain Loss: 1.430541\n",
      "Train Epoch: 8 [9280/75750 (15%)]\tTrain Loss: 1.122764\n",
      "Train Epoch: 8 [9600/75750 (16%)]\tTrain Loss: 0.827130\n",
      "Train Epoch: 8 [9920/75750 (16%)]\tTrain Loss: 1.357302\n",
      "Train Epoch: 8 [10240/75750 (17%)]\tTrain Loss: 1.078275\n",
      "Train Epoch: 8 [10560/75750 (17%)]\tTrain Loss: 1.187396\n",
      "Train Epoch: 8 [10880/75750 (18%)]\tTrain Loss: 1.192679\n",
      "Train Epoch: 8 [11200/75750 (18%)]\tTrain Loss: 1.511460\n",
      "Train Epoch: 8 [11520/75750 (19%)]\tTrain Loss: 1.305477\n",
      "Train Epoch: 8 [11840/75750 (20%)]\tTrain Loss: 1.049288\n",
      "Train Epoch: 8 [12160/75750 (20%)]\tTrain Loss: 0.945434\n",
      "Train Epoch: 8 [12480/75750 (21%)]\tTrain Loss: 1.008639\n",
      "Train Epoch: 8 [12800/75750 (21%)]\tTrain Loss: 0.880895\n",
      "Train Epoch: 8 [13120/75750 (22%)]\tTrain Loss: 0.644852\n",
      "Train Epoch: 8 [13440/75750 (22%)]\tTrain Loss: 0.943494\n",
      "Train Epoch: 8 [13760/75750 (23%)]\tTrain Loss: 0.991555\n",
      "Train Epoch: 8 [14080/75750 (23%)]\tTrain Loss: 1.383852\n",
      "Train Epoch: 8 [14400/75750 (24%)]\tTrain Loss: 1.507398\n",
      "Train Epoch: 8 [14720/75750 (24%)]\tTrain Loss: 1.221420\n",
      "Train Epoch: 8 [15040/75750 (25%)]\tTrain Loss: 0.895602\n",
      "Train Epoch: 8 [15360/75750 (25%)]\tTrain Loss: 1.108394\n",
      "Train Epoch: 8 [15680/75750 (26%)]\tTrain Loss: 1.404041\n",
      "Train Epoch: 8 [16000/75750 (26%)]\tTrain Loss: 1.339069\n",
      "Train Epoch: 8 [16320/75750 (27%)]\tTrain Loss: 0.791247\n",
      "Train Epoch: 8 [16640/75750 (27%)]\tTrain Loss: 1.694980\n",
      "Train Epoch: 8 [16960/75750 (28%)]\tTrain Loss: 1.475457\n",
      "Train Epoch: 8 [17280/75750 (29%)]\tTrain Loss: 1.067345\n",
      "Train Epoch: 8 [17600/75750 (29%)]\tTrain Loss: 1.029713\n",
      "Train Epoch: 8 [17920/75750 (30%)]\tTrain Loss: 0.905622\n",
      "Train Epoch: 8 [18240/75750 (30%)]\tTrain Loss: 1.092523\n",
      "Train Epoch: 8 [18560/75750 (31%)]\tTrain Loss: 1.064625\n",
      "Train Epoch: 8 [18880/75750 (31%)]\tTrain Loss: 1.363271\n",
      "Train Epoch: 8 [19200/75750 (32%)]\tTrain Loss: 1.460664\n",
      "Train Epoch: 8 [19520/75750 (32%)]\tTrain Loss: 1.038833\n",
      "Train Epoch: 8 [19840/75750 (33%)]\tTrain Loss: 1.351273\n",
      "Train Epoch: 8 [20160/75750 (33%)]\tTrain Loss: 1.294564\n",
      "Train Epoch: 8 [20480/75750 (34%)]\tTrain Loss: 1.409055\n",
      "Train Epoch: 8 [20800/75750 (34%)]\tTrain Loss: 1.136618\n",
      "Train Epoch: 8 [21120/75750 (35%)]\tTrain Loss: 1.357833\n",
      "Train Epoch: 8 [21440/75750 (35%)]\tTrain Loss: 1.168068\n",
      "Train Epoch: 8 [21760/75750 (36%)]\tTrain Loss: 0.733070\n",
      "Train Epoch: 8 [22080/75750 (36%)]\tTrain Loss: 1.142272\n",
      "Train Epoch: 8 [22400/75750 (37%)]\tTrain Loss: 1.150868\n",
      "Train Epoch: 8 [22720/75750 (37%)]\tTrain Loss: 1.353189\n",
      "Train Epoch: 8 [23040/75750 (38%)]\tTrain Loss: 0.770273\n",
      "Train Epoch: 8 [23360/75750 (39%)]\tTrain Loss: 1.126297\n",
      "Train Epoch: 8 [23680/75750 (39%)]\tTrain Loss: 1.168184\n",
      "Train Epoch: 8 [24000/75750 (40%)]\tTrain Loss: 1.401380\n",
      "Train Epoch: 8 [24320/75750 (40%)]\tTrain Loss: 1.298187\n",
      "Train Epoch: 8 [24640/75750 (41%)]\tTrain Loss: 1.398777\n",
      "Train Epoch: 8 [24960/75750 (41%)]\tTrain Loss: 1.198797\n",
      "Train Epoch: 8 [25280/75750 (42%)]\tTrain Loss: 1.367510\n",
      "Train Epoch: 8 [25600/75750 (42%)]\tTrain Loss: 1.547318\n",
      "Train Epoch: 8 [25920/75750 (43%)]\tTrain Loss: 0.826055\n",
      "Train Epoch: 8 [26240/75750 (43%)]\tTrain Loss: 1.142089\n",
      "Train Epoch: 8 [26560/75750 (44%)]\tTrain Loss: 1.345803\n",
      "Train Epoch: 8 [26880/75750 (44%)]\tTrain Loss: 1.154726\n",
      "Train Epoch: 8 [27200/75750 (45%)]\tTrain Loss: 0.751754\n",
      "Train Epoch: 8 [27520/75750 (45%)]\tTrain Loss: 1.164464\n",
      "Train Epoch: 8 [27840/75750 (46%)]\tTrain Loss: 1.349458\n",
      "Train Epoch: 8 [28160/75750 (46%)]\tTrain Loss: 1.204323\n",
      "Train Epoch: 8 [28480/75750 (47%)]\tTrain Loss: 1.182804\n",
      "Train Epoch: 8 [28800/75750 (48%)]\tTrain Loss: 0.790667\n",
      "Train Epoch: 8 [29120/75750 (48%)]\tTrain Loss: 0.898448\n",
      "Train Epoch: 8 [29440/75750 (49%)]\tTrain Loss: 1.490949\n",
      "Train Epoch: 8 [29760/75750 (49%)]\tTrain Loss: 1.100904\n",
      "Train Epoch: 8 [30080/75750 (50%)]\tTrain Loss: 0.983305\n",
      "Train Epoch: 8 [30400/75750 (50%)]\tTrain Loss: 1.294442\n",
      "Train Epoch: 8 [30720/75750 (51%)]\tTrain Loss: 0.840015\n",
      "Train Epoch: 8 [31040/75750 (51%)]\tTrain Loss: 1.293448\n",
      "Train Epoch: 8 [31360/75750 (52%)]\tTrain Loss: 1.714737\n",
      "Train Epoch: 8 [31680/75750 (52%)]\tTrain Loss: 1.363253\n",
      "Train Epoch: 8 [32000/75750 (53%)]\tTrain Loss: 1.634450\n",
      "Train Epoch: 8 [32320/75750 (53%)]\tTrain Loss: 1.177530\n",
      "Train Epoch: 8 [32640/75750 (54%)]\tTrain Loss: 0.993105\n",
      "Train Epoch: 8 [32960/75750 (54%)]\tTrain Loss: 1.133410\n",
      "Train Epoch: 8 [33280/75750 (55%)]\tTrain Loss: 1.096487\n",
      "Train Epoch: 8 [33600/75750 (55%)]\tTrain Loss: 1.275672\n",
      "Train Epoch: 8 [33920/75750 (56%)]\tTrain Loss: 1.201501\n",
      "Train Epoch: 8 [34240/75750 (56%)]\tTrain Loss: 0.867191\n",
      "Train Epoch: 8 [34560/75750 (57%)]\tTrain Loss: 1.085251\n",
      "Train Epoch: 8 [34880/75750 (58%)]\tTrain Loss: 0.839219\n",
      "Train Epoch: 8 [35200/75750 (58%)]\tTrain Loss: 1.314555\n",
      "Train Epoch: 8 [35520/75750 (59%)]\tTrain Loss: 1.227223\n",
      "Train Epoch: 8 [35840/75750 (59%)]\tTrain Loss: 1.070456\n",
      "Train Epoch: 8 [36160/75750 (60%)]\tTrain Loss: 1.263330\n",
      "Train Epoch: 8 [36480/75750 (60%)]\tTrain Loss: 1.311191\n",
      "Train Epoch: 8 [36800/75750 (61%)]\tTrain Loss: 1.376664\n",
      "Train Epoch: 8 [37120/75750 (61%)]\tTrain Loss: 0.972060\n",
      "Train Epoch: 8 [37440/75750 (62%)]\tTrain Loss: 1.219399\n",
      "Train Epoch: 8 [37760/75750 (62%)]\tTrain Loss: 1.096096\n",
      "Train Epoch: 8 [38080/75750 (63%)]\tTrain Loss: 1.278131\n",
      "Train Epoch: 8 [38400/75750 (63%)]\tTrain Loss: 0.914553\n",
      "Train Epoch: 8 [38720/75750 (64%)]\tTrain Loss: 1.154474\n",
      "Train Epoch: 8 [39040/75750 (64%)]\tTrain Loss: 1.093733\n",
      "Train Epoch: 8 [39360/75750 (65%)]\tTrain Loss: 1.414935\n",
      "Train Epoch: 8 [39680/75750 (65%)]\tTrain Loss: 1.149760\n",
      "Train Epoch: 8 [40000/75750 (66%)]\tTrain Loss: 1.122789\n",
      "Train Epoch: 8 [40320/75750 (67%)]\tTrain Loss: 1.399193\n",
      "Train Epoch: 8 [40640/75750 (67%)]\tTrain Loss: 1.263226\n",
      "Train Epoch: 8 [40960/75750 (68%)]\tTrain Loss: 1.284687\n",
      "Train Epoch: 8 [41280/75750 (68%)]\tTrain Loss: 1.274331\n",
      "Train Epoch: 8 [41600/75750 (69%)]\tTrain Loss: 1.298499\n",
      "Train Epoch: 8 [41920/75750 (69%)]\tTrain Loss: 1.244358\n",
      "Train Epoch: 8 [42240/75750 (70%)]\tTrain Loss: 1.243730\n",
      "Train Epoch: 8 [42560/75750 (70%)]\tTrain Loss: 1.508300\n",
      "Train Epoch: 8 [42880/75750 (71%)]\tTrain Loss: 1.171556\n",
      "Train Epoch: 8 [43200/75750 (71%)]\tTrain Loss: 1.355878\n",
      "Train Epoch: 8 [43520/75750 (72%)]\tTrain Loss: 1.222248\n",
      "Train Epoch: 8 [43840/75750 (72%)]\tTrain Loss: 1.173978\n",
      "Train Epoch: 8 [44160/75750 (73%)]\tTrain Loss: 1.586293\n",
      "Train Epoch: 8 [44480/75750 (73%)]\tTrain Loss: 1.040695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [44800/75750 (74%)]\tTrain Loss: 1.570649\n",
      "Train Epoch: 8 [45120/75750 (74%)]\tTrain Loss: 0.882031\n",
      "Train Epoch: 8 [45440/75750 (75%)]\tTrain Loss: 1.223098\n",
      "Train Epoch: 8 [45760/75750 (76%)]\tTrain Loss: 1.069824\n",
      "Train Epoch: 8 [46080/75750 (76%)]\tTrain Loss: 0.967947\n",
      "Train Epoch: 8 [46400/75750 (77%)]\tTrain Loss: 1.335734\n",
      "Train Epoch: 8 [46720/75750 (77%)]\tTrain Loss: 1.195885\n",
      "Train Epoch: 8 [47040/75750 (78%)]\tTrain Loss: 1.366283\n",
      "Train Epoch: 8 [47360/75750 (78%)]\tTrain Loss: 1.329505\n",
      "Train Epoch: 8 [47680/75750 (79%)]\tTrain Loss: 0.915962\n",
      "Train Epoch: 8 [48000/75750 (79%)]\tTrain Loss: 1.361642\n",
      "Train Epoch: 8 [48320/75750 (80%)]\tTrain Loss: 1.147432\n",
      "Train Epoch: 8 [48640/75750 (80%)]\tTrain Loss: 1.215818\n",
      "Train Epoch: 8 [48960/75750 (81%)]\tTrain Loss: 1.049029\n",
      "Train Epoch: 8 [49280/75750 (81%)]\tTrain Loss: 1.202106\n",
      "Train Epoch: 8 [49600/75750 (82%)]\tTrain Loss: 1.296682\n",
      "Train Epoch: 8 [49920/75750 (82%)]\tTrain Loss: 1.273966\n",
      "Train Epoch: 8 [50240/75750 (83%)]\tTrain Loss: 0.871549\n",
      "Train Epoch: 8 [50560/75750 (83%)]\tTrain Loss: 1.461501\n",
      "Train Epoch: 8 [50880/75750 (84%)]\tTrain Loss: 1.093039\n",
      "Train Epoch: 8 [51200/75750 (84%)]\tTrain Loss: 1.313106\n",
      "Train Epoch: 8 [51520/75750 (85%)]\tTrain Loss: 1.179251\n",
      "Train Epoch: 8 [51840/75750 (86%)]\tTrain Loss: 0.834609\n",
      "Train Epoch: 8 [52160/75750 (86%)]\tTrain Loss: 1.459005\n",
      "Train Epoch: 8 [52480/75750 (87%)]\tTrain Loss: 1.271007\n",
      "Train Epoch: 8 [52800/75750 (87%)]\tTrain Loss: 1.199790\n",
      "Train Epoch: 8 [53120/75750 (88%)]\tTrain Loss: 1.509895\n",
      "Train Epoch: 8 [53440/75750 (88%)]\tTrain Loss: 1.270869\n",
      "Train Epoch: 8 [53760/75750 (89%)]\tTrain Loss: 1.227240\n",
      "Train Epoch: 8 [54080/75750 (89%)]\tTrain Loss: 1.306602\n",
      "Train Epoch: 8 [54400/75750 (90%)]\tTrain Loss: 1.573847\n",
      "Train Epoch: 8 [54720/75750 (90%)]\tTrain Loss: 1.063925\n",
      "Train Epoch: 8 [55040/75750 (91%)]\tTrain Loss: 0.863811\n",
      "Train Epoch: 8 [55360/75750 (91%)]\tTrain Loss: 1.683565\n",
      "Train Epoch: 8 [55680/75750 (92%)]\tTrain Loss: 1.150708\n",
      "Train Epoch: 8 [56000/75750 (92%)]\tTrain Loss: 1.139627\n",
      "Train Epoch: 8 [56320/75750 (93%)]\tTrain Loss: 1.180645\n",
      "Train Epoch: 8 [56640/75750 (93%)]\tTrain Loss: 0.975675\n",
      "Train Epoch: 8 [56960/75750 (94%)]\tTrain Loss: 1.002825\n",
      "Train Epoch: 8 [57280/75750 (95%)]\tTrain Loss: 1.615062\n",
      "Train Epoch: 8 [57600/75750 (95%)]\tTrain Loss: 1.079753\n",
      "Train Epoch: 8 [57920/75750 (96%)]\tTrain Loss: 1.453048\n",
      "Train Epoch: 8 [58240/75750 (96%)]\tTrain Loss: 1.315009\n",
      "Train Epoch: 8 [58560/75750 (97%)]\tTrain Loss: 1.253086\n",
      "Train Epoch: 8 [58880/75750 (97%)]\tTrain Loss: 1.454857\n",
      "Train Epoch: 8 [59200/75750 (98%)]\tTrain Loss: 1.132117\n",
      "Train Epoch: 8 [59520/75750 (98%)]\tTrain Loss: 1.210764\n",
      "Train Epoch: 8 [59840/75750 (99%)]\tTrain Loss: 1.113528\n",
      "Train Epoch: 8 [60160/75750 (99%)]\tTrain Loss: 1.065623\n",
      "Train Epoch: 8 [60480/75750 (100%)]\tTrain Loss: 1.698591\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.4460, \tTest Accuracy: 55.50 % \n",
      "\n",
      "Train Epoch: 9 [0/75750 (0%)]\tTrain Loss: 0.796688\n",
      "Train Epoch: 9 [320/75750 (1%)]\tTrain Loss: 0.985413\n",
      "Train Epoch: 9 [640/75750 (1%)]\tTrain Loss: 0.808619\n",
      "Train Epoch: 9 [960/75750 (2%)]\tTrain Loss: 1.118455\n",
      "Train Epoch: 9 [1280/75750 (2%)]\tTrain Loss: 1.363700\n",
      "Train Epoch: 9 [1600/75750 (3%)]\tTrain Loss: 0.893994\n",
      "Train Epoch: 9 [1920/75750 (3%)]\tTrain Loss: 0.928311\n",
      "Train Epoch: 9 [2240/75750 (4%)]\tTrain Loss: 0.903179\n",
      "Train Epoch: 9 [2560/75750 (4%)]\tTrain Loss: 1.495909\n",
      "Train Epoch: 9 [2880/75750 (5%)]\tTrain Loss: 0.761652\n",
      "Train Epoch: 9 [3200/75750 (5%)]\tTrain Loss: 1.253952\n",
      "Train Epoch: 9 [3520/75750 (6%)]\tTrain Loss: 1.213099\n",
      "Train Epoch: 9 [3840/75750 (6%)]\tTrain Loss: 1.103483\n",
      "Train Epoch: 9 [4160/75750 (7%)]\tTrain Loss: 1.228602\n",
      "Train Epoch: 9 [4480/75750 (7%)]\tTrain Loss: 0.953357\n",
      "Train Epoch: 9 [4800/75750 (8%)]\tTrain Loss: 0.855795\n",
      "Train Epoch: 9 [5120/75750 (8%)]\tTrain Loss: 1.065795\n",
      "Train Epoch: 9 [5440/75750 (9%)]\tTrain Loss: 1.076419\n",
      "Train Epoch: 9 [5760/75750 (10%)]\tTrain Loss: 1.322202\n",
      "Train Epoch: 9 [6080/75750 (10%)]\tTrain Loss: 0.917732\n",
      "Train Epoch: 9 [6400/75750 (11%)]\tTrain Loss: 1.121173\n",
      "Train Epoch: 9 [6720/75750 (11%)]\tTrain Loss: 1.342300\n",
      "Train Epoch: 9 [7040/75750 (12%)]\tTrain Loss: 1.324924\n",
      "Train Epoch: 9 [7360/75750 (12%)]\tTrain Loss: 1.092753\n",
      "Train Epoch: 9 [7680/75750 (13%)]\tTrain Loss: 0.961156\n",
      "Train Epoch: 9 [8000/75750 (13%)]\tTrain Loss: 1.185401\n",
      "Train Epoch: 9 [8320/75750 (14%)]\tTrain Loss: 1.318161\n",
      "Train Epoch: 9 [8640/75750 (14%)]\tTrain Loss: 1.355310\n",
      "Train Epoch: 9 [8960/75750 (15%)]\tTrain Loss: 1.234800\n",
      "Train Epoch: 9 [9280/75750 (15%)]\tTrain Loss: 0.876924\n",
      "Train Epoch: 9 [9600/75750 (16%)]\tTrain Loss: 1.378720\n",
      "Train Epoch: 9 [9920/75750 (16%)]\tTrain Loss: 1.356529\n",
      "Train Epoch: 9 [10240/75750 (17%)]\tTrain Loss: 1.464369\n",
      "Train Epoch: 9 [10560/75750 (17%)]\tTrain Loss: 0.858995\n",
      "Train Epoch: 9 [10880/75750 (18%)]\tTrain Loss: 0.928028\n",
      "Train Epoch: 9 [11200/75750 (18%)]\tTrain Loss: 1.118085\n",
      "Train Epoch: 9 [11520/75750 (19%)]\tTrain Loss: 1.265916\n",
      "Train Epoch: 9 [11840/75750 (20%)]\tTrain Loss: 0.714473\n",
      "Train Epoch: 9 [12160/75750 (20%)]\tTrain Loss: 1.010548\n",
      "Train Epoch: 9 [12480/75750 (21%)]\tTrain Loss: 1.437588\n",
      "Train Epoch: 9 [12800/75750 (21%)]\tTrain Loss: 1.253702\n",
      "Train Epoch: 9 [13120/75750 (22%)]\tTrain Loss: 1.309883\n",
      "Train Epoch: 9 [13440/75750 (22%)]\tTrain Loss: 0.969987\n",
      "Train Epoch: 9 [13760/75750 (23%)]\tTrain Loss: 0.944201\n",
      "Train Epoch: 9 [14080/75750 (23%)]\tTrain Loss: 1.303274\n",
      "Train Epoch: 9 [14400/75750 (24%)]\tTrain Loss: 1.085931\n",
      "Train Epoch: 9 [14720/75750 (24%)]\tTrain Loss: 0.966412\n",
      "Train Epoch: 9 [15040/75750 (25%)]\tTrain Loss: 1.226008\n",
      "Train Epoch: 9 [15360/75750 (25%)]\tTrain Loss: 0.956596\n",
      "Train Epoch: 9 [15680/75750 (26%)]\tTrain Loss: 1.165796\n",
      "Train Epoch: 9 [16000/75750 (26%)]\tTrain Loss: 1.080248\n",
      "Train Epoch: 9 [16320/75750 (27%)]\tTrain Loss: 1.169850\n",
      "Train Epoch: 9 [16640/75750 (27%)]\tTrain Loss: 0.994770\n",
      "Train Epoch: 9 [16960/75750 (28%)]\tTrain Loss: 0.998010\n",
      "Train Epoch: 9 [17280/75750 (29%)]\tTrain Loss: 0.816746\n",
      "Train Epoch: 9 [17600/75750 (29%)]\tTrain Loss: 1.100471\n",
      "Train Epoch: 9 [17920/75750 (30%)]\tTrain Loss: 0.853961\n",
      "Train Epoch: 9 [18240/75750 (30%)]\tTrain Loss: 1.087649\n",
      "Train Epoch: 9 [18560/75750 (31%)]\tTrain Loss: 1.202965\n",
      "Train Epoch: 9 [18880/75750 (31%)]\tTrain Loss: 1.146514\n",
      "Train Epoch: 9 [19200/75750 (32%)]\tTrain Loss: 1.090455\n",
      "Train Epoch: 9 [19520/75750 (32%)]\tTrain Loss: 1.101455\n",
      "Train Epoch: 9 [19840/75750 (33%)]\tTrain Loss: 1.223769\n",
      "Train Epoch: 9 [20160/75750 (33%)]\tTrain Loss: 0.950875\n",
      "Train Epoch: 9 [20480/75750 (34%)]\tTrain Loss: 1.189503\n",
      "Train Epoch: 9 [20800/75750 (34%)]\tTrain Loss: 1.210865\n",
      "Train Epoch: 9 [21120/75750 (35%)]\tTrain Loss: 1.131670\n",
      "Train Epoch: 9 [21440/75750 (35%)]\tTrain Loss: 0.990134\n",
      "Train Epoch: 9 [21760/75750 (36%)]\tTrain Loss: 0.841331\n",
      "Train Epoch: 9 [22080/75750 (36%)]\tTrain Loss: 0.781826\n",
      "Train Epoch: 9 [22400/75750 (37%)]\tTrain Loss: 1.010664\n",
      "Train Epoch: 9 [22720/75750 (37%)]\tTrain Loss: 1.299904\n",
      "Train Epoch: 9 [23040/75750 (38%)]\tTrain Loss: 1.225672\n",
      "Train Epoch: 9 [23360/75750 (39%)]\tTrain Loss: 1.062432\n",
      "Train Epoch: 9 [23680/75750 (39%)]\tTrain Loss: 1.304250\n",
      "Train Epoch: 9 [24000/75750 (40%)]\tTrain Loss: 0.856213\n",
      "Train Epoch: 9 [24320/75750 (40%)]\tTrain Loss: 1.265787\n",
      "Train Epoch: 9 [24640/75750 (41%)]\tTrain Loss: 1.112164\n",
      "Train Epoch: 9 [24960/75750 (41%)]\tTrain Loss: 0.918859\n",
      "Train Epoch: 9 [25280/75750 (42%)]\tTrain Loss: 0.940821\n",
      "Train Epoch: 9 [25600/75750 (42%)]\tTrain Loss: 1.137807\n",
      "Train Epoch: 9 [25920/75750 (43%)]\tTrain Loss: 0.865178\n",
      "Train Epoch: 9 [26240/75750 (43%)]\tTrain Loss: 0.773836\n",
      "Train Epoch: 9 [26560/75750 (44%)]\tTrain Loss: 1.230507\n",
      "Train Epoch: 9 [26880/75750 (44%)]\tTrain Loss: 1.282000\n",
      "Train Epoch: 9 [27200/75750 (45%)]\tTrain Loss: 0.970762\n",
      "Train Epoch: 9 [27520/75750 (45%)]\tTrain Loss: 0.964865\n",
      "Train Epoch: 9 [27840/75750 (46%)]\tTrain Loss: 1.292523\n",
      "Train Epoch: 9 [28160/75750 (46%)]\tTrain Loss: 1.027815\n",
      "Train Epoch: 9 [28480/75750 (47%)]\tTrain Loss: 1.098536\n",
      "Train Epoch: 9 [28800/75750 (48%)]\tTrain Loss: 1.075181\n",
      "Train Epoch: 9 [29120/75750 (48%)]\tTrain Loss: 1.251755\n",
      "Train Epoch: 9 [29440/75750 (49%)]\tTrain Loss: 1.078235\n",
      "Train Epoch: 9 [29760/75750 (49%)]\tTrain Loss: 1.087643\n",
      "Train Epoch: 9 [30080/75750 (50%)]\tTrain Loss: 1.138075\n",
      "Train Epoch: 9 [30400/75750 (50%)]\tTrain Loss: 1.246110\n",
      "Train Epoch: 9 [30720/75750 (51%)]\tTrain Loss: 1.018203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [31040/75750 (51%)]\tTrain Loss: 0.931949\n",
      "Train Epoch: 9 [31360/75750 (52%)]\tTrain Loss: 1.358754\n",
      "Train Epoch: 9 [31680/75750 (52%)]\tTrain Loss: 1.056409\n",
      "Train Epoch: 9 [32000/75750 (53%)]\tTrain Loss: 1.404830\n",
      "Train Epoch: 9 [32320/75750 (53%)]\tTrain Loss: 1.641396\n",
      "Train Epoch: 9 [32640/75750 (54%)]\tTrain Loss: 1.003211\n",
      "Train Epoch: 9 [32960/75750 (54%)]\tTrain Loss: 1.038595\n",
      "Train Epoch: 9 [33280/75750 (55%)]\tTrain Loss: 0.929285\n",
      "Train Epoch: 9 [33600/75750 (55%)]\tTrain Loss: 1.371258\n",
      "Train Epoch: 9 [33920/75750 (56%)]\tTrain Loss: 1.198737\n",
      "Train Epoch: 9 [34240/75750 (56%)]\tTrain Loss: 1.176949\n",
      "Train Epoch: 9 [34560/75750 (57%)]\tTrain Loss: 1.079529\n",
      "Train Epoch: 9 [34880/75750 (58%)]\tTrain Loss: 1.074912\n",
      "Train Epoch: 9 [35200/75750 (58%)]\tTrain Loss: 1.272642\n",
      "Train Epoch: 9 [35520/75750 (59%)]\tTrain Loss: 0.987732\n",
      "Train Epoch: 9 [35840/75750 (59%)]\tTrain Loss: 1.188466\n",
      "Train Epoch: 9 [36160/75750 (60%)]\tTrain Loss: 1.303379\n",
      "Train Epoch: 9 [36480/75750 (60%)]\tTrain Loss: 1.347072\n",
      "Train Epoch: 9 [36800/75750 (61%)]\tTrain Loss: 1.107067\n",
      "Train Epoch: 9 [37120/75750 (61%)]\tTrain Loss: 1.370247\n",
      "Train Epoch: 9 [37440/75750 (62%)]\tTrain Loss: 0.970306\n",
      "Train Epoch: 9 [37760/75750 (62%)]\tTrain Loss: 1.239655\n",
      "Train Epoch: 9 [38080/75750 (63%)]\tTrain Loss: 1.147170\n",
      "Train Epoch: 9 [38400/75750 (63%)]\tTrain Loss: 0.968776\n",
      "Train Epoch: 9 [38720/75750 (64%)]\tTrain Loss: 1.230053\n",
      "Train Epoch: 9 [39040/75750 (64%)]\tTrain Loss: 1.074606\n",
      "Train Epoch: 9 [39360/75750 (65%)]\tTrain Loss: 1.272316\n",
      "Train Epoch: 9 [39680/75750 (65%)]\tTrain Loss: 0.997535\n",
      "Train Epoch: 9 [40000/75750 (66%)]\tTrain Loss: 1.142323\n",
      "Train Epoch: 9 [40320/75750 (67%)]\tTrain Loss: 1.103807\n",
      "Train Epoch: 9 [40640/75750 (67%)]\tTrain Loss: 0.946618\n",
      "Train Epoch: 9 [40960/75750 (68%)]\tTrain Loss: 1.188732\n",
      "Train Epoch: 9 [41280/75750 (68%)]\tTrain Loss: 1.626263\n",
      "Train Epoch: 9 [41600/75750 (69%)]\tTrain Loss: 1.164129\n",
      "Train Epoch: 9 [41920/75750 (69%)]\tTrain Loss: 1.115353\n",
      "Train Epoch: 9 [42240/75750 (70%)]\tTrain Loss: 1.068339\n",
      "Train Epoch: 9 [42560/75750 (70%)]\tTrain Loss: 1.005359\n",
      "Train Epoch: 9 [42880/75750 (71%)]\tTrain Loss: 1.208636\n",
      "Train Epoch: 9 [43200/75750 (71%)]\tTrain Loss: 0.702284\n",
      "Train Epoch: 9 [43520/75750 (72%)]\tTrain Loss: 0.813613\n",
      "Train Epoch: 9 [43840/75750 (72%)]\tTrain Loss: 1.419250\n",
      "Train Epoch: 9 [44160/75750 (73%)]\tTrain Loss: 1.058380\n",
      "Train Epoch: 9 [44480/75750 (73%)]\tTrain Loss: 1.597093\n",
      "Train Epoch: 9 [44800/75750 (74%)]\tTrain Loss: 1.154628\n",
      "Train Epoch: 9 [45120/75750 (74%)]\tTrain Loss: 0.952323\n",
      "Train Epoch: 9 [45440/75750 (75%)]\tTrain Loss: 0.885275\n",
      "Train Epoch: 9 [45760/75750 (76%)]\tTrain Loss: 1.288398\n",
      "Train Epoch: 9 [46080/75750 (76%)]\tTrain Loss: 1.390601\n",
      "Train Epoch: 9 [46400/75750 (77%)]\tTrain Loss: 1.497678\n",
      "Train Epoch: 9 [46720/75750 (77%)]\tTrain Loss: 1.232922\n",
      "Train Epoch: 9 [47040/75750 (78%)]\tTrain Loss: 1.152582\n",
      "Train Epoch: 9 [47360/75750 (78%)]\tTrain Loss: 1.361101\n",
      "Train Epoch: 9 [47680/75750 (79%)]\tTrain Loss: 0.841921\n",
      "Train Epoch: 9 [48000/75750 (79%)]\tTrain Loss: 0.963446\n",
      "Train Epoch: 9 [48320/75750 (80%)]\tTrain Loss: 0.973242\n",
      "Train Epoch: 9 [48640/75750 (80%)]\tTrain Loss: 1.465235\n",
      "Train Epoch: 9 [48960/75750 (81%)]\tTrain Loss: 1.299737\n",
      "Train Epoch: 9 [49280/75750 (81%)]\tTrain Loss: 1.250054\n",
      "Train Epoch: 9 [49600/75750 (82%)]\tTrain Loss: 1.115574\n",
      "Train Epoch: 9 [49920/75750 (82%)]\tTrain Loss: 1.395082\n",
      "Train Epoch: 9 [50240/75750 (83%)]\tTrain Loss: 1.242902\n",
      "Train Epoch: 9 [50560/75750 (83%)]\tTrain Loss: 0.943850\n",
      "Train Epoch: 9 [50880/75750 (84%)]\tTrain Loss: 1.276805\n",
      "Train Epoch: 9 [51200/75750 (84%)]\tTrain Loss: 1.276335\n",
      "Train Epoch: 9 [51520/75750 (85%)]\tTrain Loss: 1.344765\n",
      "Train Epoch: 9 [51840/75750 (86%)]\tTrain Loss: 1.006721\n",
      "Train Epoch: 9 [52160/75750 (86%)]\tTrain Loss: 0.605035\n",
      "Train Epoch: 9 [52480/75750 (87%)]\tTrain Loss: 1.183008\n",
      "Train Epoch: 9 [52800/75750 (87%)]\tTrain Loss: 1.424237\n",
      "Train Epoch: 9 [53120/75750 (88%)]\tTrain Loss: 1.341818\n",
      "Train Epoch: 9 [53440/75750 (88%)]\tTrain Loss: 1.068403\n",
      "Train Epoch: 9 [53760/75750 (89%)]\tTrain Loss: 1.033803\n",
      "Train Epoch: 9 [54080/75750 (89%)]\tTrain Loss: 0.911860\n",
      "Train Epoch: 9 [54400/75750 (90%)]\tTrain Loss: 1.089323\n",
      "Train Epoch: 9 [54720/75750 (90%)]\tTrain Loss: 1.191258\n",
      "Train Epoch: 9 [55040/75750 (91%)]\tTrain Loss: 1.045324\n",
      "Train Epoch: 9 [55360/75750 (91%)]\tTrain Loss: 1.044309\n",
      "Train Epoch: 9 [55680/75750 (92%)]\tTrain Loss: 1.328449\n",
      "Train Epoch: 9 [56000/75750 (92%)]\tTrain Loss: 1.314832\n",
      "Train Epoch: 9 [56320/75750 (93%)]\tTrain Loss: 1.357719\n",
      "Train Epoch: 9 [56640/75750 (93%)]\tTrain Loss: 1.023934\n",
      "Train Epoch: 9 [56960/75750 (94%)]\tTrain Loss: 1.147991\n",
      "Train Epoch: 9 [57280/75750 (95%)]\tTrain Loss: 1.288408\n",
      "Train Epoch: 9 [57600/75750 (95%)]\tTrain Loss: 1.028391\n",
      "Train Epoch: 9 [57920/75750 (96%)]\tTrain Loss: 1.225030\n",
      "Train Epoch: 9 [58240/75750 (96%)]\tTrain Loss: 1.023473\n",
      "Train Epoch: 9 [58560/75750 (97%)]\tTrain Loss: 1.589014\n",
      "Train Epoch: 9 [58880/75750 (97%)]\tTrain Loss: 1.408992\n",
      "Train Epoch: 9 [59200/75750 (98%)]\tTrain Loss: 0.942771\n",
      "Train Epoch: 9 [59520/75750 (98%)]\tTrain Loss: 1.099385\n",
      "Train Epoch: 9 [59840/75750 (99%)]\tTrain Loss: 0.904920\n",
      "Train Epoch: 9 [60160/75750 (99%)]\tTrain Loss: 1.063929\n",
      "Train Epoch: 9 [60480/75750 (100%)]\tTrain Loss: 1.184687\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.4394, \tTest Accuracy: 55.57 % \n",
      "\n",
      "Train Epoch: 10 [0/75750 (0%)]\tTrain Loss: 0.861156\n",
      "Train Epoch: 10 [320/75750 (1%)]\tTrain Loss: 1.022112\n",
      "Train Epoch: 10 [640/75750 (1%)]\tTrain Loss: 0.846423\n",
      "Train Epoch: 10 [960/75750 (2%)]\tTrain Loss: 0.943164\n",
      "Train Epoch: 10 [1280/75750 (2%)]\tTrain Loss: 1.122186\n",
      "Train Epoch: 10 [1600/75750 (3%)]\tTrain Loss: 1.243998\n",
      "Train Epoch: 10 [1920/75750 (3%)]\tTrain Loss: 0.844272\n",
      "Train Epoch: 10 [2240/75750 (4%)]\tTrain Loss: 1.196043\n",
      "Train Epoch: 10 [2560/75750 (4%)]\tTrain Loss: 0.727704\n",
      "Train Epoch: 10 [2880/75750 (5%)]\tTrain Loss: 0.924604\n",
      "Train Epoch: 10 [3200/75750 (5%)]\tTrain Loss: 1.195282\n",
      "Train Epoch: 10 [3520/75750 (6%)]\tTrain Loss: 0.657519\n",
      "Train Epoch: 10 [3840/75750 (6%)]\tTrain Loss: 1.030678\n",
      "Train Epoch: 10 [4160/75750 (7%)]\tTrain Loss: 1.294476\n",
      "Train Epoch: 10 [4480/75750 (7%)]\tTrain Loss: 1.164201\n",
      "Train Epoch: 10 [4800/75750 (8%)]\tTrain Loss: 1.164164\n",
      "Train Epoch: 10 [5120/75750 (8%)]\tTrain Loss: 0.951575\n",
      "Train Epoch: 10 [5440/75750 (9%)]\tTrain Loss: 1.123190\n",
      "Train Epoch: 10 [5760/75750 (10%)]\tTrain Loss: 0.609167\n",
      "Train Epoch: 10 [6080/75750 (10%)]\tTrain Loss: 1.263958\n",
      "Train Epoch: 10 [6400/75750 (11%)]\tTrain Loss: 0.808900\n",
      "Train Epoch: 10 [6720/75750 (11%)]\tTrain Loss: 1.242208\n",
      "Train Epoch: 10 [7040/75750 (12%)]\tTrain Loss: 1.172242\n",
      "Train Epoch: 10 [7360/75750 (12%)]\tTrain Loss: 0.831523\n",
      "Train Epoch: 10 [7680/75750 (13%)]\tTrain Loss: 1.125133\n",
      "Train Epoch: 10 [8000/75750 (13%)]\tTrain Loss: 0.761948\n",
      "Train Epoch: 10 [8320/75750 (14%)]\tTrain Loss: 0.643694\n",
      "Train Epoch: 10 [8640/75750 (14%)]\tTrain Loss: 1.179312\n",
      "Train Epoch: 10 [8960/75750 (15%)]\tTrain Loss: 0.937436\n",
      "Train Epoch: 10 [9280/75750 (15%)]\tTrain Loss: 0.825288\n",
      "Train Epoch: 10 [9600/75750 (16%)]\tTrain Loss: 1.275562\n",
      "Train Epoch: 10 [9920/75750 (16%)]\tTrain Loss: 1.108108\n",
      "Train Epoch: 10 [10240/75750 (17%)]\tTrain Loss: 0.954198\n",
      "Train Epoch: 10 [10560/75750 (17%)]\tTrain Loss: 1.031974\n",
      "Train Epoch: 10 [10880/75750 (18%)]\tTrain Loss: 0.856151\n",
      "Train Epoch: 10 [11200/75750 (18%)]\tTrain Loss: 0.869376\n",
      "Train Epoch: 10 [11520/75750 (19%)]\tTrain Loss: 1.217817\n",
      "Train Epoch: 10 [11840/75750 (20%)]\tTrain Loss: 1.459171\n",
      "Train Epoch: 10 [12160/75750 (20%)]\tTrain Loss: 0.726006\n",
      "Train Epoch: 10 [12480/75750 (21%)]\tTrain Loss: 0.608133\n",
      "Train Epoch: 10 [12800/75750 (21%)]\tTrain Loss: 1.230868\n",
      "Train Epoch: 10 [13120/75750 (22%)]\tTrain Loss: 0.906875\n",
      "Train Epoch: 10 [13440/75750 (22%)]\tTrain Loss: 0.976692\n",
      "Train Epoch: 10 [13760/75750 (23%)]\tTrain Loss: 0.917612\n",
      "Train Epoch: 10 [14080/75750 (23%)]\tTrain Loss: 1.021763\n",
      "Train Epoch: 10 [14400/75750 (24%)]\tTrain Loss: 1.026209\n",
      "Train Epoch: 10 [14720/75750 (24%)]\tTrain Loss: 0.868315\n",
      "Train Epoch: 10 [15040/75750 (25%)]\tTrain Loss: 1.231705\n",
      "Train Epoch: 10 [15360/75750 (25%)]\tTrain Loss: 0.879343\n",
      "Train Epoch: 10 [15680/75750 (26%)]\tTrain Loss: 1.490533\n",
      "Train Epoch: 10 [16000/75750 (26%)]\tTrain Loss: 1.211592\n",
      "Train Epoch: 10 [16320/75750 (27%)]\tTrain Loss: 0.851986\n",
      "Train Epoch: 10 [16640/75750 (27%)]\tTrain Loss: 0.911629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [16960/75750 (28%)]\tTrain Loss: 1.328270\n",
      "Train Epoch: 10 [17280/75750 (29%)]\tTrain Loss: 0.988830\n",
      "Train Epoch: 10 [17600/75750 (29%)]\tTrain Loss: 0.892163\n",
      "Train Epoch: 10 [17920/75750 (30%)]\tTrain Loss: 0.626288\n",
      "Train Epoch: 10 [18240/75750 (30%)]\tTrain Loss: 1.186866\n",
      "Train Epoch: 10 [18560/75750 (31%)]\tTrain Loss: 0.677231\n",
      "Train Epoch: 10 [18880/75750 (31%)]\tTrain Loss: 1.208855\n",
      "Train Epoch: 10 [19200/75750 (32%)]\tTrain Loss: 0.930992\n",
      "Train Epoch: 10 [19520/75750 (32%)]\tTrain Loss: 0.939940\n",
      "Train Epoch: 10 [19840/75750 (33%)]\tTrain Loss: 1.496011\n",
      "Train Epoch: 10 [20160/75750 (33%)]\tTrain Loss: 0.815893\n",
      "Train Epoch: 10 [20480/75750 (34%)]\tTrain Loss: 1.146233\n",
      "Train Epoch: 10 [20800/75750 (34%)]\tTrain Loss: 1.169820\n",
      "Train Epoch: 10 [21120/75750 (35%)]\tTrain Loss: 1.150887\n",
      "Train Epoch: 10 [21440/75750 (35%)]\tTrain Loss: 0.837504\n",
      "Train Epoch: 10 [21760/75750 (36%)]\tTrain Loss: 1.121513\n",
      "Train Epoch: 10 [22080/75750 (36%)]\tTrain Loss: 1.090186\n",
      "Train Epoch: 10 [22400/75750 (37%)]\tTrain Loss: 1.067627\n",
      "Train Epoch: 10 [22720/75750 (37%)]\tTrain Loss: 0.687389\n",
      "Train Epoch: 10 [23040/75750 (38%)]\tTrain Loss: 1.318894\n",
      "Train Epoch: 10 [23360/75750 (39%)]\tTrain Loss: 1.247790\n",
      "Train Epoch: 10 [23680/75750 (39%)]\tTrain Loss: 1.065166\n",
      "Train Epoch: 10 [24000/75750 (40%)]\tTrain Loss: 0.823646\n",
      "Train Epoch: 10 [24320/75750 (40%)]\tTrain Loss: 0.855734\n",
      "Train Epoch: 10 [24640/75750 (41%)]\tTrain Loss: 1.112673\n",
      "Train Epoch: 10 [24960/75750 (41%)]\tTrain Loss: 0.779119\n",
      "Train Epoch: 10 [25280/75750 (42%)]\tTrain Loss: 1.019283\n",
      "Train Epoch: 10 [25600/75750 (42%)]\tTrain Loss: 0.805863\n",
      "Train Epoch: 10 [25920/75750 (43%)]\tTrain Loss: 1.233008\n",
      "Train Epoch: 10 [26240/75750 (43%)]\tTrain Loss: 1.137393\n",
      "Train Epoch: 10 [26560/75750 (44%)]\tTrain Loss: 0.716972\n",
      "Train Epoch: 10 [26880/75750 (44%)]\tTrain Loss: 0.868112\n",
      "Train Epoch: 10 [27200/75750 (45%)]\tTrain Loss: 1.367099\n",
      "Train Epoch: 10 [27520/75750 (45%)]\tTrain Loss: 1.029250\n",
      "Train Epoch: 10 [27840/75750 (46%)]\tTrain Loss: 0.737116\n",
      "Train Epoch: 10 [28160/75750 (46%)]\tTrain Loss: 0.979716\n",
      "Train Epoch: 10 [28480/75750 (47%)]\tTrain Loss: 1.122630\n",
      "Train Epoch: 10 [28800/75750 (48%)]\tTrain Loss: 0.962576\n",
      "Train Epoch: 10 [29120/75750 (48%)]\tTrain Loss: 0.928309\n",
      "Train Epoch: 10 [29440/75750 (49%)]\tTrain Loss: 1.023542\n",
      "Train Epoch: 10 [29760/75750 (49%)]\tTrain Loss: 1.262044\n",
      "Train Epoch: 10 [30080/75750 (50%)]\tTrain Loss: 1.162115\n",
      "Train Epoch: 10 [30400/75750 (50%)]\tTrain Loss: 1.153344\n",
      "Train Epoch: 10 [30720/75750 (51%)]\tTrain Loss: 1.139217\n",
      "Train Epoch: 10 [31040/75750 (51%)]\tTrain Loss: 1.132241\n",
      "Train Epoch: 10 [31360/75750 (52%)]\tTrain Loss: 1.043452\n",
      "Train Epoch: 10 [31680/75750 (52%)]\tTrain Loss: 1.139876\n",
      "Train Epoch: 10 [32000/75750 (53%)]\tTrain Loss: 1.434740\n",
      "Train Epoch: 10 [32320/75750 (53%)]\tTrain Loss: 1.160009\n",
      "Train Epoch: 10 [32640/75750 (54%)]\tTrain Loss: 1.367940\n",
      "Train Epoch: 10 [32960/75750 (54%)]\tTrain Loss: 1.222218\n",
      "Train Epoch: 10 [33280/75750 (55%)]\tTrain Loss: 1.094352\n",
      "Train Epoch: 10 [33600/75750 (55%)]\tTrain Loss: 1.394659\n",
      "Train Epoch: 10 [33920/75750 (56%)]\tTrain Loss: 0.824268\n",
      "Train Epoch: 10 [34240/75750 (56%)]\tTrain Loss: 1.002446\n",
      "Train Epoch: 10 [34560/75750 (57%)]\tTrain Loss: 1.244637\n",
      "Train Epoch: 10 [34880/75750 (58%)]\tTrain Loss: 1.288254\n",
      "Train Epoch: 10 [35200/75750 (58%)]\tTrain Loss: 1.377925\n",
      "Train Epoch: 10 [35520/75750 (59%)]\tTrain Loss: 1.192193\n",
      "Train Epoch: 10 [35840/75750 (59%)]\tTrain Loss: 1.169551\n",
      "Train Epoch: 10 [36160/75750 (60%)]\tTrain Loss: 1.080184\n",
      "Train Epoch: 10 [36480/75750 (60%)]\tTrain Loss: 0.832831\n",
      "Train Epoch: 10 [36800/75750 (61%)]\tTrain Loss: 1.034443\n",
      "Train Epoch: 10 [37120/75750 (61%)]\tTrain Loss: 1.316553\n",
      "Train Epoch: 10 [37440/75750 (62%)]\tTrain Loss: 1.368537\n",
      "Train Epoch: 10 [37760/75750 (62%)]\tTrain Loss: 0.790556\n",
      "Train Epoch: 10 [38080/75750 (63%)]\tTrain Loss: 1.366949\n",
      "Train Epoch: 10 [38400/75750 (63%)]\tTrain Loss: 1.328510\n",
      "Train Epoch: 10 [38720/75750 (64%)]\tTrain Loss: 1.284251\n",
      "Train Epoch: 10 [39040/75750 (64%)]\tTrain Loss: 0.902678\n",
      "Train Epoch: 10 [39360/75750 (65%)]\tTrain Loss: 1.223800\n",
      "Train Epoch: 10 [39680/75750 (65%)]\tTrain Loss: 0.777707\n",
      "Train Epoch: 10 [40000/75750 (66%)]\tTrain Loss: 1.034150\n",
      "Train Epoch: 10 [40320/75750 (67%)]\tTrain Loss: 0.797568\n",
      "Train Epoch: 10 [40640/75750 (67%)]\tTrain Loss: 1.084905\n",
      "Train Epoch: 10 [40960/75750 (68%)]\tTrain Loss: 1.005042\n",
      "Train Epoch: 10 [41280/75750 (68%)]\tTrain Loss: 1.241698\n",
      "Train Epoch: 10 [41600/75750 (69%)]\tTrain Loss: 1.039798\n",
      "Train Epoch: 10 [41920/75750 (69%)]\tTrain Loss: 1.391999\n",
      "Train Epoch: 10 [42240/75750 (70%)]\tTrain Loss: 1.662468\n",
      "Train Epoch: 10 [42560/75750 (70%)]\tTrain Loss: 0.915244\n",
      "Train Epoch: 10 [42880/75750 (71%)]\tTrain Loss: 0.911216\n",
      "Train Epoch: 10 [43200/75750 (71%)]\tTrain Loss: 1.049913\n",
      "Train Epoch: 10 [43520/75750 (72%)]\tTrain Loss: 0.808169\n",
      "Train Epoch: 10 [43840/75750 (72%)]\tTrain Loss: 1.071782\n",
      "Train Epoch: 10 [44160/75750 (73%)]\tTrain Loss: 1.012638\n",
      "Train Epoch: 10 [44480/75750 (73%)]\tTrain Loss: 1.437801\n",
      "Train Epoch: 10 [44800/75750 (74%)]\tTrain Loss: 1.445974\n",
      "Train Epoch: 10 [45120/75750 (74%)]\tTrain Loss: 1.027218\n",
      "Train Epoch: 10 [45440/75750 (75%)]\tTrain Loss: 0.720356\n",
      "Train Epoch: 10 [45760/75750 (76%)]\tTrain Loss: 1.273322\n",
      "Train Epoch: 10 [46080/75750 (76%)]\tTrain Loss: 0.999470\n",
      "Train Epoch: 10 [46400/75750 (77%)]\tTrain Loss: 0.935580\n",
      "Train Epoch: 10 [46720/75750 (77%)]\tTrain Loss: 1.067255\n",
      "Train Epoch: 10 [47040/75750 (78%)]\tTrain Loss: 1.209216\n",
      "Train Epoch: 10 [47360/75750 (78%)]\tTrain Loss: 1.138616\n",
      "Train Epoch: 10 [47680/75750 (79%)]\tTrain Loss: 0.933239\n",
      "Train Epoch: 10 [48000/75750 (79%)]\tTrain Loss: 1.480598\n",
      "Train Epoch: 10 [48320/75750 (80%)]\tTrain Loss: 0.902841\n",
      "Train Epoch: 10 [48640/75750 (80%)]\tTrain Loss: 0.909384\n",
      "Train Epoch: 10 [48960/75750 (81%)]\tTrain Loss: 0.993653\n",
      "Train Epoch: 10 [49280/75750 (81%)]\tTrain Loss: 0.905171\n",
      "Train Epoch: 10 [49600/75750 (82%)]\tTrain Loss: 1.564835\n",
      "Train Epoch: 10 [49920/75750 (82%)]\tTrain Loss: 1.374480\n",
      "Train Epoch: 10 [50240/75750 (83%)]\tTrain Loss: 1.231970\n",
      "Train Epoch: 10 [50560/75750 (83%)]\tTrain Loss: 1.668136\n",
      "Train Epoch: 10 [50880/75750 (84%)]\tTrain Loss: 1.030789\n",
      "Train Epoch: 10 [51200/75750 (84%)]\tTrain Loss: 1.000398\n",
      "Train Epoch: 10 [51520/75750 (85%)]\tTrain Loss: 1.240555\n",
      "Train Epoch: 10 [51840/75750 (86%)]\tTrain Loss: 1.190024\n",
      "Train Epoch: 10 [52160/75750 (86%)]\tTrain Loss: 0.938898\n",
      "Train Epoch: 10 [52480/75750 (87%)]\tTrain Loss: 1.204166\n",
      "Train Epoch: 10 [52800/75750 (87%)]\tTrain Loss: 0.869034\n",
      "Train Epoch: 10 [53120/75750 (88%)]\tTrain Loss: 1.103837\n",
      "Train Epoch: 10 [53440/75750 (88%)]\tTrain Loss: 0.708211\n",
      "Train Epoch: 10 [53760/75750 (89%)]\tTrain Loss: 0.827486\n",
      "Train Epoch: 10 [54080/75750 (89%)]\tTrain Loss: 1.046551\n",
      "Train Epoch: 10 [54400/75750 (90%)]\tTrain Loss: 1.275161\n",
      "Train Epoch: 10 [54720/75750 (90%)]\tTrain Loss: 1.061845\n",
      "Train Epoch: 10 [55040/75750 (91%)]\tTrain Loss: 1.055866\n",
      "Train Epoch: 10 [55360/75750 (91%)]\tTrain Loss: 1.037247\n",
      "Train Epoch: 10 [55680/75750 (92%)]\tTrain Loss: 1.435699\n",
      "Train Epoch: 10 [56000/75750 (92%)]\tTrain Loss: 1.043319\n",
      "Train Epoch: 10 [56320/75750 (93%)]\tTrain Loss: 1.224771\n",
      "Train Epoch: 10 [56640/75750 (93%)]\tTrain Loss: 0.930455\n",
      "Train Epoch: 10 [56960/75750 (94%)]\tTrain Loss: 1.157129\n",
      "Train Epoch: 10 [57280/75750 (95%)]\tTrain Loss: 1.199243\n",
      "Train Epoch: 10 [57600/75750 (95%)]\tTrain Loss: 0.913424\n",
      "Train Epoch: 10 [57920/75750 (96%)]\tTrain Loss: 1.342224\n",
      "Train Epoch: 10 [58240/75750 (96%)]\tTrain Loss: 1.030442\n",
      "Train Epoch: 10 [58560/75750 (97%)]\tTrain Loss: 1.188165\n",
      "Train Epoch: 10 [58880/75750 (97%)]\tTrain Loss: 1.009211\n",
      "Train Epoch: 10 [59200/75750 (98%)]\tTrain Loss: 1.129389\n",
      "Train Epoch: 10 [59520/75750 (98%)]\tTrain Loss: 1.339240\n",
      "Train Epoch: 10 [59840/75750 (99%)]\tTrain Loss: 0.815501\n",
      "Train Epoch: 10 [60160/75750 (99%)]\tTrain Loss: 1.223710\n",
      "Train Epoch: 10 [60480/75750 (100%)]\tTrain Loss: 1.047836\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.3925, \tTest Accuracy: 58.23 % \n",
      "\n",
      "Train Epoch: 11 [0/75750 (0%)]\tTrain Loss: 1.051396\n",
      "Train Epoch: 11 [320/75750 (1%)]\tTrain Loss: 0.774594\n",
      "Train Epoch: 11 [640/75750 (1%)]\tTrain Loss: 0.794299\n",
      "Train Epoch: 11 [960/75750 (2%)]\tTrain Loss: 0.703475\n",
      "Train Epoch: 11 [1280/75750 (2%)]\tTrain Loss: 1.035248\n",
      "Train Epoch: 11 [1600/75750 (3%)]\tTrain Loss: 1.090455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [1920/75750 (3%)]\tTrain Loss: 0.963551\n",
      "Train Epoch: 11 [2240/75750 (4%)]\tTrain Loss: 1.132824\n",
      "Train Epoch: 11 [2560/75750 (4%)]\tTrain Loss: 0.864944\n",
      "Train Epoch: 11 [2880/75750 (5%)]\tTrain Loss: 0.756509\n",
      "Train Epoch: 11 [3200/75750 (5%)]\tTrain Loss: 0.960037\n",
      "Train Epoch: 11 [3520/75750 (6%)]\tTrain Loss: 0.955432\n",
      "Train Epoch: 11 [3840/75750 (6%)]\tTrain Loss: 1.154469\n",
      "Train Epoch: 11 [4160/75750 (7%)]\tTrain Loss: 0.950847\n",
      "Train Epoch: 11 [4480/75750 (7%)]\tTrain Loss: 0.927832\n",
      "Train Epoch: 11 [4800/75750 (8%)]\tTrain Loss: 1.089276\n",
      "Train Epoch: 11 [5120/75750 (8%)]\tTrain Loss: 1.033013\n",
      "Train Epoch: 11 [5440/75750 (9%)]\tTrain Loss: 0.814942\n",
      "Train Epoch: 11 [5760/75750 (10%)]\tTrain Loss: 0.761625\n",
      "Train Epoch: 11 [6080/75750 (10%)]\tTrain Loss: 1.116982\n",
      "Train Epoch: 11 [6400/75750 (11%)]\tTrain Loss: 1.082067\n",
      "Train Epoch: 11 [6720/75750 (11%)]\tTrain Loss: 0.749036\n",
      "Train Epoch: 11 [7040/75750 (12%)]\tTrain Loss: 0.750647\n",
      "Train Epoch: 11 [7360/75750 (12%)]\tTrain Loss: 0.635766\n",
      "Train Epoch: 11 [7680/75750 (13%)]\tTrain Loss: 1.283054\n",
      "Train Epoch: 11 [8000/75750 (13%)]\tTrain Loss: 0.930473\n",
      "Train Epoch: 11 [8320/75750 (14%)]\tTrain Loss: 0.811701\n",
      "Train Epoch: 11 [8640/75750 (14%)]\tTrain Loss: 1.610803\n",
      "Train Epoch: 11 [8960/75750 (15%)]\tTrain Loss: 0.783232\n",
      "Train Epoch: 11 [9280/75750 (15%)]\tTrain Loss: 0.936931\n",
      "Train Epoch: 11 [9600/75750 (16%)]\tTrain Loss: 1.001034\n",
      "Train Epoch: 11 [9920/75750 (16%)]\tTrain Loss: 0.923317\n",
      "Train Epoch: 11 [10240/75750 (17%)]\tTrain Loss: 1.253220\n",
      "Train Epoch: 11 [10560/75750 (17%)]\tTrain Loss: 0.898264\n",
      "Train Epoch: 11 [10880/75750 (18%)]\tTrain Loss: 0.910676\n",
      "Train Epoch: 11 [11200/75750 (18%)]\tTrain Loss: 1.068499\n",
      "Train Epoch: 11 [11520/75750 (19%)]\tTrain Loss: 0.669275\n",
      "Train Epoch: 11 [11840/75750 (20%)]\tTrain Loss: 0.941069\n",
      "Train Epoch: 11 [12160/75750 (20%)]\tTrain Loss: 0.796348\n",
      "Train Epoch: 11 [12480/75750 (21%)]\tTrain Loss: 1.013563\n",
      "Train Epoch: 11 [12800/75750 (21%)]\tTrain Loss: 1.065277\n",
      "Train Epoch: 11 [13120/75750 (22%)]\tTrain Loss: 1.163826\n",
      "Train Epoch: 11 [13440/75750 (22%)]\tTrain Loss: 1.082529\n",
      "Train Epoch: 11 [13760/75750 (23%)]\tTrain Loss: 0.964019\n",
      "Train Epoch: 11 [14080/75750 (23%)]\tTrain Loss: 0.994680\n",
      "Train Epoch: 11 [14400/75750 (24%)]\tTrain Loss: 0.734612\n",
      "Train Epoch: 11 [14720/75750 (24%)]\tTrain Loss: 0.814298\n",
      "Train Epoch: 11 [15040/75750 (25%)]\tTrain Loss: 0.968483\n",
      "Train Epoch: 11 [15360/75750 (25%)]\tTrain Loss: 1.065104\n",
      "Train Epoch: 11 [15680/75750 (26%)]\tTrain Loss: 0.848728\n",
      "Train Epoch: 11 [16000/75750 (26%)]\tTrain Loss: 0.788015\n",
      "Train Epoch: 11 [16320/75750 (27%)]\tTrain Loss: 0.659689\n",
      "Train Epoch: 11 [16640/75750 (27%)]\tTrain Loss: 0.993265\n",
      "Train Epoch: 11 [16960/75750 (28%)]\tTrain Loss: 1.368040\n",
      "Train Epoch: 11 [17280/75750 (29%)]\tTrain Loss: 1.152875\n",
      "Train Epoch: 11 [17600/75750 (29%)]\tTrain Loss: 0.863042\n",
      "Train Epoch: 11 [17920/75750 (30%)]\tTrain Loss: 1.022376\n",
      "Train Epoch: 11 [18240/75750 (30%)]\tTrain Loss: 1.159334\n",
      "Train Epoch: 11 [18560/75750 (31%)]\tTrain Loss: 1.020239\n",
      "Train Epoch: 11 [18880/75750 (31%)]\tTrain Loss: 1.259651\n",
      "Train Epoch: 11 [19200/75750 (32%)]\tTrain Loss: 0.871369\n",
      "Train Epoch: 11 [19520/75750 (32%)]\tTrain Loss: 0.847047\n",
      "Train Epoch: 11 [19840/75750 (33%)]\tTrain Loss: 0.619763\n",
      "Train Epoch: 11 [20160/75750 (33%)]\tTrain Loss: 1.038017\n",
      "Train Epoch: 11 [20480/75750 (34%)]\tTrain Loss: 1.090787\n",
      "Train Epoch: 11 [20800/75750 (34%)]\tTrain Loss: 1.028845\n",
      "Train Epoch: 11 [21120/75750 (35%)]\tTrain Loss: 0.964314\n",
      "Train Epoch: 11 [21440/75750 (35%)]\tTrain Loss: 0.795582\n",
      "Train Epoch: 11 [21760/75750 (36%)]\tTrain Loss: 0.808713\n",
      "Train Epoch: 11 [22080/75750 (36%)]\tTrain Loss: 1.082261\n",
      "Train Epoch: 11 [22400/75750 (37%)]\tTrain Loss: 0.990745\n",
      "Train Epoch: 11 [22720/75750 (37%)]\tTrain Loss: 1.170472\n",
      "Train Epoch: 11 [23040/75750 (38%)]\tTrain Loss: 1.430554\n",
      "Train Epoch: 11 [23360/75750 (39%)]\tTrain Loss: 1.274455\n",
      "Train Epoch: 11 [23680/75750 (39%)]\tTrain Loss: 0.872101\n",
      "Train Epoch: 11 [24000/75750 (40%)]\tTrain Loss: 1.080936\n",
      "Train Epoch: 11 [24320/75750 (40%)]\tTrain Loss: 0.907380\n",
      "Train Epoch: 11 [24640/75750 (41%)]\tTrain Loss: 0.985737\n",
      "Train Epoch: 11 [24960/75750 (41%)]\tTrain Loss: 1.100319\n",
      "Train Epoch: 11 [25280/75750 (42%)]\tTrain Loss: 1.022080\n",
      "Train Epoch: 11 [25600/75750 (42%)]\tTrain Loss: 0.917808\n",
      "Train Epoch: 11 [25920/75750 (43%)]\tTrain Loss: 1.074945\n",
      "Train Epoch: 11 [26240/75750 (43%)]\tTrain Loss: 1.281031\n",
      "Train Epoch: 11 [26560/75750 (44%)]\tTrain Loss: 1.232612\n",
      "Train Epoch: 11 [26880/75750 (44%)]\tTrain Loss: 1.397159\n",
      "Train Epoch: 11 [27200/75750 (45%)]\tTrain Loss: 1.337138\n",
      "Train Epoch: 11 [27520/75750 (45%)]\tTrain Loss: 0.731172\n",
      "Train Epoch: 11 [27840/75750 (46%)]\tTrain Loss: 1.076332\n",
      "Train Epoch: 11 [28160/75750 (46%)]\tTrain Loss: 1.005689\n",
      "Train Epoch: 11 [28480/75750 (47%)]\tTrain Loss: 0.929638\n",
      "Train Epoch: 11 [28800/75750 (48%)]\tTrain Loss: 1.007497\n",
      "Train Epoch: 11 [29120/75750 (48%)]\tTrain Loss: 1.235075\n",
      "Train Epoch: 11 [29440/75750 (49%)]\tTrain Loss: 1.424321\n",
      "Train Epoch: 11 [29760/75750 (49%)]\tTrain Loss: 1.208279\n",
      "Train Epoch: 11 [30080/75750 (50%)]\tTrain Loss: 0.931421\n",
      "Train Epoch: 11 [30400/75750 (50%)]\tTrain Loss: 0.977551\n",
      "Train Epoch: 11 [30720/75750 (51%)]\tTrain Loss: 0.955366\n",
      "Train Epoch: 11 [31040/75750 (51%)]\tTrain Loss: 1.492982\n",
      "Train Epoch: 11 [31360/75750 (52%)]\tTrain Loss: 1.271400\n",
      "Train Epoch: 11 [31680/75750 (52%)]\tTrain Loss: 1.138381\n",
      "Train Epoch: 11 [32000/75750 (53%)]\tTrain Loss: 1.056569\n",
      "Train Epoch: 11 [32320/75750 (53%)]\tTrain Loss: 0.808476\n",
      "Train Epoch: 11 [32640/75750 (54%)]\tTrain Loss: 1.111697\n",
      "Train Epoch: 11 [32960/75750 (54%)]\tTrain Loss: 0.950240\n",
      "Train Epoch: 11 [33280/75750 (55%)]\tTrain Loss: 0.841374\n",
      "Train Epoch: 11 [33600/75750 (55%)]\tTrain Loss: 0.968890\n",
      "Train Epoch: 11 [33920/75750 (56%)]\tTrain Loss: 1.179814\n",
      "Train Epoch: 11 [34240/75750 (56%)]\tTrain Loss: 0.943223\n",
      "Train Epoch: 11 [34560/75750 (57%)]\tTrain Loss: 1.296585\n",
      "Train Epoch: 11 [34880/75750 (58%)]\tTrain Loss: 0.809749\n",
      "Train Epoch: 11 [35200/75750 (58%)]\tTrain Loss: 1.112921\n",
      "Train Epoch: 11 [35520/75750 (59%)]\tTrain Loss: 1.225266\n",
      "Train Epoch: 11 [35840/75750 (59%)]\tTrain Loss: 0.912976\n",
      "Train Epoch: 11 [36160/75750 (60%)]\tTrain Loss: 0.940238\n",
      "Train Epoch: 11 [36480/75750 (60%)]\tTrain Loss: 0.827041\n",
      "Train Epoch: 11 [36800/75750 (61%)]\tTrain Loss: 1.127086\n",
      "Train Epoch: 11 [37120/75750 (61%)]\tTrain Loss: 0.688058\n",
      "Train Epoch: 11 [37440/75750 (62%)]\tTrain Loss: 0.849166\n",
      "Train Epoch: 11 [37760/75750 (62%)]\tTrain Loss: 1.027014\n",
      "Train Epoch: 11 [38080/75750 (63%)]\tTrain Loss: 0.927397\n",
      "Train Epoch: 11 [38400/75750 (63%)]\tTrain Loss: 0.998175\n",
      "Train Epoch: 11 [38720/75750 (64%)]\tTrain Loss: 0.841056\n",
      "Train Epoch: 11 [39040/75750 (64%)]\tTrain Loss: 0.882753\n",
      "Train Epoch: 11 [39360/75750 (65%)]\tTrain Loss: 1.082489\n",
      "Train Epoch: 11 [39680/75750 (65%)]\tTrain Loss: 1.152357\n",
      "Train Epoch: 11 [40000/75750 (66%)]\tTrain Loss: 1.207460\n",
      "Train Epoch: 11 [40320/75750 (67%)]\tTrain Loss: 1.001086\n",
      "Train Epoch: 11 [40640/75750 (67%)]\tTrain Loss: 1.038652\n",
      "Train Epoch: 11 [40960/75750 (68%)]\tTrain Loss: 1.123241\n",
      "Train Epoch: 11 [41280/75750 (68%)]\tTrain Loss: 0.990642\n",
      "Train Epoch: 11 [41600/75750 (69%)]\tTrain Loss: 0.975941\n",
      "Train Epoch: 11 [41920/75750 (69%)]\tTrain Loss: 1.353114\n",
      "Train Epoch: 11 [42240/75750 (70%)]\tTrain Loss: 1.223322\n",
      "Train Epoch: 11 [42560/75750 (70%)]\tTrain Loss: 0.832585\n",
      "Train Epoch: 11 [42880/75750 (71%)]\tTrain Loss: 0.952833\n",
      "Train Epoch: 11 [43200/75750 (71%)]\tTrain Loss: 0.654419\n",
      "Train Epoch: 11 [43520/75750 (72%)]\tTrain Loss: 1.204246\n",
      "Train Epoch: 11 [43840/75750 (72%)]\tTrain Loss: 1.178690\n",
      "Train Epoch: 11 [44160/75750 (73%)]\tTrain Loss: 0.814146\n",
      "Train Epoch: 11 [44480/75750 (73%)]\tTrain Loss: 1.203783\n",
      "Train Epoch: 11 [44800/75750 (74%)]\tTrain Loss: 0.906399\n",
      "Train Epoch: 11 [45120/75750 (74%)]\tTrain Loss: 0.667232\n",
      "Train Epoch: 11 [45440/75750 (75%)]\tTrain Loss: 0.911221\n",
      "Train Epoch: 11 [45760/75750 (76%)]\tTrain Loss: 0.977100\n",
      "Train Epoch: 11 [46080/75750 (76%)]\tTrain Loss: 1.254683\n",
      "Train Epoch: 11 [46400/75750 (77%)]\tTrain Loss: 1.303126\n",
      "Train Epoch: 11 [46720/75750 (77%)]\tTrain Loss: 1.000070\n",
      "Train Epoch: 11 [47040/75750 (78%)]\tTrain Loss: 1.031295\n",
      "Train Epoch: 11 [47360/75750 (78%)]\tTrain Loss: 0.865244\n",
      "Train Epoch: 11 [47680/75750 (79%)]\tTrain Loss: 1.235740\n",
      "Train Epoch: 11 [48000/75750 (79%)]\tTrain Loss: 0.966034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [48320/75750 (80%)]\tTrain Loss: 1.162181\n",
      "Train Epoch: 11 [48640/75750 (80%)]\tTrain Loss: 1.146132\n",
      "Train Epoch: 11 [48960/75750 (81%)]\tTrain Loss: 0.924277\n",
      "Train Epoch: 11 [49280/75750 (81%)]\tTrain Loss: 1.509383\n",
      "Train Epoch: 11 [49600/75750 (82%)]\tTrain Loss: 1.078057\n",
      "Train Epoch: 11 [49920/75750 (82%)]\tTrain Loss: 1.104952\n",
      "Train Epoch: 11 [50240/75750 (83%)]\tTrain Loss: 0.885158\n",
      "Train Epoch: 11 [50560/75750 (83%)]\tTrain Loss: 0.798519\n",
      "Train Epoch: 11 [50880/75750 (84%)]\tTrain Loss: 1.637652\n",
      "Train Epoch: 11 [51200/75750 (84%)]\tTrain Loss: 1.222754\n",
      "Train Epoch: 11 [51520/75750 (85%)]\tTrain Loss: 1.166703\n",
      "Train Epoch: 11 [51840/75750 (86%)]\tTrain Loss: 1.073447\n",
      "Train Epoch: 11 [52160/75750 (86%)]\tTrain Loss: 0.769950\n",
      "Train Epoch: 11 [52480/75750 (87%)]\tTrain Loss: 1.034052\n",
      "Train Epoch: 11 [52800/75750 (87%)]\tTrain Loss: 1.427087\n",
      "Train Epoch: 11 [53120/75750 (88%)]\tTrain Loss: 1.006318\n",
      "Train Epoch: 11 [53440/75750 (88%)]\tTrain Loss: 1.264455\n",
      "Train Epoch: 11 [53760/75750 (89%)]\tTrain Loss: 1.191628\n",
      "Train Epoch: 11 [54080/75750 (89%)]\tTrain Loss: 1.015867\n",
      "Train Epoch: 11 [54400/75750 (90%)]\tTrain Loss: 1.035847\n",
      "Train Epoch: 11 [54720/75750 (90%)]\tTrain Loss: 1.337987\n",
      "Train Epoch: 11 [55040/75750 (91%)]\tTrain Loss: 1.159388\n",
      "Train Epoch: 11 [55360/75750 (91%)]\tTrain Loss: 1.178104\n",
      "Train Epoch: 11 [55680/75750 (92%)]\tTrain Loss: 0.901656\n",
      "Train Epoch: 11 [56000/75750 (92%)]\tTrain Loss: 1.633356\n",
      "Train Epoch: 11 [56320/75750 (93%)]\tTrain Loss: 1.027371\n",
      "Train Epoch: 11 [56640/75750 (93%)]\tTrain Loss: 0.956776\n",
      "Train Epoch: 11 [56960/75750 (94%)]\tTrain Loss: 1.047238\n",
      "Train Epoch: 11 [57280/75750 (95%)]\tTrain Loss: 1.059388\n",
      "Train Epoch: 11 [57600/75750 (95%)]\tTrain Loss: 0.699995\n",
      "Train Epoch: 11 [57920/75750 (96%)]\tTrain Loss: 1.218925\n",
      "Train Epoch: 11 [58240/75750 (96%)]\tTrain Loss: 0.834479\n",
      "Train Epoch: 11 [58560/75750 (97%)]\tTrain Loss: 0.872851\n",
      "Train Epoch: 11 [58880/75750 (97%)]\tTrain Loss: 1.176577\n",
      "Train Epoch: 11 [59200/75750 (98%)]\tTrain Loss: 1.341115\n",
      "Train Epoch: 11 [59520/75750 (98%)]\tTrain Loss: 0.659337\n",
      "Train Epoch: 11 [59840/75750 (99%)]\tTrain Loss: 1.169673\n",
      "Train Epoch: 11 [60160/75750 (99%)]\tTrain Loss: 1.120738\n",
      "Train Epoch: 11 [60480/75750 (100%)]\tTrain Loss: 1.226710\n",
      "\n",
      "[EPOCH: 11], \tTest Loss: 0.3717, \tTest Accuracy: 59.05 % \n",
      "\n",
      "Train Epoch: 12 [0/75750 (0%)]\tTrain Loss: 1.116573\n",
      "Train Epoch: 12 [320/75750 (1%)]\tTrain Loss: 0.724353\n",
      "Train Epoch: 12 [640/75750 (1%)]\tTrain Loss: 0.815387\n",
      "Train Epoch: 12 [960/75750 (2%)]\tTrain Loss: 1.021002\n",
      "Train Epoch: 12 [1280/75750 (2%)]\tTrain Loss: 0.579871\n",
      "Train Epoch: 12 [1600/75750 (3%)]\tTrain Loss: 1.067957\n",
      "Train Epoch: 12 [1920/75750 (3%)]\tTrain Loss: 0.776807\n",
      "Train Epoch: 12 [2240/75750 (4%)]\tTrain Loss: 0.993966\n",
      "Train Epoch: 12 [2560/75750 (4%)]\tTrain Loss: 0.608513\n",
      "Train Epoch: 12 [2880/75750 (5%)]\tTrain Loss: 0.918006\n",
      "Train Epoch: 12 [3200/75750 (5%)]\tTrain Loss: 1.156910\n",
      "Train Epoch: 12 [3520/75750 (6%)]\tTrain Loss: 1.001173\n",
      "Train Epoch: 12 [3840/75750 (6%)]\tTrain Loss: 0.716830\n",
      "Train Epoch: 12 [4160/75750 (7%)]\tTrain Loss: 0.806874\n",
      "Train Epoch: 12 [4480/75750 (7%)]\tTrain Loss: 0.727715\n",
      "Train Epoch: 12 [4800/75750 (8%)]\tTrain Loss: 0.816018\n",
      "Train Epoch: 12 [5120/75750 (8%)]\tTrain Loss: 1.053285\n",
      "Train Epoch: 12 [5440/75750 (9%)]\tTrain Loss: 0.670154\n",
      "Train Epoch: 12 [5760/75750 (10%)]\tTrain Loss: 0.562394\n",
      "Train Epoch: 12 [6080/75750 (10%)]\tTrain Loss: 0.684340\n",
      "Train Epoch: 12 [6400/75750 (11%)]\tTrain Loss: 1.063478\n",
      "Train Epoch: 12 [6720/75750 (11%)]\tTrain Loss: 0.828629\n",
      "Train Epoch: 12 [7040/75750 (12%)]\tTrain Loss: 0.863904\n",
      "Train Epoch: 12 [7360/75750 (12%)]\tTrain Loss: 0.735193\n",
      "Train Epoch: 12 [7680/75750 (13%)]\tTrain Loss: 0.818026\n",
      "Train Epoch: 12 [8000/75750 (13%)]\tTrain Loss: 0.844143\n",
      "Train Epoch: 12 [8320/75750 (14%)]\tTrain Loss: 0.746950\n",
      "Train Epoch: 12 [8640/75750 (14%)]\tTrain Loss: 1.242257\n",
      "Train Epoch: 12 [8960/75750 (15%)]\tTrain Loss: 1.029742\n",
      "Train Epoch: 12 [9280/75750 (15%)]\tTrain Loss: 0.574356\n",
      "Train Epoch: 12 [9600/75750 (16%)]\tTrain Loss: 0.983984\n",
      "Train Epoch: 12 [9920/75750 (16%)]\tTrain Loss: 0.882014\n",
      "Train Epoch: 12 [10240/75750 (17%)]\tTrain Loss: 0.786713\n",
      "Train Epoch: 12 [10560/75750 (17%)]\tTrain Loss: 0.544605\n",
      "Train Epoch: 12 [10880/75750 (18%)]\tTrain Loss: 0.779157\n",
      "Train Epoch: 12 [11200/75750 (18%)]\tTrain Loss: 1.701982\n",
      "Train Epoch: 12 [11520/75750 (19%)]\tTrain Loss: 1.307510\n",
      "Train Epoch: 12 [11840/75750 (20%)]\tTrain Loss: 1.106399\n",
      "Train Epoch: 12 [12160/75750 (20%)]\tTrain Loss: 0.502784\n",
      "Train Epoch: 12 [12480/75750 (21%)]\tTrain Loss: 0.738806\n",
      "Train Epoch: 12 [12800/75750 (21%)]\tTrain Loss: 1.494313\n",
      "Train Epoch: 12 [13120/75750 (22%)]\tTrain Loss: 0.735179\n",
      "Train Epoch: 12 [13440/75750 (22%)]\tTrain Loss: 0.613581\n",
      "Train Epoch: 12 [13760/75750 (23%)]\tTrain Loss: 1.200297\n",
      "Train Epoch: 12 [14080/75750 (23%)]\tTrain Loss: 0.983906\n",
      "Train Epoch: 12 [14400/75750 (24%)]\tTrain Loss: 1.065310\n",
      "Train Epoch: 12 [14720/75750 (24%)]\tTrain Loss: 0.796149\n",
      "Train Epoch: 12 [15040/75750 (25%)]\tTrain Loss: 0.842524\n",
      "Train Epoch: 12 [15360/75750 (25%)]\tTrain Loss: 0.979788\n",
      "Train Epoch: 12 [15680/75750 (26%)]\tTrain Loss: 0.825011\n",
      "Train Epoch: 12 [16000/75750 (26%)]\tTrain Loss: 1.140779\n",
      "Train Epoch: 12 [16320/75750 (27%)]\tTrain Loss: 0.816011\n",
      "Train Epoch: 12 [16640/75750 (27%)]\tTrain Loss: 1.081188\n",
      "Train Epoch: 12 [16960/75750 (28%)]\tTrain Loss: 0.981665\n",
      "Train Epoch: 12 [17280/75750 (29%)]\tTrain Loss: 0.948226\n",
      "Train Epoch: 12 [17600/75750 (29%)]\tTrain Loss: 0.746722\n",
      "Train Epoch: 12 [17920/75750 (30%)]\tTrain Loss: 0.855421\n",
      "Train Epoch: 12 [18240/75750 (30%)]\tTrain Loss: 1.056551\n",
      "Train Epoch: 12 [18560/75750 (31%)]\tTrain Loss: 0.945560\n",
      "Train Epoch: 12 [18880/75750 (31%)]\tTrain Loss: 1.095016\n",
      "Train Epoch: 12 [19200/75750 (32%)]\tTrain Loss: 0.913160\n",
      "Train Epoch: 12 [19520/75750 (32%)]\tTrain Loss: 1.101447\n",
      "Train Epoch: 12 [19840/75750 (33%)]\tTrain Loss: 0.970278\n",
      "Train Epoch: 12 [20160/75750 (33%)]\tTrain Loss: 0.603530\n",
      "Train Epoch: 12 [20480/75750 (34%)]\tTrain Loss: 0.999629\n",
      "Train Epoch: 12 [20800/75750 (34%)]\tTrain Loss: 0.691182\n",
      "Train Epoch: 12 [21120/75750 (35%)]\tTrain Loss: 0.973707\n",
      "Train Epoch: 12 [21440/75750 (35%)]\tTrain Loss: 1.105069\n",
      "Train Epoch: 12 [21760/75750 (36%)]\tTrain Loss: 0.689140\n",
      "Train Epoch: 12 [22080/75750 (36%)]\tTrain Loss: 1.083362\n",
      "Train Epoch: 12 [22400/75750 (37%)]\tTrain Loss: 0.982459\n",
      "Train Epoch: 12 [22720/75750 (37%)]\tTrain Loss: 0.876360\n",
      "Train Epoch: 12 [23040/75750 (38%)]\tTrain Loss: 0.922686\n",
      "Train Epoch: 12 [23360/75750 (39%)]\tTrain Loss: 0.922306\n",
      "Train Epoch: 12 [23680/75750 (39%)]\tTrain Loss: 0.945205\n",
      "Train Epoch: 12 [24000/75750 (40%)]\tTrain Loss: 0.975852\n",
      "Train Epoch: 12 [24320/75750 (40%)]\tTrain Loss: 0.928227\n",
      "Train Epoch: 12 [24640/75750 (41%)]\tTrain Loss: 1.604660\n",
      "Train Epoch: 12 [24960/75750 (41%)]\tTrain Loss: 0.790205\n",
      "Train Epoch: 12 [25280/75750 (42%)]\tTrain Loss: 0.918687\n",
      "Train Epoch: 12 [25600/75750 (42%)]\tTrain Loss: 0.773264\n",
      "Train Epoch: 12 [25920/75750 (43%)]\tTrain Loss: 0.742781\n",
      "Train Epoch: 12 [26240/75750 (43%)]\tTrain Loss: 1.297501\n",
      "Train Epoch: 12 [26560/75750 (44%)]\tTrain Loss: 1.158368\n",
      "Train Epoch: 12 [26880/75750 (44%)]\tTrain Loss: 1.100716\n",
      "Train Epoch: 12 [27200/75750 (45%)]\tTrain Loss: 0.748709\n",
      "Train Epoch: 12 [27520/75750 (45%)]\tTrain Loss: 1.032021\n",
      "Train Epoch: 12 [27840/75750 (46%)]\tTrain Loss: 1.247118\n",
      "Train Epoch: 12 [28160/75750 (46%)]\tTrain Loss: 0.852274\n",
      "Train Epoch: 12 [28480/75750 (47%)]\tTrain Loss: 0.997131\n",
      "Train Epoch: 12 [28800/75750 (48%)]\tTrain Loss: 0.862625\n",
      "Train Epoch: 12 [29120/75750 (48%)]\tTrain Loss: 1.281411\n",
      "Train Epoch: 12 [29440/75750 (49%)]\tTrain Loss: 0.882632\n",
      "Train Epoch: 12 [29760/75750 (49%)]\tTrain Loss: 0.993252\n",
      "Train Epoch: 12 [30080/75750 (50%)]\tTrain Loss: 0.815346\n",
      "Train Epoch: 12 [30400/75750 (50%)]\tTrain Loss: 0.921599\n",
      "Train Epoch: 12 [30720/75750 (51%)]\tTrain Loss: 0.811022\n",
      "Train Epoch: 12 [31040/75750 (51%)]\tTrain Loss: 1.291893\n",
      "Train Epoch: 12 [31360/75750 (52%)]\tTrain Loss: 1.190413\n",
      "Train Epoch: 12 [31680/75750 (52%)]\tTrain Loss: 1.088315\n",
      "Train Epoch: 12 [32000/75750 (53%)]\tTrain Loss: 1.133160\n",
      "Train Epoch: 12 [32320/75750 (53%)]\tTrain Loss: 0.888244\n",
      "Train Epoch: 12 [32640/75750 (54%)]\tTrain Loss: 1.322063\n",
      "Train Epoch: 12 [32960/75750 (54%)]\tTrain Loss: 0.993423\n",
      "Train Epoch: 12 [33280/75750 (55%)]\tTrain Loss: 0.749404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [33600/75750 (55%)]\tTrain Loss: 0.922843\n",
      "Train Epoch: 12 [33920/75750 (56%)]\tTrain Loss: 0.635485\n",
      "Train Epoch: 12 [34240/75750 (56%)]\tTrain Loss: 0.875888\n",
      "Train Epoch: 12 [34560/75750 (57%)]\tTrain Loss: 1.378582\n",
      "Train Epoch: 12 [34880/75750 (58%)]\tTrain Loss: 0.866558\n",
      "Train Epoch: 12 [35200/75750 (58%)]\tTrain Loss: 1.040883\n",
      "Train Epoch: 12 [35520/75750 (59%)]\tTrain Loss: 0.779150\n",
      "Train Epoch: 12 [35840/75750 (59%)]\tTrain Loss: 0.593385\n",
      "Train Epoch: 12 [36160/75750 (60%)]\tTrain Loss: 1.075934\n",
      "Train Epoch: 12 [36480/75750 (60%)]\tTrain Loss: 1.322579\n",
      "Train Epoch: 12 [36800/75750 (61%)]\tTrain Loss: 0.966639\n",
      "Train Epoch: 12 [37120/75750 (61%)]\tTrain Loss: 1.406983\n",
      "Train Epoch: 12 [37440/75750 (62%)]\tTrain Loss: 1.139616\n",
      "Train Epoch: 12 [37760/75750 (62%)]\tTrain Loss: 0.904223\n",
      "Train Epoch: 12 [38080/75750 (63%)]\tTrain Loss: 1.134802\n",
      "Train Epoch: 12 [38400/75750 (63%)]\tTrain Loss: 0.948359\n",
      "Train Epoch: 12 [38720/75750 (64%)]\tTrain Loss: 0.930167\n",
      "Train Epoch: 12 [39040/75750 (64%)]\tTrain Loss: 1.085090\n",
      "Train Epoch: 12 [39360/75750 (65%)]\tTrain Loss: 0.903160\n",
      "Train Epoch: 12 [39680/75750 (65%)]\tTrain Loss: 1.036515\n",
      "Train Epoch: 12 [40000/75750 (66%)]\tTrain Loss: 0.970652\n",
      "Train Epoch: 12 [40320/75750 (67%)]\tTrain Loss: 1.370587\n",
      "Train Epoch: 12 [40640/75750 (67%)]\tTrain Loss: 0.915589\n",
      "Train Epoch: 12 [40960/75750 (68%)]\tTrain Loss: 1.111193\n",
      "Train Epoch: 12 [41280/75750 (68%)]\tTrain Loss: 1.380467\n",
      "Train Epoch: 12 [41600/75750 (69%)]\tTrain Loss: 0.992924\n",
      "Train Epoch: 12 [41920/75750 (69%)]\tTrain Loss: 0.840811\n",
      "Train Epoch: 12 [42240/75750 (70%)]\tTrain Loss: 0.954710\n",
      "Train Epoch: 12 [42560/75750 (70%)]\tTrain Loss: 0.593940\n",
      "Train Epoch: 12 [42880/75750 (71%)]\tTrain Loss: 0.767814\n",
      "Train Epoch: 12 [43200/75750 (71%)]\tTrain Loss: 0.734353\n",
      "Train Epoch: 12 [43520/75750 (72%)]\tTrain Loss: 0.963762\n",
      "Train Epoch: 12 [43840/75750 (72%)]\tTrain Loss: 0.909641\n",
      "Train Epoch: 12 [44160/75750 (73%)]\tTrain Loss: 0.691626\n",
      "Train Epoch: 12 [44480/75750 (73%)]\tTrain Loss: 1.124919\n",
      "Train Epoch: 12 [44800/75750 (74%)]\tTrain Loss: 1.097390\n",
      "Train Epoch: 12 [45120/75750 (74%)]\tTrain Loss: 0.728282\n",
      "Train Epoch: 12 [45440/75750 (75%)]\tTrain Loss: 1.259812\n",
      "Train Epoch: 12 [45760/75750 (76%)]\tTrain Loss: 1.007515\n",
      "Train Epoch: 12 [46080/75750 (76%)]\tTrain Loss: 1.041595\n",
      "Train Epoch: 12 [46400/75750 (77%)]\tTrain Loss: 0.963364\n",
      "Train Epoch: 12 [46720/75750 (77%)]\tTrain Loss: 0.899319\n",
      "Train Epoch: 12 [47040/75750 (78%)]\tTrain Loss: 1.338566\n",
      "Train Epoch: 12 [47360/75750 (78%)]\tTrain Loss: 1.255237\n",
      "Train Epoch: 12 [47680/75750 (79%)]\tTrain Loss: 0.776059\n",
      "Train Epoch: 12 [48000/75750 (79%)]\tTrain Loss: 1.001255\n",
      "Train Epoch: 12 [48320/75750 (80%)]\tTrain Loss: 0.956531\n",
      "Train Epoch: 12 [48640/75750 (80%)]\tTrain Loss: 0.873602\n",
      "Train Epoch: 12 [48960/75750 (81%)]\tTrain Loss: 0.883343\n",
      "Train Epoch: 12 [49280/75750 (81%)]\tTrain Loss: 0.990963\n",
      "Train Epoch: 12 [49600/75750 (82%)]\tTrain Loss: 0.913369\n",
      "Train Epoch: 12 [49920/75750 (82%)]\tTrain Loss: 1.193704\n",
      "Train Epoch: 12 [50240/75750 (83%)]\tTrain Loss: 1.002099\n",
      "Train Epoch: 12 [50560/75750 (83%)]\tTrain Loss: 0.804252\n",
      "Train Epoch: 12 [50880/75750 (84%)]\tTrain Loss: 0.787633\n",
      "Train Epoch: 12 [51200/75750 (84%)]\tTrain Loss: 0.942456\n",
      "Train Epoch: 12 [51520/75750 (85%)]\tTrain Loss: 1.030601\n",
      "Train Epoch: 12 [51840/75750 (86%)]\tTrain Loss: 1.047366\n",
      "Train Epoch: 12 [52160/75750 (86%)]\tTrain Loss: 0.677384\n",
      "Train Epoch: 12 [52480/75750 (87%)]\tTrain Loss: 0.846830\n",
      "Train Epoch: 12 [52800/75750 (87%)]\tTrain Loss: 0.873588\n",
      "Train Epoch: 12 [53120/75750 (88%)]\tTrain Loss: 0.827816\n",
      "Train Epoch: 12 [53440/75750 (88%)]\tTrain Loss: 0.993737\n",
      "Train Epoch: 12 [53760/75750 (89%)]\tTrain Loss: 1.032897\n",
      "Train Epoch: 12 [54080/75750 (89%)]\tTrain Loss: 0.876143\n",
      "Train Epoch: 12 [54400/75750 (90%)]\tTrain Loss: 0.850766\n",
      "Train Epoch: 12 [54720/75750 (90%)]\tTrain Loss: 0.910620\n",
      "Train Epoch: 12 [55040/75750 (91%)]\tTrain Loss: 1.151466\n",
      "Train Epoch: 12 [55360/75750 (91%)]\tTrain Loss: 1.196320\n",
      "Train Epoch: 12 [55680/75750 (92%)]\tTrain Loss: 0.991243\n",
      "Train Epoch: 12 [56000/75750 (92%)]\tTrain Loss: 1.005797\n",
      "Train Epoch: 12 [56320/75750 (93%)]\tTrain Loss: 1.614729\n",
      "Train Epoch: 12 [56640/75750 (93%)]\tTrain Loss: 0.975015\n",
      "Train Epoch: 12 [56960/75750 (94%)]\tTrain Loss: 1.078255\n",
      "Train Epoch: 12 [57280/75750 (95%)]\tTrain Loss: 1.003160\n",
      "Train Epoch: 12 [57600/75750 (95%)]\tTrain Loss: 1.102392\n",
      "Train Epoch: 12 [57920/75750 (96%)]\tTrain Loss: 1.015426\n",
      "Train Epoch: 12 [58240/75750 (96%)]\tTrain Loss: 1.315890\n",
      "Train Epoch: 12 [58560/75750 (97%)]\tTrain Loss: 1.115987\n",
      "Train Epoch: 12 [58880/75750 (97%)]\tTrain Loss: 0.788394\n",
      "Train Epoch: 12 [59200/75750 (98%)]\tTrain Loss: 0.841246\n",
      "Train Epoch: 12 [59520/75750 (98%)]\tTrain Loss: 0.945254\n",
      "Train Epoch: 12 [59840/75750 (99%)]\tTrain Loss: 1.041839\n",
      "Train Epoch: 12 [60160/75750 (99%)]\tTrain Loss: 1.065895\n",
      "Train Epoch: 12 [60480/75750 (100%)]\tTrain Loss: 1.236132\n",
      "\n",
      "[EPOCH: 12], \tTest Loss: 0.3483, \tTest Accuracy: 60.18 % \n",
      "\n",
      "Train Epoch: 13 [0/75750 (0%)]\tTrain Loss: 0.778471\n",
      "Train Epoch: 13 [320/75750 (1%)]\tTrain Loss: 0.546756\n",
      "Train Epoch: 13 [640/75750 (1%)]\tTrain Loss: 0.833467\n",
      "Train Epoch: 13 [960/75750 (2%)]\tTrain Loss: 0.892240\n",
      "Train Epoch: 13 [1280/75750 (2%)]\tTrain Loss: 1.411780\n",
      "Train Epoch: 13 [1600/75750 (3%)]\tTrain Loss: 1.182146\n",
      "Train Epoch: 13 [1920/75750 (3%)]\tTrain Loss: 0.612961\n",
      "Train Epoch: 13 [2240/75750 (4%)]\tTrain Loss: 0.754046\n",
      "Train Epoch: 13 [2560/75750 (4%)]\tTrain Loss: 0.914175\n",
      "Train Epoch: 13 [2880/75750 (5%)]\tTrain Loss: 0.890842\n",
      "Train Epoch: 13 [3200/75750 (5%)]\tTrain Loss: 0.855797\n",
      "Train Epoch: 13 [3520/75750 (6%)]\tTrain Loss: 0.652312\n",
      "Train Epoch: 13 [3840/75750 (6%)]\tTrain Loss: 0.936750\n",
      "Train Epoch: 13 [4160/75750 (7%)]\tTrain Loss: 0.653849\n",
      "Train Epoch: 13 [4480/75750 (7%)]\tTrain Loss: 1.004650\n",
      "Train Epoch: 13 [4800/75750 (8%)]\tTrain Loss: 0.769297\n",
      "Train Epoch: 13 [5120/75750 (8%)]\tTrain Loss: 0.908400\n",
      "Train Epoch: 13 [5440/75750 (9%)]\tTrain Loss: 0.987506\n",
      "Train Epoch: 13 [5760/75750 (10%)]\tTrain Loss: 0.868505\n",
      "Train Epoch: 13 [6080/75750 (10%)]\tTrain Loss: 0.787932\n",
      "Train Epoch: 13 [6400/75750 (11%)]\tTrain Loss: 0.867922\n",
      "Train Epoch: 13 [6720/75750 (11%)]\tTrain Loss: 0.773960\n",
      "Train Epoch: 13 [7040/75750 (12%)]\tTrain Loss: 0.686741\n",
      "Train Epoch: 13 [7360/75750 (12%)]\tTrain Loss: 0.994357\n",
      "Train Epoch: 13 [7680/75750 (13%)]\tTrain Loss: 0.993732\n",
      "Train Epoch: 13 [8000/75750 (13%)]\tTrain Loss: 0.808096\n",
      "Train Epoch: 13 [8320/75750 (14%)]\tTrain Loss: 1.003531\n",
      "Train Epoch: 13 [8640/75750 (14%)]\tTrain Loss: 1.231838\n",
      "Train Epoch: 13 [8960/75750 (15%)]\tTrain Loss: 1.094948\n",
      "Train Epoch: 13 [9280/75750 (15%)]\tTrain Loss: 0.775274\n",
      "Train Epoch: 13 [9600/75750 (16%)]\tTrain Loss: 1.103653\n",
      "Train Epoch: 13 [9920/75750 (16%)]\tTrain Loss: 1.049243\n",
      "Train Epoch: 13 [10240/75750 (17%)]\tTrain Loss: 1.009528\n",
      "Train Epoch: 13 [10560/75750 (17%)]\tTrain Loss: 1.316819\n",
      "Train Epoch: 13 [10880/75750 (18%)]\tTrain Loss: 0.837767\n",
      "Train Epoch: 13 [11200/75750 (18%)]\tTrain Loss: 0.740286\n",
      "Train Epoch: 13 [11520/75750 (19%)]\tTrain Loss: 0.642097\n",
      "Train Epoch: 13 [11840/75750 (20%)]\tTrain Loss: 0.752757\n",
      "Train Epoch: 13 [12160/75750 (20%)]\tTrain Loss: 0.795595\n",
      "Train Epoch: 13 [12480/75750 (21%)]\tTrain Loss: 0.789392\n",
      "Train Epoch: 13 [12800/75750 (21%)]\tTrain Loss: 0.795798\n",
      "Train Epoch: 13 [13120/75750 (22%)]\tTrain Loss: 0.695281\n",
      "Train Epoch: 13 [13440/75750 (22%)]\tTrain Loss: 1.242643\n",
      "Train Epoch: 13 [13760/75750 (23%)]\tTrain Loss: 1.458949\n",
      "Train Epoch: 13 [14080/75750 (23%)]\tTrain Loss: 0.858430\n",
      "Train Epoch: 13 [14400/75750 (24%)]\tTrain Loss: 0.743530\n",
      "Train Epoch: 13 [14720/75750 (24%)]\tTrain Loss: 0.919251\n",
      "Train Epoch: 13 [15040/75750 (25%)]\tTrain Loss: 0.693715\n",
      "Train Epoch: 13 [15360/75750 (25%)]\tTrain Loss: 0.929398\n",
      "Train Epoch: 13 [15680/75750 (26%)]\tTrain Loss: 1.008433\n",
      "Train Epoch: 13 [16000/75750 (26%)]\tTrain Loss: 0.724146\n",
      "Train Epoch: 13 [16320/75750 (27%)]\tTrain Loss: 0.789465\n",
      "Train Epoch: 13 [16640/75750 (27%)]\tTrain Loss: 0.771667\n",
      "Train Epoch: 13 [16960/75750 (28%)]\tTrain Loss: 1.036600\n",
      "Train Epoch: 13 [17280/75750 (29%)]\tTrain Loss: 0.854188\n",
      "Train Epoch: 13 [17600/75750 (29%)]\tTrain Loss: 0.488064\n",
      "Train Epoch: 13 [17920/75750 (30%)]\tTrain Loss: 1.076329\n",
      "Train Epoch: 13 [18240/75750 (30%)]\tTrain Loss: 0.946188\n",
      "Train Epoch: 13 [18560/75750 (31%)]\tTrain Loss: 0.777673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [18880/75750 (31%)]\tTrain Loss: 1.140957\n",
      "Train Epoch: 13 [19200/75750 (32%)]\tTrain Loss: 0.902851\n",
      "Train Epoch: 13 [19520/75750 (32%)]\tTrain Loss: 1.042819\n",
      "Train Epoch: 13 [19840/75750 (33%)]\tTrain Loss: 1.112730\n",
      "Train Epoch: 13 [20160/75750 (33%)]\tTrain Loss: 1.037317\n",
      "Train Epoch: 13 [20480/75750 (34%)]\tTrain Loss: 1.038329\n",
      "Train Epoch: 13 [20800/75750 (34%)]\tTrain Loss: 1.023034\n",
      "Train Epoch: 13 [21120/75750 (35%)]\tTrain Loss: 0.651729\n",
      "Train Epoch: 13 [21440/75750 (35%)]\tTrain Loss: 1.165222\n",
      "Train Epoch: 13 [21760/75750 (36%)]\tTrain Loss: 1.129970\n",
      "Train Epoch: 13 [22080/75750 (36%)]\tTrain Loss: 0.805686\n",
      "Train Epoch: 13 [22400/75750 (37%)]\tTrain Loss: 0.900450\n",
      "Train Epoch: 13 [22720/75750 (37%)]\tTrain Loss: 0.692879\n",
      "Train Epoch: 13 [23040/75750 (38%)]\tTrain Loss: 0.833474\n",
      "Train Epoch: 13 [23360/75750 (39%)]\tTrain Loss: 1.097792\n",
      "Train Epoch: 13 [23680/75750 (39%)]\tTrain Loss: 0.926781\n",
      "Train Epoch: 13 [24000/75750 (40%)]\tTrain Loss: 1.012461\n",
      "Train Epoch: 13 [24320/75750 (40%)]\tTrain Loss: 0.825312\n",
      "Train Epoch: 13 [24640/75750 (41%)]\tTrain Loss: 0.867411\n",
      "Train Epoch: 13 [24960/75750 (41%)]\tTrain Loss: 1.034327\n",
      "Train Epoch: 13 [25280/75750 (42%)]\tTrain Loss: 0.777890\n",
      "Train Epoch: 13 [25600/75750 (42%)]\tTrain Loss: 0.835467\n",
      "Train Epoch: 13 [25920/75750 (43%)]\tTrain Loss: 0.997033\n",
      "Train Epoch: 13 [26240/75750 (43%)]\tTrain Loss: 0.920335\n",
      "Train Epoch: 13 [26560/75750 (44%)]\tTrain Loss: 1.082765\n",
      "Train Epoch: 13 [26880/75750 (44%)]\tTrain Loss: 0.962223\n",
      "Train Epoch: 13 [27200/75750 (45%)]\tTrain Loss: 0.677026\n",
      "Train Epoch: 13 [27520/75750 (45%)]\tTrain Loss: 1.017345\n",
      "Train Epoch: 13 [27840/75750 (46%)]\tTrain Loss: 0.680380\n",
      "Train Epoch: 13 [28160/75750 (46%)]\tTrain Loss: 0.908592\n",
      "Train Epoch: 13 [28480/75750 (47%)]\tTrain Loss: 1.015046\n",
      "Train Epoch: 13 [28800/75750 (48%)]\tTrain Loss: 0.761568\n",
      "Train Epoch: 13 [29120/75750 (48%)]\tTrain Loss: 0.877150\n",
      "Train Epoch: 13 [29440/75750 (49%)]\tTrain Loss: 0.784424\n",
      "Train Epoch: 13 [29760/75750 (49%)]\tTrain Loss: 0.905610\n",
      "Train Epoch: 13 [30080/75750 (50%)]\tTrain Loss: 0.932772\n",
      "Train Epoch: 13 [30400/75750 (50%)]\tTrain Loss: 1.197243\n",
      "Train Epoch: 13 [30720/75750 (51%)]\tTrain Loss: 0.891257\n",
      "Train Epoch: 13 [31040/75750 (51%)]\tTrain Loss: 0.956770\n",
      "Train Epoch: 13 [31360/75750 (52%)]\tTrain Loss: 0.763137\n",
      "Train Epoch: 13 [31680/75750 (52%)]\tTrain Loss: 0.853571\n",
      "Train Epoch: 13 [32000/75750 (53%)]\tTrain Loss: 0.981841\n",
      "Train Epoch: 13 [32320/75750 (53%)]\tTrain Loss: 1.255171\n",
      "Train Epoch: 13 [32640/75750 (54%)]\tTrain Loss: 1.012191\n",
      "Train Epoch: 13 [32960/75750 (54%)]\tTrain Loss: 0.917498\n",
      "Train Epoch: 13 [33280/75750 (55%)]\tTrain Loss: 0.810795\n",
      "Train Epoch: 13 [33600/75750 (55%)]\tTrain Loss: 0.872188\n",
      "Train Epoch: 13 [33920/75750 (56%)]\tTrain Loss: 0.887634\n",
      "Train Epoch: 13 [34240/75750 (56%)]\tTrain Loss: 0.901785\n",
      "Train Epoch: 13 [34560/75750 (57%)]\tTrain Loss: 1.157049\n",
      "Train Epoch: 13 [34880/75750 (58%)]\tTrain Loss: 0.722855\n",
      "Train Epoch: 13 [35200/75750 (58%)]\tTrain Loss: 0.892697\n",
      "Train Epoch: 13 [35520/75750 (59%)]\tTrain Loss: 0.900114\n",
      "Train Epoch: 13 [35840/75750 (59%)]\tTrain Loss: 1.139475\n",
      "Train Epoch: 13 [36160/75750 (60%)]\tTrain Loss: 0.710708\n",
      "Train Epoch: 13 [36480/75750 (60%)]\tTrain Loss: 0.890206\n",
      "Train Epoch: 13 [36800/75750 (61%)]\tTrain Loss: 1.230455\n",
      "Train Epoch: 13 [37120/75750 (61%)]\tTrain Loss: 1.076676\n",
      "Train Epoch: 13 [37440/75750 (62%)]\tTrain Loss: 0.923591\n",
      "Train Epoch: 13 [37760/75750 (62%)]\tTrain Loss: 0.766067\n",
      "Train Epoch: 13 [38080/75750 (63%)]\tTrain Loss: 0.725017\n",
      "Train Epoch: 13 [38400/75750 (63%)]\tTrain Loss: 1.049239\n",
      "Train Epoch: 13 [38720/75750 (64%)]\tTrain Loss: 0.893906\n",
      "Train Epoch: 13 [39040/75750 (64%)]\tTrain Loss: 1.036003\n",
      "Train Epoch: 13 [39360/75750 (65%)]\tTrain Loss: 1.166815\n",
      "Train Epoch: 13 [39680/75750 (65%)]\tTrain Loss: 0.694300\n",
      "Train Epoch: 13 [40000/75750 (66%)]\tTrain Loss: 0.632823\n",
      "Train Epoch: 13 [40320/75750 (67%)]\tTrain Loss: 0.843123\n",
      "Train Epoch: 13 [40640/75750 (67%)]\tTrain Loss: 0.589897\n",
      "Train Epoch: 13 [40960/75750 (68%)]\tTrain Loss: 0.777961\n",
      "Train Epoch: 13 [41280/75750 (68%)]\tTrain Loss: 0.839111\n",
      "Train Epoch: 13 [41600/75750 (69%)]\tTrain Loss: 1.319172\n",
      "Train Epoch: 13 [41920/75750 (69%)]\tTrain Loss: 1.065847\n",
      "Train Epoch: 13 [42240/75750 (70%)]\tTrain Loss: 0.972645\n",
      "Train Epoch: 13 [42560/75750 (70%)]\tTrain Loss: 1.225292\n",
      "Train Epoch: 13 [42880/75750 (71%)]\tTrain Loss: 0.928819\n",
      "Train Epoch: 13 [43200/75750 (71%)]\tTrain Loss: 1.110731\n",
      "Train Epoch: 13 [43520/75750 (72%)]\tTrain Loss: 1.092887\n",
      "Train Epoch: 13 [43840/75750 (72%)]\tTrain Loss: 1.049001\n",
      "Train Epoch: 13 [44160/75750 (73%)]\tTrain Loss: 0.862705\n",
      "Train Epoch: 13 [44480/75750 (73%)]\tTrain Loss: 0.790052\n",
      "Train Epoch: 13 [44800/75750 (74%)]\tTrain Loss: 0.825204\n",
      "Train Epoch: 13 [45120/75750 (74%)]\tTrain Loss: 0.650263\n",
      "Train Epoch: 13 [45440/75750 (75%)]\tTrain Loss: 1.143208\n",
      "Train Epoch: 13 [45760/75750 (76%)]\tTrain Loss: 1.214583\n",
      "Train Epoch: 13 [46080/75750 (76%)]\tTrain Loss: 0.934553\n",
      "Train Epoch: 13 [46400/75750 (77%)]\tTrain Loss: 0.743397\n",
      "Train Epoch: 13 [46720/75750 (77%)]\tTrain Loss: 1.066778\n",
      "Train Epoch: 13 [47040/75750 (78%)]\tTrain Loss: 0.915766\n",
      "Train Epoch: 13 [47360/75750 (78%)]\tTrain Loss: 0.734817\n",
      "Train Epoch: 13 [47680/75750 (79%)]\tTrain Loss: 0.840509\n",
      "Train Epoch: 13 [48000/75750 (79%)]\tTrain Loss: 0.720716\n",
      "Train Epoch: 13 [48320/75750 (80%)]\tTrain Loss: 0.796200\n",
      "Train Epoch: 13 [48640/75750 (80%)]\tTrain Loss: 0.705640\n",
      "Train Epoch: 13 [48960/75750 (81%)]\tTrain Loss: 1.162066\n",
      "Train Epoch: 13 [49280/75750 (81%)]\tTrain Loss: 0.861293\n",
      "Train Epoch: 13 [49600/75750 (82%)]\tTrain Loss: 0.594901\n",
      "Train Epoch: 13 [49920/75750 (82%)]\tTrain Loss: 0.792393\n",
      "Train Epoch: 13 [50240/75750 (83%)]\tTrain Loss: 0.896816\n",
      "Train Epoch: 13 [50560/75750 (83%)]\tTrain Loss: 0.748916\n",
      "Train Epoch: 13 [50880/75750 (84%)]\tTrain Loss: 0.932320\n",
      "Train Epoch: 13 [51200/75750 (84%)]\tTrain Loss: 0.859739\n",
      "Train Epoch: 13 [51520/75750 (85%)]\tTrain Loss: 1.541289\n",
      "Train Epoch: 13 [51840/75750 (86%)]\tTrain Loss: 1.336363\n",
      "Train Epoch: 13 [52160/75750 (86%)]\tTrain Loss: 0.658817\n",
      "Train Epoch: 13 [52480/75750 (87%)]\tTrain Loss: 0.754199\n",
      "Train Epoch: 13 [52800/75750 (87%)]\tTrain Loss: 0.833296\n",
      "Train Epoch: 13 [53120/75750 (88%)]\tTrain Loss: 1.063458\n",
      "Train Epoch: 13 [53440/75750 (88%)]\tTrain Loss: 0.643650\n",
      "Train Epoch: 13 [53760/75750 (89%)]\tTrain Loss: 1.147287\n",
      "Train Epoch: 13 [54080/75750 (89%)]\tTrain Loss: 0.963928\n",
      "Train Epoch: 13 [54400/75750 (90%)]\tTrain Loss: 0.932846\n",
      "Train Epoch: 13 [54720/75750 (90%)]\tTrain Loss: 0.711489\n",
      "Train Epoch: 13 [55040/75750 (91%)]\tTrain Loss: 0.827276\n",
      "Train Epoch: 13 [55360/75750 (91%)]\tTrain Loss: 0.895029\n",
      "Train Epoch: 13 [55680/75750 (92%)]\tTrain Loss: 0.983195\n",
      "Train Epoch: 13 [56000/75750 (92%)]\tTrain Loss: 0.898367\n",
      "Train Epoch: 13 [56320/75750 (93%)]\tTrain Loss: 1.076851\n",
      "Train Epoch: 13 [56640/75750 (93%)]\tTrain Loss: 0.875671\n",
      "Train Epoch: 13 [56960/75750 (94%)]\tTrain Loss: 0.798248\n",
      "Train Epoch: 13 [57280/75750 (95%)]\tTrain Loss: 0.672559\n",
      "Train Epoch: 13 [57600/75750 (95%)]\tTrain Loss: 0.830115\n",
      "Train Epoch: 13 [57920/75750 (96%)]\tTrain Loss: 0.884887\n",
      "Train Epoch: 13 [58240/75750 (96%)]\tTrain Loss: 0.864903\n",
      "Train Epoch: 13 [58560/75750 (97%)]\tTrain Loss: 0.626876\n",
      "Train Epoch: 13 [58880/75750 (97%)]\tTrain Loss: 1.116446\n",
      "Train Epoch: 13 [59200/75750 (98%)]\tTrain Loss: 0.804268\n",
      "Train Epoch: 13 [59520/75750 (98%)]\tTrain Loss: 1.298434\n",
      "Train Epoch: 13 [59840/75750 (99%)]\tTrain Loss: 1.009526\n",
      "Train Epoch: 13 [60160/75750 (99%)]\tTrain Loss: 0.975030\n",
      "Train Epoch: 13 [60480/75750 (100%)]\tTrain Loss: 0.901195\n",
      "\n",
      "[EPOCH: 13], \tTest Loss: 0.3308, \tTest Accuracy: 61.04 % \n",
      "\n",
      "Train Epoch: 14 [0/75750 (0%)]\tTrain Loss: 0.868346\n",
      "Train Epoch: 14 [320/75750 (1%)]\tTrain Loss: 0.563920\n",
      "Train Epoch: 14 [640/75750 (1%)]\tTrain Loss: 0.660934\n",
      "Train Epoch: 14 [960/75750 (2%)]\tTrain Loss: 0.731483\n",
      "Train Epoch: 14 [1280/75750 (2%)]\tTrain Loss: 0.785339\n",
      "Train Epoch: 14 [1600/75750 (3%)]\tTrain Loss: 0.549430\n",
      "Train Epoch: 14 [1920/75750 (3%)]\tTrain Loss: 0.720708\n",
      "Train Epoch: 14 [2240/75750 (4%)]\tTrain Loss: 0.674437\n",
      "Train Epoch: 14 [2560/75750 (4%)]\tTrain Loss: 0.437354\n",
      "Train Epoch: 14 [2880/75750 (5%)]\tTrain Loss: 0.788624\n",
      "Train Epoch: 14 [3200/75750 (5%)]\tTrain Loss: 0.907573\n",
      "Train Epoch: 14 [3520/75750 (6%)]\tTrain Loss: 0.768444\n",
      "Train Epoch: 14 [3840/75750 (6%)]\tTrain Loss: 0.941012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [4160/75750 (7%)]\tTrain Loss: 0.717121\n",
      "Train Epoch: 14 [4480/75750 (7%)]\tTrain Loss: 0.875898\n",
      "Train Epoch: 14 [4800/75750 (8%)]\tTrain Loss: 0.771064\n",
      "Train Epoch: 14 [5120/75750 (8%)]\tTrain Loss: 0.759658\n",
      "Train Epoch: 14 [5440/75750 (9%)]\tTrain Loss: 1.008853\n",
      "Train Epoch: 14 [5760/75750 (10%)]\tTrain Loss: 0.894525\n",
      "Train Epoch: 14 [6080/75750 (10%)]\tTrain Loss: 0.996059\n",
      "Train Epoch: 14 [6400/75750 (11%)]\tTrain Loss: 0.676102\n",
      "Train Epoch: 14 [6720/75750 (11%)]\tTrain Loss: 0.698307\n",
      "Train Epoch: 14 [7040/75750 (12%)]\tTrain Loss: 0.965171\n",
      "Train Epoch: 14 [7360/75750 (12%)]\tTrain Loss: 0.685661\n",
      "Train Epoch: 14 [7680/75750 (13%)]\tTrain Loss: 0.592710\n",
      "Train Epoch: 14 [8000/75750 (13%)]\tTrain Loss: 0.872624\n",
      "Train Epoch: 14 [8320/75750 (14%)]\tTrain Loss: 0.697675\n",
      "Train Epoch: 14 [8640/75750 (14%)]\tTrain Loss: 0.944595\n",
      "Train Epoch: 14 [8960/75750 (15%)]\tTrain Loss: 0.707439\n",
      "Train Epoch: 14 [9280/75750 (15%)]\tTrain Loss: 0.606262\n",
      "Train Epoch: 14 [9600/75750 (16%)]\tTrain Loss: 0.984009\n",
      "Train Epoch: 14 [9920/75750 (16%)]\tTrain Loss: 0.585841\n",
      "Train Epoch: 14 [10240/75750 (17%)]\tTrain Loss: 0.920453\n",
      "Train Epoch: 14 [10560/75750 (17%)]\tTrain Loss: 0.961347\n",
      "Train Epoch: 14 [10880/75750 (18%)]\tTrain Loss: 0.902187\n",
      "Train Epoch: 14 [11200/75750 (18%)]\tTrain Loss: 0.606424\n",
      "Train Epoch: 14 [11520/75750 (19%)]\tTrain Loss: 0.776849\n",
      "Train Epoch: 14 [11840/75750 (20%)]\tTrain Loss: 0.851274\n",
      "Train Epoch: 14 [12160/75750 (20%)]\tTrain Loss: 0.723253\n",
      "Train Epoch: 14 [12480/75750 (21%)]\tTrain Loss: 0.728470\n",
      "Train Epoch: 14 [12800/75750 (21%)]\tTrain Loss: 0.998359\n",
      "Train Epoch: 14 [13120/75750 (22%)]\tTrain Loss: 0.563680\n",
      "Train Epoch: 14 [13440/75750 (22%)]\tTrain Loss: 0.893795\n",
      "Train Epoch: 14 [13760/75750 (23%)]\tTrain Loss: 0.945182\n",
      "Train Epoch: 14 [14080/75750 (23%)]\tTrain Loss: 0.451325\n",
      "Train Epoch: 14 [14400/75750 (24%)]\tTrain Loss: 0.957308\n",
      "Train Epoch: 14 [14720/75750 (24%)]\tTrain Loss: 0.941998\n",
      "Train Epoch: 14 [15040/75750 (25%)]\tTrain Loss: 0.939577\n",
      "Train Epoch: 14 [15360/75750 (25%)]\tTrain Loss: 0.644647\n",
      "Train Epoch: 14 [15680/75750 (26%)]\tTrain Loss: 0.690138\n",
      "Train Epoch: 14 [16000/75750 (26%)]\tTrain Loss: 0.616149\n",
      "Train Epoch: 14 [16320/75750 (27%)]\tTrain Loss: 0.927337\n",
      "Train Epoch: 14 [16640/75750 (27%)]\tTrain Loss: 0.757737\n",
      "Train Epoch: 14 [16960/75750 (28%)]\tTrain Loss: 0.622110\n",
      "Train Epoch: 14 [17280/75750 (29%)]\tTrain Loss: 0.706950\n",
      "Train Epoch: 14 [17600/75750 (29%)]\tTrain Loss: 0.872511\n",
      "Train Epoch: 14 [17920/75750 (30%)]\tTrain Loss: 0.677824\n",
      "Train Epoch: 14 [18240/75750 (30%)]\tTrain Loss: 0.890632\n",
      "Train Epoch: 14 [18560/75750 (31%)]\tTrain Loss: 0.790288\n",
      "Train Epoch: 14 [18880/75750 (31%)]\tTrain Loss: 0.961583\n",
      "Train Epoch: 14 [19200/75750 (32%)]\tTrain Loss: 0.758156\n",
      "Train Epoch: 14 [19520/75750 (32%)]\tTrain Loss: 0.581958\n",
      "Train Epoch: 14 [19840/75750 (33%)]\tTrain Loss: 0.978037\n",
      "Train Epoch: 14 [20160/75750 (33%)]\tTrain Loss: 0.641384\n",
      "Train Epoch: 14 [20480/75750 (34%)]\tTrain Loss: 0.714760\n",
      "Train Epoch: 14 [20800/75750 (34%)]\tTrain Loss: 1.028519\n",
      "Train Epoch: 14 [21120/75750 (35%)]\tTrain Loss: 1.122932\n",
      "Train Epoch: 14 [21440/75750 (35%)]\tTrain Loss: 0.678476\n",
      "Train Epoch: 14 [21760/75750 (36%)]\tTrain Loss: 0.641486\n",
      "Train Epoch: 14 [22080/75750 (36%)]\tTrain Loss: 1.193169\n",
      "Train Epoch: 14 [22400/75750 (37%)]\tTrain Loss: 0.827365\n",
      "Train Epoch: 14 [22720/75750 (37%)]\tTrain Loss: 0.562782\n",
      "Train Epoch: 14 [23040/75750 (38%)]\tTrain Loss: 0.575100\n",
      "Train Epoch: 14 [23360/75750 (39%)]\tTrain Loss: 0.701823\n",
      "Train Epoch: 14 [23680/75750 (39%)]\tTrain Loss: 0.830029\n",
      "Train Epoch: 14 [24000/75750 (40%)]\tTrain Loss: 0.969165\n",
      "Train Epoch: 14 [24320/75750 (40%)]\tTrain Loss: 0.953433\n",
      "Train Epoch: 14 [24640/75750 (41%)]\tTrain Loss: 0.923009\n",
      "Train Epoch: 14 [24960/75750 (41%)]\tTrain Loss: 0.677896\n",
      "Train Epoch: 14 [25280/75750 (42%)]\tTrain Loss: 0.880986\n",
      "Train Epoch: 14 [25600/75750 (42%)]\tTrain Loss: 0.687988\n",
      "Train Epoch: 14 [25920/75750 (43%)]\tTrain Loss: 0.644113\n",
      "Train Epoch: 14 [26240/75750 (43%)]\tTrain Loss: 0.586336\n",
      "Train Epoch: 14 [26560/75750 (44%)]\tTrain Loss: 0.831242\n",
      "Train Epoch: 14 [26880/75750 (44%)]\tTrain Loss: 0.776786\n",
      "Train Epoch: 14 [27200/75750 (45%)]\tTrain Loss: 0.920066\n",
      "Train Epoch: 14 [27520/75750 (45%)]\tTrain Loss: 0.785353\n",
      "Train Epoch: 14 [27840/75750 (46%)]\tTrain Loss: 1.105283\n",
      "Train Epoch: 14 [28160/75750 (46%)]\tTrain Loss: 0.840895\n",
      "Train Epoch: 14 [28480/75750 (47%)]\tTrain Loss: 0.936831\n",
      "Train Epoch: 14 [28800/75750 (48%)]\tTrain Loss: 0.965337\n",
      "Train Epoch: 14 [29120/75750 (48%)]\tTrain Loss: 0.666758\n",
      "Train Epoch: 14 [29440/75750 (49%)]\tTrain Loss: 0.929763\n",
      "Train Epoch: 14 [29760/75750 (49%)]\tTrain Loss: 0.971359\n",
      "Train Epoch: 14 [30080/75750 (50%)]\tTrain Loss: 0.683955\n",
      "Train Epoch: 14 [30400/75750 (50%)]\tTrain Loss: 0.880110\n",
      "Train Epoch: 14 [30720/75750 (51%)]\tTrain Loss: 0.846117\n",
      "Train Epoch: 14 [31040/75750 (51%)]\tTrain Loss: 0.731560\n",
      "Train Epoch: 14 [31360/75750 (52%)]\tTrain Loss: 0.654284\n",
      "Train Epoch: 14 [31680/75750 (52%)]\tTrain Loss: 0.586828\n",
      "Train Epoch: 14 [32000/75750 (53%)]\tTrain Loss: 1.108941\n",
      "Train Epoch: 14 [32320/75750 (53%)]\tTrain Loss: 0.882829\n",
      "Train Epoch: 14 [32640/75750 (54%)]\tTrain Loss: 0.880782\n",
      "Train Epoch: 14 [32960/75750 (54%)]\tTrain Loss: 1.232001\n",
      "Train Epoch: 14 [33280/75750 (55%)]\tTrain Loss: 0.982569\n",
      "Train Epoch: 14 [33600/75750 (55%)]\tTrain Loss: 0.889816\n",
      "Train Epoch: 14 [33920/75750 (56%)]\tTrain Loss: 1.313793\n",
      "Train Epoch: 14 [34240/75750 (56%)]\tTrain Loss: 0.987424\n",
      "Train Epoch: 14 [34560/75750 (57%)]\tTrain Loss: 1.013736\n",
      "Train Epoch: 14 [34880/75750 (58%)]\tTrain Loss: 0.629000\n",
      "Train Epoch: 14 [35200/75750 (58%)]\tTrain Loss: 0.597538\n",
      "Train Epoch: 14 [35520/75750 (59%)]\tTrain Loss: 0.701791\n",
      "Train Epoch: 14 [35840/75750 (59%)]\tTrain Loss: 1.104962\n",
      "Train Epoch: 14 [36160/75750 (60%)]\tTrain Loss: 0.665561\n",
      "Train Epoch: 14 [36480/75750 (60%)]\tTrain Loss: 0.864163\n",
      "Train Epoch: 14 [36800/75750 (61%)]\tTrain Loss: 0.753206\n",
      "Train Epoch: 14 [37120/75750 (61%)]\tTrain Loss: 0.781326\n",
      "Train Epoch: 14 [37440/75750 (62%)]\tTrain Loss: 0.818865\n",
      "Train Epoch: 14 [37760/75750 (62%)]\tTrain Loss: 0.912926\n",
      "Train Epoch: 14 [38080/75750 (63%)]\tTrain Loss: 0.713346\n",
      "Train Epoch: 14 [38400/75750 (63%)]\tTrain Loss: 0.547756\n",
      "Train Epoch: 14 [38720/75750 (64%)]\tTrain Loss: 0.722738\n",
      "Train Epoch: 14 [39040/75750 (64%)]\tTrain Loss: 0.649948\n",
      "Train Epoch: 14 [39360/75750 (65%)]\tTrain Loss: 0.612010\n",
      "Train Epoch: 14 [39680/75750 (65%)]\tTrain Loss: 1.218558\n",
      "Train Epoch: 14 [40000/75750 (66%)]\tTrain Loss: 0.761087\n",
      "Train Epoch: 14 [40320/75750 (67%)]\tTrain Loss: 0.664192\n",
      "Train Epoch: 14 [40640/75750 (67%)]\tTrain Loss: 0.986613\n",
      "Train Epoch: 14 [40960/75750 (68%)]\tTrain Loss: 0.892189\n",
      "Train Epoch: 14 [41280/75750 (68%)]\tTrain Loss: 0.918668\n",
      "Train Epoch: 14 [41600/75750 (69%)]\tTrain Loss: 1.343632\n",
      "Train Epoch: 14 [41920/75750 (69%)]\tTrain Loss: 0.848346\n",
      "Train Epoch: 14 [42240/75750 (70%)]\tTrain Loss: 0.769423\n",
      "Train Epoch: 14 [42560/75750 (70%)]\tTrain Loss: 0.599314\n",
      "Train Epoch: 14 [42880/75750 (71%)]\tTrain Loss: 0.586606\n",
      "Train Epoch: 14 [43200/75750 (71%)]\tTrain Loss: 0.884859\n",
      "Train Epoch: 14 [43520/75750 (72%)]\tTrain Loss: 0.955483\n",
      "Train Epoch: 14 [43840/75750 (72%)]\tTrain Loss: 1.018405\n",
      "Train Epoch: 14 [44160/75750 (73%)]\tTrain Loss: 0.738498\n",
      "Train Epoch: 14 [44480/75750 (73%)]\tTrain Loss: 0.900191\n",
      "Train Epoch: 14 [44800/75750 (74%)]\tTrain Loss: 0.460065\n",
      "Train Epoch: 14 [45120/75750 (74%)]\tTrain Loss: 0.913385\n",
      "Train Epoch: 14 [45440/75750 (75%)]\tTrain Loss: 0.850556\n",
      "Train Epoch: 14 [45760/75750 (76%)]\tTrain Loss: 0.997617\n",
      "Train Epoch: 14 [46080/75750 (76%)]\tTrain Loss: 0.882606\n",
      "Train Epoch: 14 [46400/75750 (77%)]\tTrain Loss: 0.769932\n",
      "Train Epoch: 14 [46720/75750 (77%)]\tTrain Loss: 0.847024\n",
      "Train Epoch: 14 [47040/75750 (78%)]\tTrain Loss: 0.968326\n",
      "Train Epoch: 14 [47360/75750 (78%)]\tTrain Loss: 0.818426\n",
      "Train Epoch: 14 [47680/75750 (79%)]\tTrain Loss: 0.797028\n",
      "Train Epoch: 14 [48000/75750 (79%)]\tTrain Loss: 0.878084\n",
      "Train Epoch: 14 [48320/75750 (80%)]\tTrain Loss: 0.634529\n",
      "Train Epoch: 14 [48640/75750 (80%)]\tTrain Loss: 0.876155\n",
      "Train Epoch: 14 [48960/75750 (81%)]\tTrain Loss: 0.963535\n",
      "Train Epoch: 14 [49280/75750 (81%)]\tTrain Loss: 0.720049\n",
      "Train Epoch: 14 [49600/75750 (82%)]\tTrain Loss: 0.716821\n",
      "Train Epoch: 14 [49920/75750 (82%)]\tTrain Loss: 0.925117\n",
      "Train Epoch: 14 [50240/75750 (83%)]\tTrain Loss: 0.829911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [50560/75750 (83%)]\tTrain Loss: 0.833166\n",
      "Train Epoch: 14 [50880/75750 (84%)]\tTrain Loss: 0.747296\n",
      "Train Epoch: 14 [51200/75750 (84%)]\tTrain Loss: 0.852888\n",
      "Train Epoch: 14 [51520/75750 (85%)]\tTrain Loss: 1.151057\n",
      "Train Epoch: 14 [51840/75750 (86%)]\tTrain Loss: 0.992732\n",
      "Train Epoch: 14 [52160/75750 (86%)]\tTrain Loss: 0.639962\n",
      "Train Epoch: 14 [52480/75750 (87%)]\tTrain Loss: 0.536770\n",
      "Train Epoch: 14 [52800/75750 (87%)]\tTrain Loss: 1.364442\n",
      "Train Epoch: 14 [53120/75750 (88%)]\tTrain Loss: 0.702759\n",
      "Train Epoch: 14 [53440/75750 (88%)]\tTrain Loss: 0.647595\n",
      "Train Epoch: 14 [53760/75750 (89%)]\tTrain Loss: 0.972533\n",
      "Train Epoch: 14 [54080/75750 (89%)]\tTrain Loss: 0.765920\n",
      "Train Epoch: 14 [54400/75750 (90%)]\tTrain Loss: 0.993301\n",
      "Train Epoch: 14 [54720/75750 (90%)]\tTrain Loss: 0.794173\n",
      "Train Epoch: 14 [55040/75750 (91%)]\tTrain Loss: 1.127444\n",
      "Train Epoch: 14 [55360/75750 (91%)]\tTrain Loss: 1.090046\n",
      "Train Epoch: 14 [55680/75750 (92%)]\tTrain Loss: 0.854703\n",
      "Train Epoch: 14 [56000/75750 (92%)]\tTrain Loss: 0.958701\n",
      "Train Epoch: 14 [56320/75750 (93%)]\tTrain Loss: 1.044887\n",
      "Train Epoch: 14 [56640/75750 (93%)]\tTrain Loss: 1.186935\n",
      "Train Epoch: 14 [56960/75750 (94%)]\tTrain Loss: 0.772069\n",
      "Train Epoch: 14 [57280/75750 (95%)]\tTrain Loss: 0.722352\n",
      "Train Epoch: 14 [57600/75750 (95%)]\tTrain Loss: 0.701904\n",
      "Train Epoch: 14 [57920/75750 (96%)]\tTrain Loss: 1.089608\n",
      "Train Epoch: 14 [58240/75750 (96%)]\tTrain Loss: 0.816436\n",
      "Train Epoch: 14 [58560/75750 (97%)]\tTrain Loss: 1.004638\n",
      "Train Epoch: 14 [58880/75750 (97%)]\tTrain Loss: 0.721490\n",
      "Train Epoch: 14 [59200/75750 (98%)]\tTrain Loss: 0.886661\n",
      "Train Epoch: 14 [59520/75750 (98%)]\tTrain Loss: 0.992354\n",
      "Train Epoch: 14 [59840/75750 (99%)]\tTrain Loss: 1.350083\n",
      "Train Epoch: 14 [60160/75750 (99%)]\tTrain Loss: 1.061490\n",
      "Train Epoch: 14 [60480/75750 (100%)]\tTrain Loss: 1.170968\n",
      "\n",
      "[EPOCH: 14], \tTest Loss: 0.3615, \tTest Accuracy: 59.40 % \n",
      "\n",
      "Train Epoch: 15 [0/75750 (0%)]\tTrain Loss: 0.951475\n",
      "Train Epoch: 15 [320/75750 (1%)]\tTrain Loss: 0.724400\n",
      "Train Epoch: 15 [640/75750 (1%)]\tTrain Loss: 0.470817\n",
      "Train Epoch: 15 [960/75750 (2%)]\tTrain Loss: 0.665184\n",
      "Train Epoch: 15 [1280/75750 (2%)]\tTrain Loss: 1.022070\n",
      "Train Epoch: 15 [1600/75750 (3%)]\tTrain Loss: 0.847228\n",
      "Train Epoch: 15 [1920/75750 (3%)]\tTrain Loss: 1.031251\n",
      "Train Epoch: 15 [2240/75750 (4%)]\tTrain Loss: 0.621702\n",
      "Train Epoch: 15 [2560/75750 (4%)]\tTrain Loss: 0.701859\n",
      "Train Epoch: 15 [2880/75750 (5%)]\tTrain Loss: 0.841279\n",
      "Train Epoch: 15 [3200/75750 (5%)]\tTrain Loss: 0.744738\n",
      "Train Epoch: 15 [3520/75750 (6%)]\tTrain Loss: 0.633548\n",
      "Train Epoch: 15 [3840/75750 (6%)]\tTrain Loss: 0.883033\n",
      "Train Epoch: 15 [4160/75750 (7%)]\tTrain Loss: 0.781148\n",
      "Train Epoch: 15 [4480/75750 (7%)]\tTrain Loss: 0.783996\n",
      "Train Epoch: 15 [4800/75750 (8%)]\tTrain Loss: 0.600060\n",
      "Train Epoch: 15 [5120/75750 (8%)]\tTrain Loss: 0.838655\n",
      "Train Epoch: 15 [5440/75750 (9%)]\tTrain Loss: 0.644939\n",
      "Train Epoch: 15 [5760/75750 (10%)]\tTrain Loss: 0.729363\n",
      "Train Epoch: 15 [6080/75750 (10%)]\tTrain Loss: 0.759450\n",
      "Train Epoch: 15 [6400/75750 (11%)]\tTrain Loss: 0.651506\n",
      "Train Epoch: 15 [6720/75750 (11%)]\tTrain Loss: 0.602175\n",
      "Train Epoch: 15 [7040/75750 (12%)]\tTrain Loss: 0.907486\n",
      "Train Epoch: 15 [7360/75750 (12%)]\tTrain Loss: 0.840336\n",
      "Train Epoch: 15 [7680/75750 (13%)]\tTrain Loss: 0.693721\n",
      "Train Epoch: 15 [8000/75750 (13%)]\tTrain Loss: 0.868878\n",
      "Train Epoch: 15 [8320/75750 (14%)]\tTrain Loss: 0.427284\n",
      "Train Epoch: 15 [8640/75750 (14%)]\tTrain Loss: 0.552979\n",
      "Train Epoch: 15 [8960/75750 (15%)]\tTrain Loss: 0.768246\n",
      "Train Epoch: 15 [9280/75750 (15%)]\tTrain Loss: 0.677106\n",
      "Train Epoch: 15 [9600/75750 (16%)]\tTrain Loss: 0.779989\n",
      "Train Epoch: 15 [9920/75750 (16%)]\tTrain Loss: 0.760244\n",
      "Train Epoch: 15 [10240/75750 (17%)]\tTrain Loss: 0.992382\n",
      "Train Epoch: 15 [10560/75750 (17%)]\tTrain Loss: 0.668854\n",
      "Train Epoch: 15 [10880/75750 (18%)]\tTrain Loss: 1.072470\n",
      "Train Epoch: 15 [11200/75750 (18%)]\tTrain Loss: 0.702214\n",
      "Train Epoch: 15 [11520/75750 (19%)]\tTrain Loss: 0.794487\n",
      "Train Epoch: 15 [11840/75750 (20%)]\tTrain Loss: 0.568098\n",
      "Train Epoch: 15 [12160/75750 (20%)]\tTrain Loss: 0.588160\n",
      "Train Epoch: 15 [12480/75750 (21%)]\tTrain Loss: 0.921808\n",
      "Train Epoch: 15 [12800/75750 (21%)]\tTrain Loss: 0.895311\n",
      "Train Epoch: 15 [13120/75750 (22%)]\tTrain Loss: 0.503861\n",
      "Train Epoch: 15 [13440/75750 (22%)]\tTrain Loss: 0.779420\n",
      "Train Epoch: 15 [13760/75750 (23%)]\tTrain Loss: 0.751279\n",
      "Train Epoch: 15 [14080/75750 (23%)]\tTrain Loss: 0.680348\n",
      "Train Epoch: 15 [14400/75750 (24%)]\tTrain Loss: 0.627607\n",
      "Train Epoch: 15 [14720/75750 (24%)]\tTrain Loss: 0.890170\n",
      "Train Epoch: 15 [15040/75750 (25%)]\tTrain Loss: 0.906328\n",
      "Train Epoch: 15 [15360/75750 (25%)]\tTrain Loss: 0.765100\n",
      "Train Epoch: 15 [15680/75750 (26%)]\tTrain Loss: 0.702932\n",
      "Train Epoch: 15 [16000/75750 (26%)]\tTrain Loss: 0.752148\n",
      "Train Epoch: 15 [16320/75750 (27%)]\tTrain Loss: 0.823874\n",
      "Train Epoch: 15 [16640/75750 (27%)]\tTrain Loss: 0.609572\n",
      "Train Epoch: 15 [16960/75750 (28%)]\tTrain Loss: 0.734002\n",
      "Train Epoch: 15 [17280/75750 (29%)]\tTrain Loss: 0.952776\n",
      "Train Epoch: 15 [17600/75750 (29%)]\tTrain Loss: 0.771261\n",
      "Train Epoch: 15 [17920/75750 (30%)]\tTrain Loss: 0.778920\n",
      "Train Epoch: 15 [18240/75750 (30%)]\tTrain Loss: 0.801134\n",
      "Train Epoch: 15 [18560/75750 (31%)]\tTrain Loss: 0.615936\n",
      "Train Epoch: 15 [18880/75750 (31%)]\tTrain Loss: 0.855403\n",
      "Train Epoch: 15 [19200/75750 (32%)]\tTrain Loss: 0.975578\n",
      "Train Epoch: 15 [19520/75750 (32%)]\tTrain Loss: 0.870715\n",
      "Train Epoch: 15 [19840/75750 (33%)]\tTrain Loss: 0.569269\n",
      "Train Epoch: 15 [20160/75750 (33%)]\tTrain Loss: 1.122591\n",
      "Train Epoch: 15 [20480/75750 (34%)]\tTrain Loss: 0.638743\n",
      "Train Epoch: 15 [20800/75750 (34%)]\tTrain Loss: 0.870596\n",
      "Train Epoch: 15 [21120/75750 (35%)]\tTrain Loss: 0.812584\n",
      "Train Epoch: 15 [21440/75750 (35%)]\tTrain Loss: 0.977308\n",
      "Train Epoch: 15 [21760/75750 (36%)]\tTrain Loss: 0.776824\n",
      "Train Epoch: 15 [22080/75750 (36%)]\tTrain Loss: 0.939903\n",
      "Train Epoch: 15 [22400/75750 (37%)]\tTrain Loss: 0.792163\n",
      "Train Epoch: 15 [22720/75750 (37%)]\tTrain Loss: 0.954985\n",
      "Train Epoch: 15 [23040/75750 (38%)]\tTrain Loss: 0.763660\n",
      "Train Epoch: 15 [23360/75750 (39%)]\tTrain Loss: 0.873999\n",
      "Train Epoch: 15 [23680/75750 (39%)]\tTrain Loss: 0.760361\n",
      "Train Epoch: 15 [24000/75750 (40%)]\tTrain Loss: 0.941837\n",
      "Train Epoch: 15 [24320/75750 (40%)]\tTrain Loss: 0.798430\n",
      "Train Epoch: 15 [24640/75750 (41%)]\tTrain Loss: 0.743923\n",
      "Train Epoch: 15 [24960/75750 (41%)]\tTrain Loss: 0.859691\n",
      "Train Epoch: 15 [25280/75750 (42%)]\tTrain Loss: 1.101754\n",
      "Train Epoch: 15 [25600/75750 (42%)]\tTrain Loss: 0.772519\n",
      "Train Epoch: 15 [25920/75750 (43%)]\tTrain Loss: 0.961898\n",
      "Train Epoch: 15 [26240/75750 (43%)]\tTrain Loss: 0.765428\n",
      "Train Epoch: 15 [26560/75750 (44%)]\tTrain Loss: 0.819255\n",
      "Train Epoch: 15 [26880/75750 (44%)]\tTrain Loss: 0.676118\n",
      "Train Epoch: 15 [27200/75750 (45%)]\tTrain Loss: 0.732880\n",
      "Train Epoch: 15 [27520/75750 (45%)]\tTrain Loss: 0.667611\n",
      "Train Epoch: 15 [27840/75750 (46%)]\tTrain Loss: 0.541064\n",
      "Train Epoch: 15 [28160/75750 (46%)]\tTrain Loss: 0.665415\n",
      "Train Epoch: 15 [28480/75750 (47%)]\tTrain Loss: 0.875354\n",
      "Train Epoch: 15 [28800/75750 (48%)]\tTrain Loss: 0.574786\n",
      "Train Epoch: 15 [29120/75750 (48%)]\tTrain Loss: 0.659945\n",
      "Train Epoch: 15 [29440/75750 (49%)]\tTrain Loss: 1.317725\n",
      "Train Epoch: 15 [29760/75750 (49%)]\tTrain Loss: 0.575554\n",
      "Train Epoch: 15 [30080/75750 (50%)]\tTrain Loss: 0.881993\n",
      "Train Epoch: 15 [30400/75750 (50%)]\tTrain Loss: 0.861717\n",
      "Train Epoch: 15 [30720/75750 (51%)]\tTrain Loss: 0.939161\n",
      "Train Epoch: 15 [31040/75750 (51%)]\tTrain Loss: 1.395718\n",
      "Train Epoch: 15 [31360/75750 (52%)]\tTrain Loss: 0.803779\n",
      "Train Epoch: 15 [31680/75750 (52%)]\tTrain Loss: 0.887817\n",
      "Train Epoch: 15 [32000/75750 (53%)]\tTrain Loss: 0.889319\n",
      "Train Epoch: 15 [32320/75750 (53%)]\tTrain Loss: 0.900364\n",
      "Train Epoch: 15 [32640/75750 (54%)]\tTrain Loss: 0.648657\n",
      "Train Epoch: 15 [32960/75750 (54%)]\tTrain Loss: 0.800266\n",
      "Train Epoch: 15 [33280/75750 (55%)]\tTrain Loss: 0.885214\n",
      "Train Epoch: 15 [33600/75750 (55%)]\tTrain Loss: 0.594118\n",
      "Train Epoch: 15 [33920/75750 (56%)]\tTrain Loss: 0.497622\n",
      "Train Epoch: 15 [34240/75750 (56%)]\tTrain Loss: 0.898310\n",
      "Train Epoch: 15 [34560/75750 (57%)]\tTrain Loss: 0.683401\n",
      "Train Epoch: 15 [34880/75750 (58%)]\tTrain Loss: 0.681181\n",
      "Train Epoch: 15 [35200/75750 (58%)]\tTrain Loss: 0.843096\n",
      "Train Epoch: 15 [35520/75750 (59%)]\tTrain Loss: 1.011673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [35840/75750 (59%)]\tTrain Loss: 1.128998\n",
      "Train Epoch: 15 [36160/75750 (60%)]\tTrain Loss: 1.014287\n",
      "Train Epoch: 15 [36480/75750 (60%)]\tTrain Loss: 0.827538\n",
      "Train Epoch: 15 [36800/75750 (61%)]\tTrain Loss: 0.742767\n",
      "Train Epoch: 15 [37120/75750 (61%)]\tTrain Loss: 0.692186\n",
      "Train Epoch: 15 [37440/75750 (62%)]\tTrain Loss: 1.062421\n",
      "Train Epoch: 15 [37760/75750 (62%)]\tTrain Loss: 0.993663\n",
      "Train Epoch: 15 [38080/75750 (63%)]\tTrain Loss: 0.596522\n",
      "Train Epoch: 15 [38400/75750 (63%)]\tTrain Loss: 0.762940\n",
      "Train Epoch: 15 [38720/75750 (64%)]\tTrain Loss: 0.629964\n",
      "Train Epoch: 15 [39040/75750 (64%)]\tTrain Loss: 0.936071\n",
      "Train Epoch: 15 [39360/75750 (65%)]\tTrain Loss: 0.840039\n",
      "Train Epoch: 15 [39680/75750 (65%)]\tTrain Loss: 1.071028\n",
      "Train Epoch: 15 [40000/75750 (66%)]\tTrain Loss: 0.777771\n",
      "Train Epoch: 15 [40320/75750 (67%)]\tTrain Loss: 1.030510\n",
      "Train Epoch: 15 [40640/75750 (67%)]\tTrain Loss: 0.793886\n",
      "Train Epoch: 15 [40960/75750 (68%)]\tTrain Loss: 0.838465\n",
      "Train Epoch: 15 [41280/75750 (68%)]\tTrain Loss: 0.924177\n",
      "Train Epoch: 15 [41600/75750 (69%)]\tTrain Loss: 0.733081\n",
      "Train Epoch: 15 [41920/75750 (69%)]\tTrain Loss: 0.908078\n",
      "Train Epoch: 15 [42240/75750 (70%)]\tTrain Loss: 0.857970\n",
      "Train Epoch: 15 [42560/75750 (70%)]\tTrain Loss: 0.997797\n",
      "Train Epoch: 15 [42880/75750 (71%)]\tTrain Loss: 0.727604\n",
      "Train Epoch: 15 [43200/75750 (71%)]\tTrain Loss: 0.885455\n",
      "Train Epoch: 15 [43520/75750 (72%)]\tTrain Loss: 1.039177\n",
      "Train Epoch: 15 [43840/75750 (72%)]\tTrain Loss: 0.748939\n",
      "Train Epoch: 15 [44160/75750 (73%)]\tTrain Loss: 1.002686\n",
      "Train Epoch: 15 [44480/75750 (73%)]\tTrain Loss: 0.930782\n",
      "Train Epoch: 15 [44800/75750 (74%)]\tTrain Loss: 0.744506\n",
      "Train Epoch: 15 [45120/75750 (74%)]\tTrain Loss: 0.721320\n",
      "Train Epoch: 15 [45440/75750 (75%)]\tTrain Loss: 0.710216\n",
      "Train Epoch: 15 [45760/75750 (76%)]\tTrain Loss: 0.791930\n",
      "Train Epoch: 15 [46080/75750 (76%)]\tTrain Loss: 0.907045\n",
      "Train Epoch: 15 [46400/75750 (77%)]\tTrain Loss: 0.889888\n",
      "Train Epoch: 15 [46720/75750 (77%)]\tTrain Loss: 0.747450\n",
      "Train Epoch: 15 [47040/75750 (78%)]\tTrain Loss: 0.989953\n",
      "Train Epoch: 15 [47360/75750 (78%)]\tTrain Loss: 0.619566\n",
      "Train Epoch: 15 [47680/75750 (79%)]\tTrain Loss: 0.926623\n",
      "Train Epoch: 15 [48000/75750 (79%)]\tTrain Loss: 0.683442\n",
      "Train Epoch: 15 [48320/75750 (80%)]\tTrain Loss: 0.729524\n",
      "Train Epoch: 15 [48640/75750 (80%)]\tTrain Loss: 0.932219\n",
      "Train Epoch: 15 [48960/75750 (81%)]\tTrain Loss: 0.705137\n",
      "Train Epoch: 15 [49280/75750 (81%)]\tTrain Loss: 0.885234\n",
      "Train Epoch: 15 [49600/75750 (82%)]\tTrain Loss: 1.022522\n",
      "Train Epoch: 15 [49920/75750 (82%)]\tTrain Loss: 0.547064\n",
      "Train Epoch: 15 [50240/75750 (83%)]\tTrain Loss: 0.942955\n",
      "Train Epoch: 15 [50560/75750 (83%)]\tTrain Loss: 0.648317\n",
      "Train Epoch: 15 [50880/75750 (84%)]\tTrain Loss: 0.779498\n",
      "Train Epoch: 15 [51200/75750 (84%)]\tTrain Loss: 0.830162\n",
      "Train Epoch: 15 [51520/75750 (85%)]\tTrain Loss: 0.590810\n",
      "Train Epoch: 15 [51840/75750 (86%)]\tTrain Loss: 0.846816\n",
      "Train Epoch: 15 [52160/75750 (86%)]\tTrain Loss: 1.402876\n",
      "Train Epoch: 15 [52480/75750 (87%)]\tTrain Loss: 0.912076\n",
      "Train Epoch: 15 [52800/75750 (87%)]\tTrain Loss: 0.805336\n",
      "Train Epoch: 15 [53120/75750 (88%)]\tTrain Loss: 1.244358\n",
      "Train Epoch: 15 [53440/75750 (88%)]\tTrain Loss: 0.689970\n",
      "Train Epoch: 15 [53760/75750 (89%)]\tTrain Loss: 0.750609\n",
      "Train Epoch: 15 [54080/75750 (89%)]\tTrain Loss: 0.920250\n",
      "Train Epoch: 15 [54400/75750 (90%)]\tTrain Loss: 0.850360\n",
      "Train Epoch: 15 [54720/75750 (90%)]\tTrain Loss: 0.865512\n",
      "Train Epoch: 15 [55040/75750 (91%)]\tTrain Loss: 0.926870\n",
      "Train Epoch: 15 [55360/75750 (91%)]\tTrain Loss: 1.228501\n",
      "Train Epoch: 15 [55680/75750 (92%)]\tTrain Loss: 0.832705\n",
      "Train Epoch: 15 [56000/75750 (92%)]\tTrain Loss: 1.037653\n",
      "Train Epoch: 15 [56320/75750 (93%)]\tTrain Loss: 0.800376\n",
      "Train Epoch: 15 [56640/75750 (93%)]\tTrain Loss: 0.913716\n",
      "Train Epoch: 15 [56960/75750 (94%)]\tTrain Loss: 1.267894\n",
      "Train Epoch: 15 [57280/75750 (95%)]\tTrain Loss: 0.942718\n",
      "Train Epoch: 15 [57600/75750 (95%)]\tTrain Loss: 0.807341\n",
      "Train Epoch: 15 [57920/75750 (96%)]\tTrain Loss: 1.067830\n",
      "Train Epoch: 15 [58240/75750 (96%)]\tTrain Loss: 0.959209\n",
      "Train Epoch: 15 [58560/75750 (97%)]\tTrain Loss: 1.032032\n",
      "Train Epoch: 15 [58880/75750 (97%)]\tTrain Loss: 0.674545\n",
      "Train Epoch: 15 [59200/75750 (98%)]\tTrain Loss: 0.752025\n",
      "Train Epoch: 15 [59520/75750 (98%)]\tTrain Loss: 0.818250\n",
      "Train Epoch: 15 [59840/75750 (99%)]\tTrain Loss: 0.922861\n",
      "Train Epoch: 15 [60160/75750 (99%)]\tTrain Loss: 1.016912\n",
      "Train Epoch: 15 [60480/75750 (100%)]\tTrain Loss: 0.860415\n",
      "\n",
      "[EPOCH: 15], \tTest Loss: 0.3010, \tTest Accuracy: 62.46 % \n",
      "\n",
      "Train Epoch: 16 [0/75750 (0%)]\tTrain Loss: 0.837983\n",
      "Train Epoch: 16 [320/75750 (1%)]\tTrain Loss: 0.891305\n",
      "Train Epoch: 16 [640/75750 (1%)]\tTrain Loss: 0.744285\n",
      "Train Epoch: 16 [960/75750 (2%)]\tTrain Loss: 0.795676\n",
      "Train Epoch: 16 [1280/75750 (2%)]\tTrain Loss: 0.834811\n",
      "Train Epoch: 16 [1600/75750 (3%)]\tTrain Loss: 0.418995\n",
      "Train Epoch: 16 [1920/75750 (3%)]\tTrain Loss: 0.764647\n",
      "Train Epoch: 16 [2240/75750 (4%)]\tTrain Loss: 0.663294\n",
      "Train Epoch: 16 [2560/75750 (4%)]\tTrain Loss: 0.484800\n",
      "Train Epoch: 16 [2880/75750 (5%)]\tTrain Loss: 0.539212\n",
      "Train Epoch: 16 [3200/75750 (5%)]\tTrain Loss: 0.576165\n",
      "Train Epoch: 16 [3520/75750 (6%)]\tTrain Loss: 0.651786\n",
      "Train Epoch: 16 [3840/75750 (6%)]\tTrain Loss: 0.572809\n",
      "Train Epoch: 16 [4160/75750 (7%)]\tTrain Loss: 0.883845\n",
      "Train Epoch: 16 [4480/75750 (7%)]\tTrain Loss: 0.863735\n",
      "Train Epoch: 16 [4800/75750 (8%)]\tTrain Loss: 0.734832\n",
      "Train Epoch: 16 [5120/75750 (8%)]\tTrain Loss: 0.726828\n",
      "Train Epoch: 16 [5440/75750 (9%)]\tTrain Loss: 0.809613\n",
      "Train Epoch: 16 [5760/75750 (10%)]\tTrain Loss: 0.979403\n",
      "Train Epoch: 16 [6080/75750 (10%)]\tTrain Loss: 0.740351\n",
      "Train Epoch: 16 [6400/75750 (11%)]\tTrain Loss: 0.884412\n",
      "Train Epoch: 16 [6720/75750 (11%)]\tTrain Loss: 0.809377\n",
      "Train Epoch: 16 [7040/75750 (12%)]\tTrain Loss: 0.749665\n",
      "Train Epoch: 16 [7360/75750 (12%)]\tTrain Loss: 0.660143\n",
      "Train Epoch: 16 [7680/75750 (13%)]\tTrain Loss: 0.708692\n",
      "Train Epoch: 16 [8000/75750 (13%)]\tTrain Loss: 0.839365\n",
      "Train Epoch: 16 [8320/75750 (14%)]\tTrain Loss: 0.742133\n",
      "Train Epoch: 16 [8640/75750 (14%)]\tTrain Loss: 0.635030\n",
      "Train Epoch: 16 [8960/75750 (15%)]\tTrain Loss: 0.656704\n",
      "Train Epoch: 16 [9280/75750 (15%)]\tTrain Loss: 0.684076\n",
      "Train Epoch: 16 [9600/75750 (16%)]\tTrain Loss: 0.512233\n",
      "Train Epoch: 16 [9920/75750 (16%)]\tTrain Loss: 0.606605\n",
      "Train Epoch: 16 [10240/75750 (17%)]\tTrain Loss: 1.020429\n",
      "Train Epoch: 16 [10560/75750 (17%)]\tTrain Loss: 0.740262\n",
      "Train Epoch: 16 [10880/75750 (18%)]\tTrain Loss: 0.562400\n",
      "Train Epoch: 16 [11200/75750 (18%)]\tTrain Loss: 0.534161\n",
      "Train Epoch: 16 [11520/75750 (19%)]\tTrain Loss: 0.910391\n",
      "Train Epoch: 16 [11840/75750 (20%)]\tTrain Loss: 0.708702\n",
      "Train Epoch: 16 [12160/75750 (20%)]\tTrain Loss: 0.476553\n",
      "Train Epoch: 16 [12480/75750 (21%)]\tTrain Loss: 0.523882\n",
      "Train Epoch: 16 [12800/75750 (21%)]\tTrain Loss: 0.545887\n",
      "Train Epoch: 16 [13120/75750 (22%)]\tTrain Loss: 0.738571\n",
      "Train Epoch: 16 [13440/75750 (22%)]\tTrain Loss: 0.690359\n",
      "Train Epoch: 16 [13760/75750 (23%)]\tTrain Loss: 0.729649\n",
      "Train Epoch: 16 [14080/75750 (23%)]\tTrain Loss: 0.925990\n",
      "Train Epoch: 16 [14400/75750 (24%)]\tTrain Loss: 0.440750\n",
      "Train Epoch: 16 [14720/75750 (24%)]\tTrain Loss: 0.540439\n",
      "Train Epoch: 16 [15040/75750 (25%)]\tTrain Loss: 0.778454\n",
      "Train Epoch: 16 [15360/75750 (25%)]\tTrain Loss: 0.716231\n",
      "Train Epoch: 16 [15680/75750 (26%)]\tTrain Loss: 0.484622\n",
      "Train Epoch: 16 [16000/75750 (26%)]\tTrain Loss: 1.104273\n",
      "Train Epoch: 16 [16320/75750 (27%)]\tTrain Loss: 0.699039\n",
      "Train Epoch: 16 [16640/75750 (27%)]\tTrain Loss: 0.574599\n",
      "Train Epoch: 16 [16960/75750 (28%)]\tTrain Loss: 0.720869\n",
      "Train Epoch: 16 [17280/75750 (29%)]\tTrain Loss: 0.694424\n",
      "Train Epoch: 16 [17600/75750 (29%)]\tTrain Loss: 0.750745\n",
      "Train Epoch: 16 [17920/75750 (30%)]\tTrain Loss: 0.504329\n",
      "Train Epoch: 16 [18240/75750 (30%)]\tTrain Loss: 0.592053\n",
      "Train Epoch: 16 [18560/75750 (31%)]\tTrain Loss: 0.476934\n",
      "Train Epoch: 16 [18880/75750 (31%)]\tTrain Loss: 0.690414\n",
      "Train Epoch: 16 [19200/75750 (32%)]\tTrain Loss: 0.670342\n",
      "Train Epoch: 16 [19520/75750 (32%)]\tTrain Loss: 0.799274\n",
      "Train Epoch: 16 [19840/75750 (33%)]\tTrain Loss: 0.538312\n",
      "Train Epoch: 16 [20160/75750 (33%)]\tTrain Loss: 1.088979\n",
      "Train Epoch: 16 [20480/75750 (34%)]\tTrain Loss: 0.854118\n",
      "Train Epoch: 16 [20800/75750 (34%)]\tTrain Loss: 0.784833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [21120/75750 (35%)]\tTrain Loss: 1.028582\n",
      "Train Epoch: 16 [21440/75750 (35%)]\tTrain Loss: 1.011154\n",
      "Train Epoch: 16 [21760/75750 (36%)]\tTrain Loss: 0.427758\n",
      "Train Epoch: 16 [22080/75750 (36%)]\tTrain Loss: 0.786237\n",
      "Train Epoch: 16 [22400/75750 (37%)]\tTrain Loss: 0.721019\n",
      "Train Epoch: 16 [22720/75750 (37%)]\tTrain Loss: 0.612864\n",
      "Train Epoch: 16 [23040/75750 (38%)]\tTrain Loss: 0.796108\n",
      "Train Epoch: 16 [23360/75750 (39%)]\tTrain Loss: 0.625155\n",
      "Train Epoch: 16 [23680/75750 (39%)]\tTrain Loss: 0.795117\n",
      "Train Epoch: 16 [24000/75750 (40%)]\tTrain Loss: 0.485303\n",
      "Train Epoch: 16 [24320/75750 (40%)]\tTrain Loss: 0.585561\n",
      "Train Epoch: 16 [24640/75750 (41%)]\tTrain Loss: 0.564229\n",
      "Train Epoch: 16 [24960/75750 (41%)]\tTrain Loss: 0.651082\n",
      "Train Epoch: 16 [25280/75750 (42%)]\tTrain Loss: 0.694319\n",
      "Train Epoch: 16 [25600/75750 (42%)]\tTrain Loss: 0.754922\n",
      "Train Epoch: 16 [25920/75750 (43%)]\tTrain Loss: 0.913797\n",
      "Train Epoch: 16 [26240/75750 (43%)]\tTrain Loss: 0.690190\n",
      "Train Epoch: 16 [26560/75750 (44%)]\tTrain Loss: 0.770917\n",
      "Train Epoch: 16 [26880/75750 (44%)]\tTrain Loss: 0.737017\n",
      "Train Epoch: 16 [27200/75750 (45%)]\tTrain Loss: 0.581014\n",
      "Train Epoch: 16 [27520/75750 (45%)]\tTrain Loss: 0.943488\n",
      "Train Epoch: 16 [27840/75750 (46%)]\tTrain Loss: 0.956519\n",
      "Train Epoch: 16 [28160/75750 (46%)]\tTrain Loss: 0.537853\n",
      "Train Epoch: 16 [28480/75750 (47%)]\tTrain Loss: 0.571064\n",
      "Train Epoch: 16 [28800/75750 (48%)]\tTrain Loss: 0.688678\n",
      "Train Epoch: 16 [29120/75750 (48%)]\tTrain Loss: 0.657954\n",
      "Train Epoch: 16 [29440/75750 (49%)]\tTrain Loss: 0.788620\n",
      "Train Epoch: 16 [29760/75750 (49%)]\tTrain Loss: 1.045213\n",
      "Train Epoch: 16 [30080/75750 (50%)]\tTrain Loss: 0.440459\n",
      "Train Epoch: 16 [30400/75750 (50%)]\tTrain Loss: 0.820670\n",
      "Train Epoch: 16 [30720/75750 (51%)]\tTrain Loss: 0.975994\n",
      "Train Epoch: 16 [31040/75750 (51%)]\tTrain Loss: 0.599957\n",
      "Train Epoch: 16 [31360/75750 (52%)]\tTrain Loss: 0.824875\n",
      "Train Epoch: 16 [31680/75750 (52%)]\tTrain Loss: 0.896264\n",
      "Train Epoch: 16 [32000/75750 (53%)]\tTrain Loss: 0.720197\n",
      "Train Epoch: 16 [32320/75750 (53%)]\tTrain Loss: 0.637164\n",
      "Train Epoch: 16 [32640/75750 (54%)]\tTrain Loss: 0.611780\n",
      "Train Epoch: 16 [32960/75750 (54%)]\tTrain Loss: 0.583894\n",
      "Train Epoch: 16 [33280/75750 (55%)]\tTrain Loss: 0.622347\n",
      "Train Epoch: 16 [33600/75750 (55%)]\tTrain Loss: 1.222306\n",
      "Train Epoch: 16 [33920/75750 (56%)]\tTrain Loss: 0.974105\n",
      "Train Epoch: 16 [34240/75750 (56%)]\tTrain Loss: 0.605050\n",
      "Train Epoch: 16 [34560/75750 (57%)]\tTrain Loss: 0.639885\n",
      "Train Epoch: 16 [34880/75750 (58%)]\tTrain Loss: 0.591659\n",
      "Train Epoch: 16 [35200/75750 (58%)]\tTrain Loss: 0.513421\n",
      "Train Epoch: 16 [35520/75750 (59%)]\tTrain Loss: 0.510815\n",
      "Train Epoch: 16 [35840/75750 (59%)]\tTrain Loss: 0.840365\n",
      "Train Epoch: 16 [36160/75750 (60%)]\tTrain Loss: 0.836361\n",
      "Train Epoch: 16 [36480/75750 (60%)]\tTrain Loss: 0.601543\n",
      "Train Epoch: 16 [36800/75750 (61%)]\tTrain Loss: 0.942706\n",
      "Train Epoch: 16 [37120/75750 (61%)]\tTrain Loss: 0.606032\n",
      "Train Epoch: 16 [37440/75750 (62%)]\tTrain Loss: 0.681674\n",
      "Train Epoch: 16 [37760/75750 (62%)]\tTrain Loss: 0.766305\n",
      "Train Epoch: 16 [38080/75750 (63%)]\tTrain Loss: 0.787007\n",
      "Train Epoch: 16 [38400/75750 (63%)]\tTrain Loss: 1.047392\n",
      "Train Epoch: 16 [38720/75750 (64%)]\tTrain Loss: 0.724157\n",
      "Train Epoch: 16 [39040/75750 (64%)]\tTrain Loss: 0.860332\n",
      "Train Epoch: 16 [39360/75750 (65%)]\tTrain Loss: 0.783205\n",
      "Train Epoch: 16 [39680/75750 (65%)]\tTrain Loss: 0.736290\n",
      "Train Epoch: 16 [40000/75750 (66%)]\tTrain Loss: 0.903755\n",
      "Train Epoch: 16 [40320/75750 (67%)]\tTrain Loss: 0.770924\n",
      "Train Epoch: 16 [40640/75750 (67%)]\tTrain Loss: 0.736111\n",
      "Train Epoch: 16 [40960/75750 (68%)]\tTrain Loss: 0.714389\n",
      "Train Epoch: 16 [41280/75750 (68%)]\tTrain Loss: 0.942075\n",
      "Train Epoch: 16 [41600/75750 (69%)]\tTrain Loss: 0.883221\n",
      "Train Epoch: 16 [41920/75750 (69%)]\tTrain Loss: 1.091366\n",
      "Train Epoch: 16 [42240/75750 (70%)]\tTrain Loss: 0.734632\n",
      "Train Epoch: 16 [42560/75750 (70%)]\tTrain Loss: 0.915678\n",
      "Train Epoch: 16 [42880/75750 (71%)]\tTrain Loss: 0.928509\n",
      "Train Epoch: 16 [43200/75750 (71%)]\tTrain Loss: 0.750154\n",
      "Train Epoch: 16 [43520/75750 (72%)]\tTrain Loss: 0.702640\n",
      "Train Epoch: 16 [43840/75750 (72%)]\tTrain Loss: 0.962489\n",
      "Train Epoch: 16 [44160/75750 (73%)]\tTrain Loss: 0.695252\n",
      "Train Epoch: 16 [44480/75750 (73%)]\tTrain Loss: 0.973493\n",
      "Train Epoch: 16 [44800/75750 (74%)]\tTrain Loss: 0.689012\n",
      "Train Epoch: 16 [45120/75750 (74%)]\tTrain Loss: 0.784106\n",
      "Train Epoch: 16 [45440/75750 (75%)]\tTrain Loss: 0.767231\n",
      "Train Epoch: 16 [45760/75750 (76%)]\tTrain Loss: 0.887905\n",
      "Train Epoch: 16 [46080/75750 (76%)]\tTrain Loss: 0.730853\n",
      "Train Epoch: 16 [46400/75750 (77%)]\tTrain Loss: 0.780095\n",
      "Train Epoch: 16 [46720/75750 (77%)]\tTrain Loss: 0.751508\n",
      "Train Epoch: 16 [47040/75750 (78%)]\tTrain Loss: 0.678064\n",
      "Train Epoch: 16 [47360/75750 (78%)]\tTrain Loss: 1.291875\n",
      "Train Epoch: 16 [47680/75750 (79%)]\tTrain Loss: 0.919322\n",
      "Train Epoch: 16 [48000/75750 (79%)]\tTrain Loss: 0.966768\n",
      "Train Epoch: 16 [48320/75750 (80%)]\tTrain Loss: 0.776182\n",
      "Train Epoch: 16 [48640/75750 (80%)]\tTrain Loss: 0.908199\n",
      "Train Epoch: 16 [48960/75750 (81%)]\tTrain Loss: 0.653261\n",
      "Train Epoch: 16 [49280/75750 (81%)]\tTrain Loss: 0.883763\n",
      "Train Epoch: 16 [49600/75750 (82%)]\tTrain Loss: 0.632017\n",
      "Train Epoch: 16 [49920/75750 (82%)]\tTrain Loss: 0.850052\n",
      "Train Epoch: 16 [50240/75750 (83%)]\tTrain Loss: 0.728599\n",
      "Train Epoch: 16 [50560/75750 (83%)]\tTrain Loss: 0.848454\n",
      "Train Epoch: 16 [50880/75750 (84%)]\tTrain Loss: 0.732532\n",
      "Train Epoch: 16 [51200/75750 (84%)]\tTrain Loss: 0.950880\n",
      "Train Epoch: 16 [51520/75750 (85%)]\tTrain Loss: 0.734400\n",
      "Train Epoch: 16 [51840/75750 (86%)]\tTrain Loss: 1.126429\n",
      "Train Epoch: 16 [52160/75750 (86%)]\tTrain Loss: 0.999563\n",
      "Train Epoch: 16 [52480/75750 (87%)]\tTrain Loss: 0.578858\n",
      "Train Epoch: 16 [52800/75750 (87%)]\tTrain Loss: 0.874399\n",
      "Train Epoch: 16 [53120/75750 (88%)]\tTrain Loss: 0.654824\n",
      "Train Epoch: 16 [53440/75750 (88%)]\tTrain Loss: 0.971336\n",
      "Train Epoch: 16 [53760/75750 (89%)]\tTrain Loss: 0.777400\n",
      "Train Epoch: 16 [54080/75750 (89%)]\tTrain Loss: 0.778006\n",
      "Train Epoch: 16 [54400/75750 (90%)]\tTrain Loss: 0.854975\n",
      "Train Epoch: 16 [54720/75750 (90%)]\tTrain Loss: 0.646486\n",
      "Train Epoch: 16 [55040/75750 (91%)]\tTrain Loss: 1.015657\n",
      "Train Epoch: 16 [55360/75750 (91%)]\tTrain Loss: 0.651466\n",
      "Train Epoch: 16 [55680/75750 (92%)]\tTrain Loss: 1.417825\n",
      "Train Epoch: 16 [56000/75750 (92%)]\tTrain Loss: 0.497461\n",
      "Train Epoch: 16 [56320/75750 (93%)]\tTrain Loss: 0.694354\n",
      "Train Epoch: 16 [56640/75750 (93%)]\tTrain Loss: 0.759000\n",
      "Train Epoch: 16 [56960/75750 (94%)]\tTrain Loss: 1.038157\n",
      "Train Epoch: 16 [57280/75750 (95%)]\tTrain Loss: 0.800111\n",
      "Train Epoch: 16 [57600/75750 (95%)]\tTrain Loss: 0.768030\n",
      "Train Epoch: 16 [57920/75750 (96%)]\tTrain Loss: 0.700369\n",
      "Train Epoch: 16 [58240/75750 (96%)]\tTrain Loss: 0.673051\n",
      "Train Epoch: 16 [58560/75750 (97%)]\tTrain Loss: 0.834550\n",
      "Train Epoch: 16 [58880/75750 (97%)]\tTrain Loss: 1.150711\n",
      "Train Epoch: 16 [59200/75750 (98%)]\tTrain Loss: 0.600934\n",
      "Train Epoch: 16 [59520/75750 (98%)]\tTrain Loss: 0.733608\n",
      "Train Epoch: 16 [59840/75750 (99%)]\tTrain Loss: 0.636208\n",
      "Train Epoch: 16 [60160/75750 (99%)]\tTrain Loss: 0.805487\n",
      "Train Epoch: 16 [60480/75750 (100%)]\tTrain Loss: 0.931390\n",
      "\n",
      "[EPOCH: 16], \tTest Loss: 0.2649, \tTest Accuracy: 64.45 % \n",
      "\n",
      "Train Epoch: 17 [0/75750 (0%)]\tTrain Loss: 0.853640\n",
      "Train Epoch: 17 [320/75750 (1%)]\tTrain Loss: 0.645600\n",
      "Train Epoch: 17 [640/75750 (1%)]\tTrain Loss: 0.474274\n",
      "Train Epoch: 17 [960/75750 (2%)]\tTrain Loss: 0.896989\n",
      "Train Epoch: 17 [1280/75750 (2%)]\tTrain Loss: 0.963096\n",
      "Train Epoch: 17 [1600/75750 (3%)]\tTrain Loss: 0.679374\n",
      "Train Epoch: 17 [1920/75750 (3%)]\tTrain Loss: 0.700577\n",
      "Train Epoch: 17 [2240/75750 (4%)]\tTrain Loss: 0.425698\n",
      "Train Epoch: 17 [2560/75750 (4%)]\tTrain Loss: 0.598467\n",
      "Train Epoch: 17 [2880/75750 (5%)]\tTrain Loss: 0.526306\n",
      "Train Epoch: 17 [3200/75750 (5%)]\tTrain Loss: 0.586237\n",
      "Train Epoch: 17 [3520/75750 (6%)]\tTrain Loss: 0.958279\n",
      "Train Epoch: 17 [3840/75750 (6%)]\tTrain Loss: 0.653551\n",
      "Train Epoch: 17 [4160/75750 (7%)]\tTrain Loss: 0.514255\n",
      "Train Epoch: 17 [4480/75750 (7%)]\tTrain Loss: 0.482531\n",
      "Train Epoch: 17 [4800/75750 (8%)]\tTrain Loss: 0.711216\n",
      "Train Epoch: 17 [5120/75750 (8%)]\tTrain Loss: 0.698749\n",
      "Train Epoch: 17 [5440/75750 (9%)]\tTrain Loss: 0.544462\n",
      "Train Epoch: 17 [5760/75750 (10%)]\tTrain Loss: 0.835219\n",
      "Train Epoch: 17 [6080/75750 (10%)]\tTrain Loss: 0.633057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [6400/75750 (11%)]\tTrain Loss: 0.905559\n",
      "Train Epoch: 17 [6720/75750 (11%)]\tTrain Loss: 0.371337\n",
      "Train Epoch: 17 [7040/75750 (12%)]\tTrain Loss: 0.524502\n",
      "Train Epoch: 17 [7360/75750 (12%)]\tTrain Loss: 0.656247\n",
      "Train Epoch: 17 [7680/75750 (13%)]\tTrain Loss: 0.732437\n",
      "Train Epoch: 17 [8000/75750 (13%)]\tTrain Loss: 0.641001\n",
      "Train Epoch: 17 [8320/75750 (14%)]\tTrain Loss: 0.679119\n",
      "Train Epoch: 17 [8640/75750 (14%)]\tTrain Loss: 0.436577\n",
      "Train Epoch: 17 [8960/75750 (15%)]\tTrain Loss: 0.650321\n",
      "Train Epoch: 17 [9280/75750 (15%)]\tTrain Loss: 0.467087\n",
      "Train Epoch: 17 [9600/75750 (16%)]\tTrain Loss: 0.504379\n",
      "Train Epoch: 17 [9920/75750 (16%)]\tTrain Loss: 0.453604\n",
      "Train Epoch: 17 [10240/75750 (17%)]\tTrain Loss: 0.736529\n",
      "Train Epoch: 17 [10560/75750 (17%)]\tTrain Loss: 0.777631\n",
      "Train Epoch: 17 [10880/75750 (18%)]\tTrain Loss: 0.610920\n",
      "Train Epoch: 17 [11200/75750 (18%)]\tTrain Loss: 1.014093\n",
      "Train Epoch: 17 [11520/75750 (19%)]\tTrain Loss: 0.740272\n",
      "Train Epoch: 17 [11840/75750 (20%)]\tTrain Loss: 0.667076\n",
      "Train Epoch: 17 [12160/75750 (20%)]\tTrain Loss: 0.785427\n",
      "Train Epoch: 17 [12480/75750 (21%)]\tTrain Loss: 0.534487\n",
      "Train Epoch: 17 [12800/75750 (21%)]\tTrain Loss: 0.760009\n",
      "Train Epoch: 17 [13120/75750 (22%)]\tTrain Loss: 0.589721\n",
      "Train Epoch: 17 [13440/75750 (22%)]\tTrain Loss: 0.659878\n",
      "Train Epoch: 17 [13760/75750 (23%)]\tTrain Loss: 0.800082\n",
      "Train Epoch: 17 [14080/75750 (23%)]\tTrain Loss: 0.386554\n",
      "Train Epoch: 17 [14400/75750 (24%)]\tTrain Loss: 0.996348\n",
      "Train Epoch: 17 [14720/75750 (24%)]\tTrain Loss: 0.642441\n",
      "Train Epoch: 17 [15040/75750 (25%)]\tTrain Loss: 0.740530\n",
      "Train Epoch: 17 [15360/75750 (25%)]\tTrain Loss: 1.022615\n",
      "Train Epoch: 17 [15680/75750 (26%)]\tTrain Loss: 0.718794\n",
      "Train Epoch: 17 [16000/75750 (26%)]\tTrain Loss: 0.649963\n",
      "Train Epoch: 17 [16320/75750 (27%)]\tTrain Loss: 0.494333\n",
      "Train Epoch: 17 [16640/75750 (27%)]\tTrain Loss: 0.505856\n",
      "Train Epoch: 17 [16960/75750 (28%)]\tTrain Loss: 0.654027\n",
      "Train Epoch: 17 [17280/75750 (29%)]\tTrain Loss: 0.441882\n",
      "Train Epoch: 17 [17600/75750 (29%)]\tTrain Loss: 0.545904\n",
      "Train Epoch: 17 [17920/75750 (30%)]\tTrain Loss: 0.559227\n",
      "Train Epoch: 17 [18240/75750 (30%)]\tTrain Loss: 0.604021\n",
      "Train Epoch: 17 [18560/75750 (31%)]\tTrain Loss: 0.577091\n",
      "Train Epoch: 17 [18880/75750 (31%)]\tTrain Loss: 0.650492\n",
      "Train Epoch: 17 [19200/75750 (32%)]\tTrain Loss: 1.041759\n",
      "Train Epoch: 17 [19520/75750 (32%)]\tTrain Loss: 0.775798\n",
      "Train Epoch: 17 [19840/75750 (33%)]\tTrain Loss: 0.916143\n",
      "Train Epoch: 17 [20160/75750 (33%)]\tTrain Loss: 0.744171\n",
      "Train Epoch: 17 [20480/75750 (34%)]\tTrain Loss: 0.599742\n",
      "Train Epoch: 17 [20800/75750 (34%)]\tTrain Loss: 0.700081\n",
      "Train Epoch: 17 [21120/75750 (35%)]\tTrain Loss: 0.914629\n",
      "Train Epoch: 17 [21440/75750 (35%)]\tTrain Loss: 0.861934\n",
      "Train Epoch: 17 [21760/75750 (36%)]\tTrain Loss: 0.706530\n",
      "Train Epoch: 17 [22080/75750 (36%)]\tTrain Loss: 0.687083\n",
      "Train Epoch: 17 [22400/75750 (37%)]\tTrain Loss: 0.687268\n",
      "Train Epoch: 17 [22720/75750 (37%)]\tTrain Loss: 0.480627\n",
      "Train Epoch: 17 [23040/75750 (38%)]\tTrain Loss: 0.577161\n",
      "Train Epoch: 17 [23360/75750 (39%)]\tTrain Loss: 0.923687\n",
      "Train Epoch: 17 [23680/75750 (39%)]\tTrain Loss: 0.502448\n",
      "Train Epoch: 17 [24000/75750 (40%)]\tTrain Loss: 0.448909\n",
      "Train Epoch: 17 [24320/75750 (40%)]\tTrain Loss: 0.840634\n",
      "Train Epoch: 17 [24640/75750 (41%)]\tTrain Loss: 0.727871\n",
      "Train Epoch: 17 [24960/75750 (41%)]\tTrain Loss: 0.781482\n",
      "Train Epoch: 17 [25280/75750 (42%)]\tTrain Loss: 0.530509\n",
      "Train Epoch: 17 [25600/75750 (42%)]\tTrain Loss: 0.789404\n",
      "Train Epoch: 17 [25920/75750 (43%)]\tTrain Loss: 0.737924\n",
      "Train Epoch: 17 [26240/75750 (43%)]\tTrain Loss: 0.457144\n",
      "Train Epoch: 17 [26560/75750 (44%)]\tTrain Loss: 0.650405\n",
      "Train Epoch: 17 [26880/75750 (44%)]\tTrain Loss: 0.709062\n",
      "Train Epoch: 17 [27200/75750 (45%)]\tTrain Loss: 0.849155\n",
      "Train Epoch: 17 [27520/75750 (45%)]\tTrain Loss: 0.659131\n",
      "Train Epoch: 17 [27840/75750 (46%)]\tTrain Loss: 0.818438\n",
      "Train Epoch: 17 [28160/75750 (46%)]\tTrain Loss: 0.839349\n",
      "Train Epoch: 17 [28480/75750 (47%)]\tTrain Loss: 1.005572\n",
      "Train Epoch: 17 [28800/75750 (48%)]\tTrain Loss: 0.537652\n",
      "Train Epoch: 17 [29120/75750 (48%)]\tTrain Loss: 0.418264\n",
      "Train Epoch: 17 [29440/75750 (49%)]\tTrain Loss: 0.669810\n",
      "Train Epoch: 17 [29760/75750 (49%)]\tTrain Loss: 0.614649\n",
      "Train Epoch: 17 [30080/75750 (50%)]\tTrain Loss: 0.954585\n",
      "Train Epoch: 17 [30400/75750 (50%)]\tTrain Loss: 0.635199\n",
      "Train Epoch: 17 [30720/75750 (51%)]\tTrain Loss: 0.787558\n",
      "Train Epoch: 17 [31040/75750 (51%)]\tTrain Loss: 0.620884\n",
      "Train Epoch: 17 [31360/75750 (52%)]\tTrain Loss: 0.714035\n",
      "Train Epoch: 17 [31680/75750 (52%)]\tTrain Loss: 0.957584\n",
      "Train Epoch: 17 [32000/75750 (53%)]\tTrain Loss: 0.978295\n",
      "Train Epoch: 17 [32320/75750 (53%)]\tTrain Loss: 0.681753\n",
      "Train Epoch: 17 [32640/75750 (54%)]\tTrain Loss: 0.721665\n",
      "Train Epoch: 17 [32960/75750 (54%)]\tTrain Loss: 0.753285\n",
      "Train Epoch: 17 [33280/75750 (55%)]\tTrain Loss: 0.659769\n",
      "Train Epoch: 17 [33600/75750 (55%)]\tTrain Loss: 0.727853\n",
      "Train Epoch: 17 [33920/75750 (56%)]\tTrain Loss: 0.609824\n",
      "Train Epoch: 17 [34240/75750 (56%)]\tTrain Loss: 0.790640\n",
      "Train Epoch: 17 [34560/75750 (57%)]\tTrain Loss: 0.358560\n",
      "Train Epoch: 17 [34880/75750 (58%)]\tTrain Loss: 0.581262\n",
      "Train Epoch: 17 [35200/75750 (58%)]\tTrain Loss: 0.816777\n",
      "Train Epoch: 17 [35520/75750 (59%)]\tTrain Loss: 0.957232\n",
      "Train Epoch: 17 [35840/75750 (59%)]\tTrain Loss: 0.689390\n",
      "Train Epoch: 17 [36160/75750 (60%)]\tTrain Loss: 0.708207\n",
      "Train Epoch: 17 [36480/75750 (60%)]\tTrain Loss: 0.701730\n",
      "Train Epoch: 17 [36800/75750 (61%)]\tTrain Loss: 0.740822\n",
      "Train Epoch: 17 [37120/75750 (61%)]\tTrain Loss: 0.859441\n",
      "Train Epoch: 17 [37440/75750 (62%)]\tTrain Loss: 0.683693\n",
      "Train Epoch: 17 [37760/75750 (62%)]\tTrain Loss: 0.867243\n",
      "Train Epoch: 17 [38080/75750 (63%)]\tTrain Loss: 0.384139\n",
      "Train Epoch: 17 [38400/75750 (63%)]\tTrain Loss: 0.733693\n",
      "Train Epoch: 17 [38720/75750 (64%)]\tTrain Loss: 0.605413\n",
      "Train Epoch: 17 [39040/75750 (64%)]\tTrain Loss: 0.590080\n",
      "Train Epoch: 17 [39360/75750 (65%)]\tTrain Loss: 0.976355\n",
      "Train Epoch: 17 [39680/75750 (65%)]\tTrain Loss: 0.753057\n",
      "Train Epoch: 17 [40000/75750 (66%)]\tTrain Loss: 0.484509\n",
      "Train Epoch: 17 [40320/75750 (67%)]\tTrain Loss: 0.742119\n",
      "Train Epoch: 17 [40640/75750 (67%)]\tTrain Loss: 0.801279\n",
      "Train Epoch: 17 [40960/75750 (68%)]\tTrain Loss: 0.887586\n",
      "Train Epoch: 17 [41280/75750 (68%)]\tTrain Loss: 0.765425\n",
      "Train Epoch: 17 [41600/75750 (69%)]\tTrain Loss: 0.726525\n",
      "Train Epoch: 17 [41920/75750 (69%)]\tTrain Loss: 0.689632\n",
      "Train Epoch: 17 [42240/75750 (70%)]\tTrain Loss: 0.546674\n",
      "Train Epoch: 17 [42560/75750 (70%)]\tTrain Loss: 0.852140\n",
      "Train Epoch: 17 [42880/75750 (71%)]\tTrain Loss: 0.494557\n",
      "Train Epoch: 17 [43200/75750 (71%)]\tTrain Loss: 1.004500\n",
      "Train Epoch: 17 [43520/75750 (72%)]\tTrain Loss: 0.653258\n",
      "Train Epoch: 17 [43840/75750 (72%)]\tTrain Loss: 1.014076\n",
      "Train Epoch: 17 [44160/75750 (73%)]\tTrain Loss: 0.525203\n",
      "Train Epoch: 17 [44480/75750 (73%)]\tTrain Loss: 0.789478\n",
      "Train Epoch: 17 [44800/75750 (74%)]\tTrain Loss: 0.698949\n",
      "Train Epoch: 17 [45120/75750 (74%)]\tTrain Loss: 0.562811\n",
      "Train Epoch: 17 [45440/75750 (75%)]\tTrain Loss: 0.719805\n",
      "Train Epoch: 17 [45760/75750 (76%)]\tTrain Loss: 0.922485\n",
      "Train Epoch: 17 [46080/75750 (76%)]\tTrain Loss: 0.653672\n",
      "Train Epoch: 17 [46400/75750 (77%)]\tTrain Loss: 0.877027\n",
      "Train Epoch: 17 [46720/75750 (77%)]\tTrain Loss: 0.877193\n",
      "Train Epoch: 17 [47040/75750 (78%)]\tTrain Loss: 0.898091\n",
      "Train Epoch: 17 [47360/75750 (78%)]\tTrain Loss: 0.908072\n",
      "Train Epoch: 17 [47680/75750 (79%)]\tTrain Loss: 0.483075\n",
      "Train Epoch: 17 [48000/75750 (79%)]\tTrain Loss: 0.802989\n",
      "Train Epoch: 17 [48320/75750 (80%)]\tTrain Loss: 0.808280\n",
      "Train Epoch: 17 [48640/75750 (80%)]\tTrain Loss: 0.515059\n",
      "Train Epoch: 17 [48960/75750 (81%)]\tTrain Loss: 0.589151\n",
      "Train Epoch: 17 [49280/75750 (81%)]\tTrain Loss: 0.612026\n",
      "Train Epoch: 17 [49600/75750 (82%)]\tTrain Loss: 0.947639\n",
      "Train Epoch: 17 [49920/75750 (82%)]\tTrain Loss: 0.911659\n",
      "Train Epoch: 17 [50240/75750 (83%)]\tTrain Loss: 1.004365\n",
      "Train Epoch: 17 [50560/75750 (83%)]\tTrain Loss: 0.704820\n",
      "Train Epoch: 17 [50880/75750 (84%)]\tTrain Loss: 0.975683\n",
      "Train Epoch: 17 [51200/75750 (84%)]\tTrain Loss: 0.669720\n",
      "Train Epoch: 17 [51520/75750 (85%)]\tTrain Loss: 0.947590\n",
      "Train Epoch: 17 [51840/75750 (86%)]\tTrain Loss: 0.814567\n",
      "Train Epoch: 17 [52160/75750 (86%)]\tTrain Loss: 0.832754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [52480/75750 (87%)]\tTrain Loss: 0.644792\n",
      "Train Epoch: 17 [52800/75750 (87%)]\tTrain Loss: 1.000380\n",
      "Train Epoch: 17 [53120/75750 (88%)]\tTrain Loss: 0.741394\n",
      "Train Epoch: 17 [53440/75750 (88%)]\tTrain Loss: 1.069051\n",
      "Train Epoch: 17 [53760/75750 (89%)]\tTrain Loss: 0.784186\n",
      "Train Epoch: 17 [54080/75750 (89%)]\tTrain Loss: 0.630420\n",
      "Train Epoch: 17 [54400/75750 (90%)]\tTrain Loss: 0.697286\n",
      "Train Epoch: 17 [54720/75750 (90%)]\tTrain Loss: 0.601781\n",
      "Train Epoch: 17 [55040/75750 (91%)]\tTrain Loss: 0.807154\n",
      "Train Epoch: 17 [55360/75750 (91%)]\tTrain Loss: 0.819594\n",
      "Train Epoch: 17 [55680/75750 (92%)]\tTrain Loss: 0.798564\n",
      "Train Epoch: 17 [56000/75750 (92%)]\tTrain Loss: 0.990250\n",
      "Train Epoch: 17 [56320/75750 (93%)]\tTrain Loss: 0.698176\n",
      "Train Epoch: 17 [56640/75750 (93%)]\tTrain Loss: 0.604161\n",
      "Train Epoch: 17 [56960/75750 (94%)]\tTrain Loss: 0.694566\n",
      "Train Epoch: 17 [57280/75750 (95%)]\tTrain Loss: 0.499459\n",
      "Train Epoch: 17 [57600/75750 (95%)]\tTrain Loss: 0.701811\n",
      "Train Epoch: 17 [57920/75750 (96%)]\tTrain Loss: 0.858013\n",
      "Train Epoch: 17 [58240/75750 (96%)]\tTrain Loss: 0.774852\n",
      "Train Epoch: 17 [58560/75750 (97%)]\tTrain Loss: 0.886170\n",
      "Train Epoch: 17 [58880/75750 (97%)]\tTrain Loss: 0.818047\n",
      "Train Epoch: 17 [59200/75750 (98%)]\tTrain Loss: 0.476102\n",
      "Train Epoch: 17 [59520/75750 (98%)]\tTrain Loss: 0.444908\n",
      "Train Epoch: 17 [59840/75750 (99%)]\tTrain Loss: 1.127563\n",
      "Train Epoch: 17 [60160/75750 (99%)]\tTrain Loss: 0.854336\n",
      "Train Epoch: 17 [60480/75750 (100%)]\tTrain Loss: 1.177058\n",
      "\n",
      "[EPOCH: 17], \tTest Loss: 0.2594, \tTest Accuracy: 64.62 % \n",
      "\n",
      "Train Epoch: 18 [0/75750 (0%)]\tTrain Loss: 0.732557\n",
      "Train Epoch: 18 [320/75750 (1%)]\tTrain Loss: 0.743480\n",
      "Train Epoch: 18 [640/75750 (1%)]\tTrain Loss: 0.663274\n",
      "Train Epoch: 18 [960/75750 (2%)]\tTrain Loss: 0.621390\n",
      "Train Epoch: 18 [1280/75750 (2%)]\tTrain Loss: 0.515710\n",
      "Train Epoch: 18 [1600/75750 (3%)]\tTrain Loss: 0.847056\n",
      "Train Epoch: 18 [1920/75750 (3%)]\tTrain Loss: 0.848552\n",
      "Train Epoch: 18 [2240/75750 (4%)]\tTrain Loss: 0.629188\n",
      "Train Epoch: 18 [2560/75750 (4%)]\tTrain Loss: 0.585474\n",
      "Train Epoch: 18 [2880/75750 (5%)]\tTrain Loss: 0.675953\n",
      "Train Epoch: 18 [3200/75750 (5%)]\tTrain Loss: 0.491059\n",
      "Train Epoch: 18 [3520/75750 (6%)]\tTrain Loss: 0.695408\n",
      "Train Epoch: 18 [3840/75750 (6%)]\tTrain Loss: 0.810896\n",
      "Train Epoch: 18 [4160/75750 (7%)]\tTrain Loss: 0.546691\n",
      "Train Epoch: 18 [4480/75750 (7%)]\tTrain Loss: 0.561630\n",
      "Train Epoch: 18 [4800/75750 (8%)]\tTrain Loss: 0.424169\n",
      "Train Epoch: 18 [5120/75750 (8%)]\tTrain Loss: 0.777416\n",
      "Train Epoch: 18 [5440/75750 (9%)]\tTrain Loss: 0.318844\n",
      "Train Epoch: 18 [5760/75750 (10%)]\tTrain Loss: 0.719270\n",
      "Train Epoch: 18 [6080/75750 (10%)]\tTrain Loss: 0.746611\n",
      "Train Epoch: 18 [6400/75750 (11%)]\tTrain Loss: 0.873229\n",
      "Train Epoch: 18 [6720/75750 (11%)]\tTrain Loss: 0.493755\n",
      "Train Epoch: 18 [7040/75750 (12%)]\tTrain Loss: 0.806652\n",
      "Train Epoch: 18 [7360/75750 (12%)]\tTrain Loss: 0.595085\n",
      "Train Epoch: 18 [7680/75750 (13%)]\tTrain Loss: 0.792618\n",
      "Train Epoch: 18 [8000/75750 (13%)]\tTrain Loss: 0.743585\n",
      "Train Epoch: 18 [8320/75750 (14%)]\tTrain Loss: 0.489494\n",
      "Train Epoch: 18 [8640/75750 (14%)]\tTrain Loss: 0.899732\n",
      "Train Epoch: 18 [8960/75750 (15%)]\tTrain Loss: 0.608257\n",
      "Train Epoch: 18 [9280/75750 (15%)]\tTrain Loss: 0.507133\n",
      "Train Epoch: 18 [9600/75750 (16%)]\tTrain Loss: 0.605097\n",
      "Train Epoch: 18 [9920/75750 (16%)]\tTrain Loss: 0.647444\n",
      "Train Epoch: 18 [10240/75750 (17%)]\tTrain Loss: 0.583119\n",
      "Train Epoch: 18 [10560/75750 (17%)]\tTrain Loss: 0.694988\n",
      "Train Epoch: 18 [10880/75750 (18%)]\tTrain Loss: 0.517598\n",
      "Train Epoch: 18 [11200/75750 (18%)]\tTrain Loss: 0.717612\n",
      "Train Epoch: 18 [11520/75750 (19%)]\tTrain Loss: 0.773636\n",
      "Train Epoch: 18 [11840/75750 (20%)]\tTrain Loss: 0.648947\n",
      "Train Epoch: 18 [12160/75750 (20%)]\tTrain Loss: 0.602571\n",
      "Train Epoch: 18 [12480/75750 (21%)]\tTrain Loss: 0.836670\n",
      "Train Epoch: 18 [12800/75750 (21%)]\tTrain Loss: 0.441556\n",
      "Train Epoch: 18 [13120/75750 (22%)]\tTrain Loss: 0.604654\n",
      "Train Epoch: 18 [13440/75750 (22%)]\tTrain Loss: 0.544089\n",
      "Train Epoch: 18 [13760/75750 (23%)]\tTrain Loss: 0.831503\n",
      "Train Epoch: 18 [14080/75750 (23%)]\tTrain Loss: 0.605891\n",
      "Train Epoch: 18 [14400/75750 (24%)]\tTrain Loss: 0.646951\n",
      "Train Epoch: 18 [14720/75750 (24%)]\tTrain Loss: 0.514392\n",
      "Train Epoch: 18 [15040/75750 (25%)]\tTrain Loss: 0.514661\n",
      "Train Epoch: 18 [15360/75750 (25%)]\tTrain Loss: 0.760000\n",
      "Train Epoch: 18 [15680/75750 (26%)]\tTrain Loss: 0.508826\n",
      "Train Epoch: 18 [16000/75750 (26%)]\tTrain Loss: 0.480668\n",
      "Train Epoch: 18 [16320/75750 (27%)]\tTrain Loss: 0.705305\n",
      "Train Epoch: 18 [16640/75750 (27%)]\tTrain Loss: 0.696436\n",
      "Train Epoch: 18 [16960/75750 (28%)]\tTrain Loss: 0.316839\n",
      "Train Epoch: 18 [17280/75750 (29%)]\tTrain Loss: 0.656735\n",
      "Train Epoch: 18 [17600/75750 (29%)]\tTrain Loss: 0.354141\n",
      "Train Epoch: 18 [17920/75750 (30%)]\tTrain Loss: 0.558967\n",
      "Train Epoch: 18 [18240/75750 (30%)]\tTrain Loss: 0.505968\n",
      "Train Epoch: 18 [18560/75750 (31%)]\tTrain Loss: 0.510543\n",
      "Train Epoch: 18 [18880/75750 (31%)]\tTrain Loss: 0.702440\n",
      "Train Epoch: 18 [19200/75750 (32%)]\tTrain Loss: 0.477579\n",
      "Train Epoch: 18 [19520/75750 (32%)]\tTrain Loss: 0.870043\n",
      "Train Epoch: 18 [19840/75750 (33%)]\tTrain Loss: 0.497413\n",
      "Train Epoch: 18 [20160/75750 (33%)]\tTrain Loss: 0.632707\n",
      "Train Epoch: 18 [20480/75750 (34%)]\tTrain Loss: 0.514676\n",
      "Train Epoch: 18 [20800/75750 (34%)]\tTrain Loss: 0.715739\n",
      "Train Epoch: 18 [21120/75750 (35%)]\tTrain Loss: 0.456660\n",
      "Train Epoch: 18 [21440/75750 (35%)]\tTrain Loss: 0.669305\n",
      "Train Epoch: 18 [21760/75750 (36%)]\tTrain Loss: 0.704308\n",
      "Train Epoch: 18 [22080/75750 (36%)]\tTrain Loss: 0.646499\n",
      "Train Epoch: 18 [22400/75750 (37%)]\tTrain Loss: 0.669533\n",
      "Train Epoch: 18 [22720/75750 (37%)]\tTrain Loss: 0.712396\n",
      "Train Epoch: 18 [23040/75750 (38%)]\tTrain Loss: 0.721401\n",
      "Train Epoch: 18 [23360/75750 (39%)]\tTrain Loss: 0.860005\n",
      "Train Epoch: 18 [23680/75750 (39%)]\tTrain Loss: 0.607518\n",
      "Train Epoch: 18 [24000/75750 (40%)]\tTrain Loss: 0.822399\n",
      "Train Epoch: 18 [24320/75750 (40%)]\tTrain Loss: 0.532821\n",
      "Train Epoch: 18 [24640/75750 (41%)]\tTrain Loss: 0.811334\n",
      "Train Epoch: 18 [24960/75750 (41%)]\tTrain Loss: 0.811155\n",
      "Train Epoch: 18 [25280/75750 (42%)]\tTrain Loss: 0.590794\n",
      "Train Epoch: 18 [25600/75750 (42%)]\tTrain Loss: 0.921770\n",
      "Train Epoch: 18 [25920/75750 (43%)]\tTrain Loss: 0.595700\n",
      "Train Epoch: 18 [26240/75750 (43%)]\tTrain Loss: 0.894750\n",
      "Train Epoch: 18 [26560/75750 (44%)]\tTrain Loss: 0.660695\n",
      "Train Epoch: 18 [26880/75750 (44%)]\tTrain Loss: 0.895010\n",
      "Train Epoch: 18 [27200/75750 (45%)]\tTrain Loss: 0.932806\n",
      "Train Epoch: 18 [27520/75750 (45%)]\tTrain Loss: 0.769154\n",
      "Train Epoch: 18 [27840/75750 (46%)]\tTrain Loss: 1.192489\n",
      "Train Epoch: 18 [28160/75750 (46%)]\tTrain Loss: 0.610145\n",
      "Train Epoch: 18 [28480/75750 (47%)]\tTrain Loss: 0.492224\n",
      "Train Epoch: 18 [28800/75750 (48%)]\tTrain Loss: 0.550172\n",
      "Train Epoch: 18 [29120/75750 (48%)]\tTrain Loss: 0.557987\n",
      "Train Epoch: 18 [29440/75750 (49%)]\tTrain Loss: 0.565868\n",
      "Train Epoch: 18 [29760/75750 (49%)]\tTrain Loss: 0.946968\n",
      "Train Epoch: 18 [30080/75750 (50%)]\tTrain Loss: 0.573449\n",
      "Train Epoch: 18 [30400/75750 (50%)]\tTrain Loss: 0.658597\n",
      "Train Epoch: 18 [30720/75750 (51%)]\tTrain Loss: 0.864389\n",
      "Train Epoch: 18 [31040/75750 (51%)]\tTrain Loss: 0.677788\n",
      "Train Epoch: 18 [31360/75750 (52%)]\tTrain Loss: 0.598159\n",
      "Train Epoch: 18 [31680/75750 (52%)]\tTrain Loss: 0.837756\n",
      "Train Epoch: 18 [32000/75750 (53%)]\tTrain Loss: 0.549790\n",
      "Train Epoch: 18 [32320/75750 (53%)]\tTrain Loss: 0.700858\n",
      "Train Epoch: 18 [32640/75750 (54%)]\tTrain Loss: 0.733631\n",
      "Train Epoch: 18 [32960/75750 (54%)]\tTrain Loss: 0.466576\n",
      "Train Epoch: 18 [33280/75750 (55%)]\tTrain Loss: 0.723471\n",
      "Train Epoch: 18 [33600/75750 (55%)]\tTrain Loss: 0.710548\n",
      "Train Epoch: 18 [33920/75750 (56%)]\tTrain Loss: 0.485922\n",
      "Train Epoch: 18 [34240/75750 (56%)]\tTrain Loss: 0.822560\n",
      "Train Epoch: 18 [34560/75750 (57%)]\tTrain Loss: 0.684675\n",
      "Train Epoch: 18 [34880/75750 (58%)]\tTrain Loss: 0.674794\n",
      "Train Epoch: 18 [35200/75750 (58%)]\tTrain Loss: 0.717047\n",
      "Train Epoch: 18 [35520/75750 (59%)]\tTrain Loss: 0.559430\n",
      "Train Epoch: 18 [35840/75750 (59%)]\tTrain Loss: 0.842597\n",
      "Train Epoch: 18 [36160/75750 (60%)]\tTrain Loss: 0.849711\n",
      "Train Epoch: 18 [36480/75750 (60%)]\tTrain Loss: 0.585722\n",
      "Train Epoch: 18 [36800/75750 (61%)]\tTrain Loss: 0.534963\n",
      "Train Epoch: 18 [37120/75750 (61%)]\tTrain Loss: 0.655781\n",
      "Train Epoch: 18 [37440/75750 (62%)]\tTrain Loss: 0.875726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [37760/75750 (62%)]\tTrain Loss: 0.598953\n",
      "Train Epoch: 18 [38080/75750 (63%)]\tTrain Loss: 0.547675\n",
      "Train Epoch: 18 [38400/75750 (63%)]\tTrain Loss: 0.848166\n",
      "Train Epoch: 18 [38720/75750 (64%)]\tTrain Loss: 0.689641\n",
      "Train Epoch: 18 [39040/75750 (64%)]\tTrain Loss: 1.150056\n",
      "Train Epoch: 18 [39360/75750 (65%)]\tTrain Loss: 0.870345\n",
      "Train Epoch: 18 [39680/75750 (65%)]\tTrain Loss: 0.715037\n",
      "Train Epoch: 18 [40000/75750 (66%)]\tTrain Loss: 0.772041\n",
      "Train Epoch: 18 [40320/75750 (67%)]\tTrain Loss: 0.704238\n",
      "Train Epoch: 18 [40640/75750 (67%)]\tTrain Loss: 0.656009\n",
      "Train Epoch: 18 [40960/75750 (68%)]\tTrain Loss: 0.616173\n",
      "Train Epoch: 18 [41280/75750 (68%)]\tTrain Loss: 0.604564\n",
      "Train Epoch: 18 [41600/75750 (69%)]\tTrain Loss: 0.644028\n",
      "Train Epoch: 18 [41920/75750 (69%)]\tTrain Loss: 0.673369\n",
      "Train Epoch: 18 [42240/75750 (70%)]\tTrain Loss: 0.887464\n",
      "Train Epoch: 18 [42560/75750 (70%)]\tTrain Loss: 0.730175\n",
      "Train Epoch: 18 [42880/75750 (71%)]\tTrain Loss: 0.886469\n",
      "Train Epoch: 18 [43200/75750 (71%)]\tTrain Loss: 0.582766\n",
      "Train Epoch: 18 [43520/75750 (72%)]\tTrain Loss: 0.910488\n",
      "Train Epoch: 18 [43840/75750 (72%)]\tTrain Loss: 0.729677\n",
      "Train Epoch: 18 [44160/75750 (73%)]\tTrain Loss: 0.493578\n",
      "Train Epoch: 18 [44480/75750 (73%)]\tTrain Loss: 0.747138\n",
      "Train Epoch: 18 [44800/75750 (74%)]\tTrain Loss: 0.979867\n",
      "Train Epoch: 18 [45120/75750 (74%)]\tTrain Loss: 0.760688\n",
      "Train Epoch: 18 [45440/75750 (75%)]\tTrain Loss: 0.811488\n",
      "Train Epoch: 18 [45760/75750 (76%)]\tTrain Loss: 0.680670\n",
      "Train Epoch: 18 [46080/75750 (76%)]\tTrain Loss: 0.737240\n",
      "Train Epoch: 18 [46400/75750 (77%)]\tTrain Loss: 0.627250\n",
      "Train Epoch: 18 [46720/75750 (77%)]\tTrain Loss: 0.563601\n",
      "Train Epoch: 18 [47040/75750 (78%)]\tTrain Loss: 0.592216\n",
      "Train Epoch: 18 [47360/75750 (78%)]\tTrain Loss: 0.570491\n",
      "Train Epoch: 18 [47680/75750 (79%)]\tTrain Loss: 0.674637\n",
      "Train Epoch: 18 [48000/75750 (79%)]\tTrain Loss: 0.659068\n",
      "Train Epoch: 18 [48320/75750 (80%)]\tTrain Loss: 0.877035\n",
      "Train Epoch: 18 [48640/75750 (80%)]\tTrain Loss: 0.652322\n",
      "Train Epoch: 18 [48960/75750 (81%)]\tTrain Loss: 0.479551\n",
      "Train Epoch: 18 [49280/75750 (81%)]\tTrain Loss: 0.560468\n",
      "Train Epoch: 18 [49600/75750 (82%)]\tTrain Loss: 0.661260\n",
      "Train Epoch: 18 [49920/75750 (82%)]\tTrain Loss: 0.536154\n",
      "Train Epoch: 18 [50240/75750 (83%)]\tTrain Loss: 0.702903\n",
      "Train Epoch: 18 [50560/75750 (83%)]\tTrain Loss: 0.839381\n",
      "Train Epoch: 18 [50880/75750 (84%)]\tTrain Loss: 0.510260\n",
      "Train Epoch: 18 [51200/75750 (84%)]\tTrain Loss: 0.396505\n",
      "Train Epoch: 18 [51520/75750 (85%)]\tTrain Loss: 1.085878\n",
      "Train Epoch: 18 [51840/75750 (86%)]\tTrain Loss: 0.748636\n",
      "Train Epoch: 18 [52160/75750 (86%)]\tTrain Loss: 0.999017\n",
      "Train Epoch: 18 [52480/75750 (87%)]\tTrain Loss: 0.653176\n",
      "Train Epoch: 18 [52800/75750 (87%)]\tTrain Loss: 0.628208\n",
      "Train Epoch: 18 [53120/75750 (88%)]\tTrain Loss: 0.539122\n",
      "Train Epoch: 18 [53440/75750 (88%)]\tTrain Loss: 1.024142\n",
      "Train Epoch: 18 [53760/75750 (89%)]\tTrain Loss: 0.742287\n",
      "Train Epoch: 18 [54080/75750 (89%)]\tTrain Loss: 0.678767\n",
      "Train Epoch: 18 [54400/75750 (90%)]\tTrain Loss: 0.643968\n",
      "Train Epoch: 18 [54720/75750 (90%)]\tTrain Loss: 0.748368\n",
      "Train Epoch: 18 [55040/75750 (91%)]\tTrain Loss: 0.917785\n",
      "Train Epoch: 18 [55360/75750 (91%)]\tTrain Loss: 0.594686\n",
      "Train Epoch: 18 [55680/75750 (92%)]\tTrain Loss: 1.074501\n",
      "Train Epoch: 18 [56000/75750 (92%)]\tTrain Loss: 0.968537\n",
      "Train Epoch: 18 [56320/75750 (93%)]\tTrain Loss: 0.601471\n",
      "Train Epoch: 18 [56640/75750 (93%)]\tTrain Loss: 0.434626\n",
      "Train Epoch: 18 [56960/75750 (94%)]\tTrain Loss: 0.669672\n",
      "Train Epoch: 18 [57280/75750 (95%)]\tTrain Loss: 0.467174\n",
      "Train Epoch: 18 [57600/75750 (95%)]\tTrain Loss: 0.689881\n",
      "Train Epoch: 18 [57920/75750 (96%)]\tTrain Loss: 0.746073\n",
      "Train Epoch: 18 [58240/75750 (96%)]\tTrain Loss: 0.782650\n",
      "Train Epoch: 18 [58560/75750 (97%)]\tTrain Loss: 0.746725\n",
      "Train Epoch: 18 [58880/75750 (97%)]\tTrain Loss: 0.759240\n",
      "Train Epoch: 18 [59200/75750 (98%)]\tTrain Loss: 0.758415\n",
      "Train Epoch: 18 [59520/75750 (98%)]\tTrain Loss: 0.492233\n",
      "Train Epoch: 18 [59840/75750 (99%)]\tTrain Loss: 0.724617\n",
      "Train Epoch: 18 [60160/75750 (99%)]\tTrain Loss: 0.435669\n",
      "Train Epoch: 18 [60480/75750 (100%)]\tTrain Loss: 0.749615\n",
      "\n",
      "[EPOCH: 18], \tTest Loss: 0.2315, \tTest Accuracy: 66.10 % \n",
      "\n",
      "Train Epoch: 19 [0/75750 (0%)]\tTrain Loss: 0.500076\n",
      "Train Epoch: 19 [320/75750 (1%)]\tTrain Loss: 0.835259\n",
      "Train Epoch: 19 [640/75750 (1%)]\tTrain Loss: 0.818474\n",
      "Train Epoch: 19 [960/75750 (2%)]\tTrain Loss: 0.335203\n",
      "Train Epoch: 19 [1280/75750 (2%)]\tTrain Loss: 0.704132\n",
      "Train Epoch: 19 [1600/75750 (3%)]\tTrain Loss: 0.424405\n",
      "Train Epoch: 19 [1920/75750 (3%)]\tTrain Loss: 0.546106\n",
      "Train Epoch: 19 [2240/75750 (4%)]\tTrain Loss: 0.707553\n",
      "Train Epoch: 19 [2560/75750 (4%)]\tTrain Loss: 0.643987\n",
      "Train Epoch: 19 [2880/75750 (5%)]\tTrain Loss: 0.325409\n",
      "Train Epoch: 19 [3200/75750 (5%)]\tTrain Loss: 0.472310\n",
      "Train Epoch: 19 [3520/75750 (6%)]\tTrain Loss: 0.775505\n",
      "Train Epoch: 19 [3840/75750 (6%)]\tTrain Loss: 0.314631\n",
      "Train Epoch: 19 [4160/75750 (7%)]\tTrain Loss: 0.581484\n",
      "Train Epoch: 19 [4480/75750 (7%)]\tTrain Loss: 0.645652\n",
      "Train Epoch: 19 [4800/75750 (8%)]\tTrain Loss: 0.691661\n",
      "Train Epoch: 19 [5120/75750 (8%)]\tTrain Loss: 0.567890\n",
      "Train Epoch: 19 [5440/75750 (9%)]\tTrain Loss: 0.559971\n",
      "Train Epoch: 19 [5760/75750 (10%)]\tTrain Loss: 0.789705\n",
      "Train Epoch: 19 [6080/75750 (10%)]\tTrain Loss: 0.409579\n",
      "Train Epoch: 19 [6400/75750 (11%)]\tTrain Loss: 0.834255\n",
      "Train Epoch: 19 [6720/75750 (11%)]\tTrain Loss: 0.548115\n",
      "Train Epoch: 19 [7040/75750 (12%)]\tTrain Loss: 0.592869\n",
      "Train Epoch: 19 [7360/75750 (12%)]\tTrain Loss: 0.397397\n",
      "Train Epoch: 19 [7680/75750 (13%)]\tTrain Loss: 0.742369\n",
      "Train Epoch: 19 [8000/75750 (13%)]\tTrain Loss: 0.481659\n",
      "Train Epoch: 19 [8320/75750 (14%)]\tTrain Loss: 0.376038\n",
      "Train Epoch: 19 [8640/75750 (14%)]\tTrain Loss: 0.408473\n",
      "Train Epoch: 19 [8960/75750 (15%)]\tTrain Loss: 0.511433\n",
      "Train Epoch: 19 [9280/75750 (15%)]\tTrain Loss: 0.454128\n",
      "Train Epoch: 19 [9600/75750 (16%)]\tTrain Loss: 0.808190\n",
      "Train Epoch: 19 [9920/75750 (16%)]\tTrain Loss: 0.662091\n",
      "Train Epoch: 19 [10240/75750 (17%)]\tTrain Loss: 0.596568\n",
      "Train Epoch: 19 [10560/75750 (17%)]\tTrain Loss: 0.588868\n",
      "Train Epoch: 19 [10880/75750 (18%)]\tTrain Loss: 0.740855\n",
      "Train Epoch: 19 [11200/75750 (18%)]\tTrain Loss: 0.532534\n",
      "Train Epoch: 19 [11520/75750 (19%)]\tTrain Loss: 0.376551\n",
      "Train Epoch: 19 [11840/75750 (20%)]\tTrain Loss: 0.770231\n",
      "Train Epoch: 19 [12160/75750 (20%)]\tTrain Loss: 0.657492\n",
      "Train Epoch: 19 [12480/75750 (21%)]\tTrain Loss: 0.407267\n",
      "Train Epoch: 19 [12800/75750 (21%)]\tTrain Loss: 0.511364\n",
      "Train Epoch: 19 [13120/75750 (22%)]\tTrain Loss: 0.496417\n",
      "Train Epoch: 19 [13440/75750 (22%)]\tTrain Loss: 0.744523\n",
      "Train Epoch: 19 [13760/75750 (23%)]\tTrain Loss: 0.450143\n",
      "Train Epoch: 19 [14080/75750 (23%)]\tTrain Loss: 0.788146\n",
      "Train Epoch: 19 [14400/75750 (24%)]\tTrain Loss: 0.466635\n",
      "Train Epoch: 19 [14720/75750 (24%)]\tTrain Loss: 0.806721\n",
      "Train Epoch: 19 [15040/75750 (25%)]\tTrain Loss: 0.802787\n",
      "Train Epoch: 19 [15360/75750 (25%)]\tTrain Loss: 0.588841\n",
      "Train Epoch: 19 [15680/75750 (26%)]\tTrain Loss: 0.599698\n",
      "Train Epoch: 19 [16000/75750 (26%)]\tTrain Loss: 0.647466\n",
      "Train Epoch: 19 [16320/75750 (27%)]\tTrain Loss: 0.569837\n",
      "Train Epoch: 19 [16640/75750 (27%)]\tTrain Loss: 0.641880\n",
      "Train Epoch: 19 [16960/75750 (28%)]\tTrain Loss: 0.448753\n",
      "Train Epoch: 19 [17280/75750 (29%)]\tTrain Loss: 0.520791\n",
      "Train Epoch: 19 [17600/75750 (29%)]\tTrain Loss: 0.456355\n",
      "Train Epoch: 19 [17920/75750 (30%)]\tTrain Loss: 0.723501\n",
      "Train Epoch: 19 [18240/75750 (30%)]\tTrain Loss: 0.537142\n",
      "Train Epoch: 19 [18560/75750 (31%)]\tTrain Loss: 0.443715\n",
      "Train Epoch: 19 [18880/75750 (31%)]\tTrain Loss: 0.571796\n",
      "Train Epoch: 19 [19200/75750 (32%)]\tTrain Loss: 0.536955\n",
      "Train Epoch: 19 [19520/75750 (32%)]\tTrain Loss: 0.440447\n",
      "Train Epoch: 19 [19840/75750 (33%)]\tTrain Loss: 0.911529\n",
      "Train Epoch: 19 [20160/75750 (33%)]\tTrain Loss: 0.773817\n",
      "Train Epoch: 19 [20480/75750 (34%)]\tTrain Loss: 0.449461\n",
      "Train Epoch: 19 [20800/75750 (34%)]\tTrain Loss: 0.592207\n",
      "Train Epoch: 19 [21120/75750 (35%)]\tTrain Loss: 0.622430\n",
      "Train Epoch: 19 [21440/75750 (35%)]\tTrain Loss: 0.598459\n",
      "Train Epoch: 19 [21760/75750 (36%)]\tTrain Loss: 0.692560\n",
      "Train Epoch: 19 [22080/75750 (36%)]\tTrain Loss: 0.573253\n",
      "Train Epoch: 19 [22400/75750 (37%)]\tTrain Loss: 0.439244\n",
      "Train Epoch: 19 [22720/75750 (37%)]\tTrain Loss: 0.498314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [23040/75750 (38%)]\tTrain Loss: 0.731014\n",
      "Train Epoch: 19 [23360/75750 (39%)]\tTrain Loss: 0.488417\n",
      "Train Epoch: 19 [23680/75750 (39%)]\tTrain Loss: 0.502531\n",
      "Train Epoch: 19 [24000/75750 (40%)]\tTrain Loss: 0.729189\n",
      "Train Epoch: 19 [24320/75750 (40%)]\tTrain Loss: 0.956330\n",
      "Train Epoch: 19 [24640/75750 (41%)]\tTrain Loss: 0.728444\n",
      "Train Epoch: 19 [24960/75750 (41%)]\tTrain Loss: 0.737235\n",
      "Train Epoch: 19 [25280/75750 (42%)]\tTrain Loss: 0.843961\n",
      "Train Epoch: 19 [25600/75750 (42%)]\tTrain Loss: 0.464752\n",
      "Train Epoch: 19 [25920/75750 (43%)]\tTrain Loss: 0.693747\n",
      "Train Epoch: 19 [26240/75750 (43%)]\tTrain Loss: 0.996216\n",
      "Train Epoch: 19 [26560/75750 (44%)]\tTrain Loss: 0.508624\n",
      "Train Epoch: 19 [26880/75750 (44%)]\tTrain Loss: 0.701660\n",
      "Train Epoch: 19 [27200/75750 (45%)]\tTrain Loss: 0.651978\n",
      "Train Epoch: 19 [27520/75750 (45%)]\tTrain Loss: 0.457502\n",
      "Train Epoch: 19 [27840/75750 (46%)]\tTrain Loss: 0.576258\n",
      "Train Epoch: 19 [28160/75750 (46%)]\tTrain Loss: 0.584375\n",
      "Train Epoch: 19 [28480/75750 (47%)]\tTrain Loss: 0.814884\n",
      "Train Epoch: 19 [28800/75750 (48%)]\tTrain Loss: 0.572123\n",
      "Train Epoch: 19 [29120/75750 (48%)]\tTrain Loss: 0.364227\n",
      "Train Epoch: 19 [29440/75750 (49%)]\tTrain Loss: 0.852694\n",
      "Train Epoch: 19 [29760/75750 (49%)]\tTrain Loss: 0.466749\n",
      "Train Epoch: 19 [30080/75750 (50%)]\tTrain Loss: 0.483417\n",
      "Train Epoch: 19 [30400/75750 (50%)]\tTrain Loss: 0.857795\n",
      "Train Epoch: 19 [30720/75750 (51%)]\tTrain Loss: 0.704567\n",
      "Train Epoch: 19 [31040/75750 (51%)]\tTrain Loss: 0.679465\n",
      "Train Epoch: 19 [31360/75750 (52%)]\tTrain Loss: 0.365835\n",
      "Train Epoch: 19 [31680/75750 (52%)]\tTrain Loss: 0.566136\n",
      "Train Epoch: 19 [32000/75750 (53%)]\tTrain Loss: 0.585882\n",
      "Train Epoch: 19 [32320/75750 (53%)]\tTrain Loss: 0.524009\n",
      "Train Epoch: 19 [32640/75750 (54%)]\tTrain Loss: 0.749068\n",
      "Train Epoch: 19 [32960/75750 (54%)]\tTrain Loss: 0.619454\n",
      "Train Epoch: 19 [33280/75750 (55%)]\tTrain Loss: 0.793835\n",
      "Train Epoch: 19 [33600/75750 (55%)]\tTrain Loss: 0.679283\n",
      "Train Epoch: 19 [33920/75750 (56%)]\tTrain Loss: 0.776371\n",
      "Train Epoch: 19 [34240/75750 (56%)]\tTrain Loss: 0.564951\n",
      "Train Epoch: 19 [34560/75750 (57%)]\tTrain Loss: 1.087670\n",
      "Train Epoch: 19 [34880/75750 (58%)]\tTrain Loss: 0.671352\n",
      "Train Epoch: 19 [35200/75750 (58%)]\tTrain Loss: 0.744504\n",
      "Train Epoch: 19 [35520/75750 (59%)]\tTrain Loss: 0.808659\n",
      "Train Epoch: 19 [35840/75750 (59%)]\tTrain Loss: 0.461123\n",
      "Train Epoch: 19 [36160/75750 (60%)]\tTrain Loss: 0.853767\n",
      "Train Epoch: 19 [36480/75750 (60%)]\tTrain Loss: 0.870080\n",
      "Train Epoch: 19 [36800/75750 (61%)]\tTrain Loss: 0.703429\n",
      "Train Epoch: 19 [37120/75750 (61%)]\tTrain Loss: 0.616722\n",
      "Train Epoch: 19 [37440/75750 (62%)]\tTrain Loss: 0.696009\n",
      "Train Epoch: 19 [37760/75750 (62%)]\tTrain Loss: 0.734816\n",
      "Train Epoch: 19 [38080/75750 (63%)]\tTrain Loss: 0.747293\n",
      "Train Epoch: 19 [38400/75750 (63%)]\tTrain Loss: 0.854859\n",
      "Train Epoch: 19 [38720/75750 (64%)]\tTrain Loss: 0.814887\n",
      "Train Epoch: 19 [39040/75750 (64%)]\tTrain Loss: 0.919210\n",
      "Train Epoch: 19 [39360/75750 (65%)]\tTrain Loss: 0.754122\n",
      "Train Epoch: 19 [39680/75750 (65%)]\tTrain Loss: 0.586828\n",
      "Train Epoch: 19 [40000/75750 (66%)]\tTrain Loss: 0.625919\n",
      "Train Epoch: 19 [40320/75750 (67%)]\tTrain Loss: 0.494231\n",
      "Train Epoch: 19 [40640/75750 (67%)]\tTrain Loss: 0.511754\n",
      "Train Epoch: 19 [40960/75750 (68%)]\tTrain Loss: 0.614185\n",
      "Train Epoch: 19 [41280/75750 (68%)]\tTrain Loss: 0.435064\n",
      "Train Epoch: 19 [41600/75750 (69%)]\tTrain Loss: 0.642903\n",
      "Train Epoch: 19 [41920/75750 (69%)]\tTrain Loss: 0.491034\n",
      "Train Epoch: 19 [42240/75750 (70%)]\tTrain Loss: 0.826490\n",
      "Train Epoch: 19 [42560/75750 (70%)]\tTrain Loss: 0.650637\n",
      "Train Epoch: 19 [42880/75750 (71%)]\tTrain Loss: 0.788791\n",
      "Train Epoch: 19 [43200/75750 (71%)]\tTrain Loss: 0.469047\n",
      "Train Epoch: 19 [43520/75750 (72%)]\tTrain Loss: 0.636685\n",
      "Train Epoch: 19 [43840/75750 (72%)]\tTrain Loss: 0.715080\n",
      "Train Epoch: 19 [44160/75750 (73%)]\tTrain Loss: 0.759552\n",
      "Train Epoch: 19 [44480/75750 (73%)]\tTrain Loss: 0.460179\n",
      "Train Epoch: 19 [44800/75750 (74%)]\tTrain Loss: 0.524331\n",
      "Train Epoch: 19 [45120/75750 (74%)]\tTrain Loss: 0.888731\n",
      "Train Epoch: 19 [45440/75750 (75%)]\tTrain Loss: 0.430330\n",
      "Train Epoch: 19 [45760/75750 (76%)]\tTrain Loss: 0.651592\n",
      "Train Epoch: 19 [46080/75750 (76%)]\tTrain Loss: 0.648325\n",
      "Train Epoch: 19 [46400/75750 (77%)]\tTrain Loss: 0.798252\n",
      "Train Epoch: 19 [46720/75750 (77%)]\tTrain Loss: 0.538274\n",
      "Train Epoch: 19 [47040/75750 (78%)]\tTrain Loss: 0.526836\n",
      "Train Epoch: 19 [47360/75750 (78%)]\tTrain Loss: 0.597456\n",
      "Train Epoch: 19 [47680/75750 (79%)]\tTrain Loss: 0.748025\n",
      "Train Epoch: 19 [48000/75750 (79%)]\tTrain Loss: 0.375244\n",
      "Train Epoch: 19 [48320/75750 (80%)]\tTrain Loss: 0.798018\n",
      "Train Epoch: 19 [48640/75750 (80%)]\tTrain Loss: 0.822735\n",
      "Train Epoch: 19 [48960/75750 (81%)]\tTrain Loss: 0.821191\n",
      "Train Epoch: 19 [49280/75750 (81%)]\tTrain Loss: 0.458874\n",
      "Train Epoch: 19 [49600/75750 (82%)]\tTrain Loss: 0.673217\n",
      "Train Epoch: 19 [49920/75750 (82%)]\tTrain Loss: 0.664957\n",
      "Train Epoch: 19 [50240/75750 (83%)]\tTrain Loss: 0.842971\n",
      "Train Epoch: 19 [50560/75750 (83%)]\tTrain Loss: 0.834957\n",
      "Train Epoch: 19 [50880/75750 (84%)]\tTrain Loss: 0.394327\n",
      "Train Epoch: 19 [51200/75750 (84%)]\tTrain Loss: 0.644111\n",
      "Train Epoch: 19 [51520/75750 (85%)]\tTrain Loss: 0.650071\n",
      "Train Epoch: 19 [51840/75750 (86%)]\tTrain Loss: 0.556112\n",
      "Train Epoch: 19 [52160/75750 (86%)]\tTrain Loss: 0.818416\n",
      "Train Epoch: 19 [52480/75750 (87%)]\tTrain Loss: 0.823570\n",
      "Train Epoch: 19 [52800/75750 (87%)]\tTrain Loss: 0.855783\n",
      "Train Epoch: 19 [53120/75750 (88%)]\tTrain Loss: 0.540719\n",
      "Train Epoch: 19 [53440/75750 (88%)]\tTrain Loss: 0.720512\n",
      "Train Epoch: 19 [53760/75750 (89%)]\tTrain Loss: 0.604366\n",
      "Train Epoch: 19 [54080/75750 (89%)]\tTrain Loss: 0.594366\n",
      "Train Epoch: 19 [54400/75750 (90%)]\tTrain Loss: 0.656215\n",
      "Train Epoch: 19 [54720/75750 (90%)]\tTrain Loss: 0.725177\n",
      "Train Epoch: 19 [55040/75750 (91%)]\tTrain Loss: 0.632317\n",
      "Train Epoch: 19 [55360/75750 (91%)]\tTrain Loss: 0.614560\n",
      "Train Epoch: 19 [55680/75750 (92%)]\tTrain Loss: 0.771662\n",
      "Train Epoch: 19 [56000/75750 (92%)]\tTrain Loss: 0.607286\n",
      "Train Epoch: 19 [56320/75750 (93%)]\tTrain Loss: 0.595083\n",
      "Train Epoch: 19 [56640/75750 (93%)]\tTrain Loss: 0.783186\n",
      "Train Epoch: 19 [56960/75750 (94%)]\tTrain Loss: 0.576822\n",
      "Train Epoch: 19 [57280/75750 (95%)]\tTrain Loss: 0.531776\n",
      "Train Epoch: 19 [57600/75750 (95%)]\tTrain Loss: 0.520403\n",
      "Train Epoch: 19 [57920/75750 (96%)]\tTrain Loss: 0.419772\n",
      "Train Epoch: 19 [58240/75750 (96%)]\tTrain Loss: 0.468247\n",
      "Train Epoch: 19 [58560/75750 (97%)]\tTrain Loss: 0.758727\n",
      "Train Epoch: 19 [58880/75750 (97%)]\tTrain Loss: 0.530704\n",
      "Train Epoch: 19 [59200/75750 (98%)]\tTrain Loss: 0.534170\n",
      "Train Epoch: 19 [59520/75750 (98%)]\tTrain Loss: 0.602445\n",
      "Train Epoch: 19 [59840/75750 (99%)]\tTrain Loss: 0.470846\n",
      "Train Epoch: 19 [60160/75750 (99%)]\tTrain Loss: 0.501029\n",
      "Train Epoch: 19 [60480/75750 (100%)]\tTrain Loss: 0.770565\n",
      "\n",
      "[EPOCH: 19], \tTest Loss: 0.2148, \tTest Accuracy: 67.10 % \n",
      "\n",
      "Train Epoch: 20 [0/75750 (0%)]\tTrain Loss: 0.368747\n",
      "Train Epoch: 20 [320/75750 (1%)]\tTrain Loss: 0.708942\n",
      "Train Epoch: 20 [640/75750 (1%)]\tTrain Loss: 0.413043\n",
      "Train Epoch: 20 [960/75750 (2%)]\tTrain Loss: 0.564511\n",
      "Train Epoch: 20 [1280/75750 (2%)]\tTrain Loss: 0.620727\n",
      "Train Epoch: 20 [1600/75750 (3%)]\tTrain Loss: 0.470516\n",
      "Train Epoch: 20 [1920/75750 (3%)]\tTrain Loss: 0.236855\n",
      "Train Epoch: 20 [2240/75750 (4%)]\tTrain Loss: 0.651891\n",
      "Train Epoch: 20 [2560/75750 (4%)]\tTrain Loss: 0.634360\n",
      "Train Epoch: 20 [2880/75750 (5%)]\tTrain Loss: 0.480203\n",
      "Train Epoch: 20 [3200/75750 (5%)]\tTrain Loss: 0.430897\n",
      "Train Epoch: 20 [3520/75750 (6%)]\tTrain Loss: 0.508579\n",
      "Train Epoch: 20 [3840/75750 (6%)]\tTrain Loss: 0.620546\n",
      "Train Epoch: 20 [4160/75750 (7%)]\tTrain Loss: 0.542459\n",
      "Train Epoch: 20 [4480/75750 (7%)]\tTrain Loss: 0.673037\n",
      "Train Epoch: 20 [4800/75750 (8%)]\tTrain Loss: 0.479852\n",
      "Train Epoch: 20 [5120/75750 (8%)]\tTrain Loss: 0.669836\n",
      "Train Epoch: 20 [5440/75750 (9%)]\tTrain Loss: 0.685680\n",
      "Train Epoch: 20 [5760/75750 (10%)]\tTrain Loss: 0.416084\n",
      "Train Epoch: 20 [6080/75750 (10%)]\tTrain Loss: 0.813381\n",
      "Train Epoch: 20 [6400/75750 (11%)]\tTrain Loss: 0.494994\n",
      "Train Epoch: 20 [6720/75750 (11%)]\tTrain Loss: 0.384851\n",
      "Train Epoch: 20 [7040/75750 (12%)]\tTrain Loss: 0.452285\n",
      "Train Epoch: 20 [7360/75750 (12%)]\tTrain Loss: 0.668113\n",
      "Train Epoch: 20 [7680/75750 (13%)]\tTrain Loss: 0.785711\n",
      "Train Epoch: 20 [8000/75750 (13%)]\tTrain Loss: 0.579797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [8320/75750 (14%)]\tTrain Loss: 0.511671\n",
      "Train Epoch: 20 [8640/75750 (14%)]\tTrain Loss: 0.461486\n",
      "Train Epoch: 20 [8960/75750 (15%)]\tTrain Loss: 0.378881\n",
      "Train Epoch: 20 [9280/75750 (15%)]\tTrain Loss: 0.636883\n",
      "Train Epoch: 20 [9600/75750 (16%)]\tTrain Loss: 0.444756\n",
      "Train Epoch: 20 [9920/75750 (16%)]\tTrain Loss: 0.479487\n",
      "Train Epoch: 20 [10240/75750 (17%)]\tTrain Loss: 0.547808\n",
      "Train Epoch: 20 [10560/75750 (17%)]\tTrain Loss: 0.586512\n",
      "Train Epoch: 20 [10880/75750 (18%)]\tTrain Loss: 0.482699\n",
      "Train Epoch: 20 [11200/75750 (18%)]\tTrain Loss: 0.396162\n",
      "Train Epoch: 20 [11520/75750 (19%)]\tTrain Loss: 0.620592\n",
      "Train Epoch: 20 [11840/75750 (20%)]\tTrain Loss: 0.705649\n",
      "Train Epoch: 20 [12160/75750 (20%)]\tTrain Loss: 0.690992\n",
      "Train Epoch: 20 [12480/75750 (21%)]\tTrain Loss: 0.624830\n",
      "Train Epoch: 20 [12800/75750 (21%)]\tTrain Loss: 0.675170\n",
      "Train Epoch: 20 [13120/75750 (22%)]\tTrain Loss: 0.706746\n",
      "Train Epoch: 20 [13440/75750 (22%)]\tTrain Loss: 0.699423\n",
      "Train Epoch: 20 [13760/75750 (23%)]\tTrain Loss: 0.538182\n",
      "Train Epoch: 20 [14080/75750 (23%)]\tTrain Loss: 0.964929\n",
      "Train Epoch: 20 [14400/75750 (24%)]\tTrain Loss: 0.571470\n",
      "Train Epoch: 20 [14720/75750 (24%)]\tTrain Loss: 0.503172\n",
      "Train Epoch: 20 [15040/75750 (25%)]\tTrain Loss: 0.607673\n",
      "Train Epoch: 20 [15360/75750 (25%)]\tTrain Loss: 0.656422\n",
      "Train Epoch: 20 [15680/75750 (26%)]\tTrain Loss: 0.485614\n",
      "Train Epoch: 20 [16000/75750 (26%)]\tTrain Loss: 0.407304\n",
      "Train Epoch: 20 [16320/75750 (27%)]\tTrain Loss: 0.771843\n",
      "Train Epoch: 20 [16640/75750 (27%)]\tTrain Loss: 0.539741\n",
      "Train Epoch: 20 [16960/75750 (28%)]\tTrain Loss: 0.596552\n",
      "Train Epoch: 20 [17280/75750 (29%)]\tTrain Loss: 0.252611\n",
      "Train Epoch: 20 [17600/75750 (29%)]\tTrain Loss: 0.569314\n",
      "Train Epoch: 20 [17920/75750 (30%)]\tTrain Loss: 0.594115\n",
      "Train Epoch: 20 [18240/75750 (30%)]\tTrain Loss: 0.511475\n",
      "Train Epoch: 20 [18560/75750 (31%)]\tTrain Loss: 0.710177\n",
      "Train Epoch: 20 [18880/75750 (31%)]\tTrain Loss: 0.683708\n",
      "Train Epoch: 20 [19200/75750 (32%)]\tTrain Loss: 0.517187\n",
      "Train Epoch: 20 [19520/75750 (32%)]\tTrain Loss: 0.437972\n",
      "Train Epoch: 20 [19840/75750 (33%)]\tTrain Loss: 0.636794\n",
      "Train Epoch: 20 [20160/75750 (33%)]\tTrain Loss: 0.790611\n",
      "Train Epoch: 20 [20480/75750 (34%)]\tTrain Loss: 0.579854\n",
      "Train Epoch: 20 [20800/75750 (34%)]\tTrain Loss: 0.555433\n",
      "Train Epoch: 20 [21120/75750 (35%)]\tTrain Loss: 0.456583\n",
      "Train Epoch: 20 [21440/75750 (35%)]\tTrain Loss: 0.668775\n",
      "Train Epoch: 20 [21760/75750 (36%)]\tTrain Loss: 0.658349\n",
      "Train Epoch: 20 [22080/75750 (36%)]\tTrain Loss: 0.667621\n",
      "Train Epoch: 20 [22400/75750 (37%)]\tTrain Loss: 0.505955\n",
      "Train Epoch: 20 [22720/75750 (37%)]\tTrain Loss: 0.398373\n",
      "Train Epoch: 20 [23040/75750 (38%)]\tTrain Loss: 0.535793\n",
      "Train Epoch: 20 [23360/75750 (39%)]\tTrain Loss: 0.639916\n",
      "Train Epoch: 20 [23680/75750 (39%)]\tTrain Loss: 0.323880\n",
      "Train Epoch: 20 [24000/75750 (40%)]\tTrain Loss: 0.366412\n",
      "Train Epoch: 20 [24320/75750 (40%)]\tTrain Loss: 0.587422\n",
      "Train Epoch: 20 [24640/75750 (41%)]\tTrain Loss: 0.702422\n",
      "Train Epoch: 20 [24960/75750 (41%)]\tTrain Loss: 0.823154\n",
      "Train Epoch: 20 [25280/75750 (42%)]\tTrain Loss: 0.758789\n",
      "Train Epoch: 20 [25600/75750 (42%)]\tTrain Loss: 0.490224\n",
      "Train Epoch: 20 [25920/75750 (43%)]\tTrain Loss: 0.457762\n",
      "Train Epoch: 20 [26240/75750 (43%)]\tTrain Loss: 0.257555\n",
      "Train Epoch: 20 [26560/75750 (44%)]\tTrain Loss: 0.931159\n",
      "Train Epoch: 20 [26880/75750 (44%)]\tTrain Loss: 0.395550\n",
      "Train Epoch: 20 [27200/75750 (45%)]\tTrain Loss: 0.424698\n",
      "Train Epoch: 20 [27520/75750 (45%)]\tTrain Loss: 0.565769\n",
      "Train Epoch: 20 [27840/75750 (46%)]\tTrain Loss: 0.706367\n",
      "Train Epoch: 20 [28160/75750 (46%)]\tTrain Loss: 0.621289\n",
      "Train Epoch: 20 [28480/75750 (47%)]\tTrain Loss: 0.714891\n",
      "Train Epoch: 20 [28800/75750 (48%)]\tTrain Loss: 0.601485\n",
      "Train Epoch: 20 [29120/75750 (48%)]\tTrain Loss: 0.959460\n",
      "Train Epoch: 20 [29440/75750 (49%)]\tTrain Loss: 0.733519\n",
      "Train Epoch: 20 [29760/75750 (49%)]\tTrain Loss: 0.762395\n",
      "Train Epoch: 20 [30080/75750 (50%)]\tTrain Loss: 0.537576\n",
      "Train Epoch: 20 [30400/75750 (50%)]\tTrain Loss: 0.553737\n",
      "Train Epoch: 20 [30720/75750 (51%)]\tTrain Loss: 0.616031\n",
      "Train Epoch: 20 [31040/75750 (51%)]\tTrain Loss: 0.672986\n",
      "Train Epoch: 20 [31360/75750 (52%)]\tTrain Loss: 0.482941\n",
      "Train Epoch: 20 [31680/75750 (52%)]\tTrain Loss: 0.507584\n",
      "Train Epoch: 20 [32000/75750 (53%)]\tTrain Loss: 0.444196\n",
      "Train Epoch: 20 [32320/75750 (53%)]\tTrain Loss: 0.643411\n",
      "Train Epoch: 20 [32640/75750 (54%)]\tTrain Loss: 0.600598\n",
      "Train Epoch: 20 [32960/75750 (54%)]\tTrain Loss: 0.727677\n",
      "Train Epoch: 20 [33280/75750 (55%)]\tTrain Loss: 0.641148\n",
      "Train Epoch: 20 [33600/75750 (55%)]\tTrain Loss: 0.614806\n",
      "Train Epoch: 20 [33920/75750 (56%)]\tTrain Loss: 0.494105\n",
      "Train Epoch: 20 [34240/75750 (56%)]\tTrain Loss: 0.523164\n",
      "Train Epoch: 20 [34560/75750 (57%)]\tTrain Loss: 0.673314\n",
      "Train Epoch: 20 [34880/75750 (58%)]\tTrain Loss: 0.470526\n",
      "Train Epoch: 20 [35200/75750 (58%)]\tTrain Loss: 0.787454\n",
      "Train Epoch: 20 [35520/75750 (59%)]\tTrain Loss: 0.658839\n",
      "Train Epoch: 20 [35840/75750 (59%)]\tTrain Loss: 0.752521\n",
      "Train Epoch: 20 [36160/75750 (60%)]\tTrain Loss: 0.801510\n",
      "Train Epoch: 20 [36480/75750 (60%)]\tTrain Loss: 0.519851\n",
      "Train Epoch: 20 [36800/75750 (61%)]\tTrain Loss: 0.455515\n",
      "Train Epoch: 20 [37120/75750 (61%)]\tTrain Loss: 0.624507\n",
      "Train Epoch: 20 [37440/75750 (62%)]\tTrain Loss: 0.596138\n",
      "Train Epoch: 20 [37760/75750 (62%)]\tTrain Loss: 0.545648\n",
      "Train Epoch: 20 [38080/75750 (63%)]\tTrain Loss: 0.691049\n",
      "Train Epoch: 20 [38400/75750 (63%)]\tTrain Loss: 0.681295\n",
      "Train Epoch: 20 [38720/75750 (64%)]\tTrain Loss: 0.676884\n",
      "Train Epoch: 20 [39040/75750 (64%)]\tTrain Loss: 0.696441\n",
      "Train Epoch: 20 [39360/75750 (65%)]\tTrain Loss: 0.598445\n",
      "Train Epoch: 20 [39680/75750 (65%)]\tTrain Loss: 0.445528\n",
      "Train Epoch: 20 [40000/75750 (66%)]\tTrain Loss: 0.609694\n",
      "Train Epoch: 20 [40320/75750 (67%)]\tTrain Loss: 0.500059\n",
      "Train Epoch: 20 [40640/75750 (67%)]\tTrain Loss: 0.473470\n",
      "Train Epoch: 20 [40960/75750 (68%)]\tTrain Loss: 0.537444\n",
      "Train Epoch: 20 [41280/75750 (68%)]\tTrain Loss: 0.727169\n",
      "Train Epoch: 20 [41600/75750 (69%)]\tTrain Loss: 0.789717\n",
      "Train Epoch: 20 [41920/75750 (69%)]\tTrain Loss: 0.619610\n",
      "Train Epoch: 20 [42240/75750 (70%)]\tTrain Loss: 0.649606\n",
      "Train Epoch: 20 [42560/75750 (70%)]\tTrain Loss: 0.808065\n",
      "Train Epoch: 20 [42880/75750 (71%)]\tTrain Loss: 0.567249\n",
      "Train Epoch: 20 [43200/75750 (71%)]\tTrain Loss: 0.592444\n",
      "Train Epoch: 20 [43520/75750 (72%)]\tTrain Loss: 0.493232\n",
      "Train Epoch: 20 [43840/75750 (72%)]\tTrain Loss: 0.490422\n",
      "Train Epoch: 20 [44160/75750 (73%)]\tTrain Loss: 0.590725\n",
      "Train Epoch: 20 [44480/75750 (73%)]\tTrain Loss: 0.535822\n",
      "Train Epoch: 20 [44800/75750 (74%)]\tTrain Loss: 0.518012\n",
      "Train Epoch: 20 [45120/75750 (74%)]\tTrain Loss: 0.602678\n",
      "Train Epoch: 20 [45440/75750 (75%)]\tTrain Loss: 0.590778\n",
      "Train Epoch: 20 [45760/75750 (76%)]\tTrain Loss: 0.420260\n",
      "Train Epoch: 20 [46080/75750 (76%)]\tTrain Loss: 0.510837\n",
      "Train Epoch: 20 [46400/75750 (77%)]\tTrain Loss: 0.591250\n",
      "Train Epoch: 20 [46720/75750 (77%)]\tTrain Loss: 0.615355\n",
      "Train Epoch: 20 [47040/75750 (78%)]\tTrain Loss: 0.316162\n",
      "Train Epoch: 20 [47360/75750 (78%)]\tTrain Loss: 0.709046\n",
      "Train Epoch: 20 [47680/75750 (79%)]\tTrain Loss: 0.689850\n",
      "Train Epoch: 20 [48000/75750 (79%)]\tTrain Loss: 0.518123\n",
      "Train Epoch: 20 [48320/75750 (80%)]\tTrain Loss: 0.820230\n",
      "Train Epoch: 20 [48640/75750 (80%)]\tTrain Loss: 0.967224\n",
      "Train Epoch: 20 [48960/75750 (81%)]\tTrain Loss: 0.577360\n",
      "Train Epoch: 20 [49280/75750 (81%)]\tTrain Loss: 0.519659\n",
      "Train Epoch: 20 [49600/75750 (82%)]\tTrain Loss: 0.495169\n",
      "Train Epoch: 20 [49920/75750 (82%)]\tTrain Loss: 0.840979\n",
      "Train Epoch: 20 [50240/75750 (83%)]\tTrain Loss: 0.748425\n",
      "Train Epoch: 20 [50560/75750 (83%)]\tTrain Loss: 0.546497\n",
      "Train Epoch: 20 [50880/75750 (84%)]\tTrain Loss: 0.717874\n",
      "Train Epoch: 20 [51200/75750 (84%)]\tTrain Loss: 0.728315\n",
      "Train Epoch: 20 [51520/75750 (85%)]\tTrain Loss: 0.713395\n",
      "Train Epoch: 20 [51840/75750 (86%)]\tTrain Loss: 0.730024\n",
      "Train Epoch: 20 [52160/75750 (86%)]\tTrain Loss: 0.525375\n",
      "Train Epoch: 20 [52480/75750 (87%)]\tTrain Loss: 0.613551\n",
      "Train Epoch: 20 [52800/75750 (87%)]\tTrain Loss: 0.574831\n",
      "Train Epoch: 20 [53120/75750 (88%)]\tTrain Loss: 0.731418\n",
      "Train Epoch: 20 [53440/75750 (88%)]\tTrain Loss: 0.788998\n",
      "Train Epoch: 20 [53760/75750 (89%)]\tTrain Loss: 0.796701\n",
      "Train Epoch: 20 [54080/75750 (89%)]\tTrain Loss: 0.721900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [54400/75750 (90%)]\tTrain Loss: 0.394702\n",
      "Train Epoch: 20 [54720/75750 (90%)]\tTrain Loss: 0.897893\n",
      "Train Epoch: 20 [55040/75750 (91%)]\tTrain Loss: 0.698949\n",
      "Train Epoch: 20 [55360/75750 (91%)]\tTrain Loss: 0.701531\n",
      "Train Epoch: 20 [55680/75750 (92%)]\tTrain Loss: 0.370643\n",
      "Train Epoch: 20 [56000/75750 (92%)]\tTrain Loss: 0.642194\n",
      "Train Epoch: 20 [56320/75750 (93%)]\tTrain Loss: 0.528811\n",
      "Train Epoch: 20 [56640/75750 (93%)]\tTrain Loss: 0.613721\n",
      "Train Epoch: 20 [56960/75750 (94%)]\tTrain Loss: 0.647261\n",
      "Train Epoch: 20 [57280/75750 (95%)]\tTrain Loss: 0.672799\n",
      "Train Epoch: 20 [57600/75750 (95%)]\tTrain Loss: 0.544688\n",
      "Train Epoch: 20 [57920/75750 (96%)]\tTrain Loss: 0.959501\n",
      "Train Epoch: 20 [58240/75750 (96%)]\tTrain Loss: 0.607163\n",
      "Train Epoch: 20 [58560/75750 (97%)]\tTrain Loss: 0.674534\n",
      "Train Epoch: 20 [58880/75750 (97%)]\tTrain Loss: 0.618943\n",
      "Train Epoch: 20 [59200/75750 (98%)]\tTrain Loss: 0.523559\n",
      "Train Epoch: 20 [59520/75750 (98%)]\tTrain Loss: 0.460878\n",
      "Train Epoch: 20 [59840/75750 (99%)]\tTrain Loss: 0.800591\n",
      "Train Epoch: 20 [60160/75750 (99%)]\tTrain Loss: 0.761529\n",
      "Train Epoch: 20 [60480/75750 (100%)]\tTrain Loss: 0.505149\n",
      "\n",
      "[EPOCH: 20], \tTest Loss: 0.2547, \tTest Accuracy: 64.68 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, dataloaders[\"train\"], optimizer, log_interval = 5)\n",
    "    valid_loss, valid_accuracy = evaluate(model, dataloaders[\"val\"])\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, valid_loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1d1c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'weights/'\n",
    "torch.save(model, PATH + 'model.pt')  # 전체 모델 저장\n",
    "torch.save(model.state_dict(), PATH + 'model_state_dict.pt')  # 모델 객체의 state_dict 저장\n",
    "torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "}, PATH + 'all.tar')  # 여러 가지 값 저장, 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar값 저장 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88d54bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(PATH + 'model_state_dict.pt')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5990a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, item in enumerate(train_loader):\n",
    "            image = item['gt'].to(DEVICE)\n",
    "            label = item['label'].to(DEVICE)\n",
    "            image = image.to(torch.float32)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            # 상위 5개의 예측을 반환합니다.\n",
    "            prediction = output.topk(5, dim=1)[1]\n",
    "            # 정답이 상위 5개 예측 중 하나라면 correct 변수의 값을 증가시킵니다.\n",
    "            correct += prediction.eq(label.view(-1, 1).expand_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a753273",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, valid_accuracy = evaluate(model, dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d27047fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'preprocess.py', 'images', 'meta']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "## 한식 데이터 학습 추가\n",
    "kor_input_root_dir = \"/Users/munseunghyeon/Documents/kor_food\"\n",
    "kor_input_root_path = Path(kor_input_root_dir)\n",
    "a = glob.glob(\"/Users/munseunghyeon/Documents/kor_food/*\")\n",
    "print(os.listdir(kor_input_root_dir))\n",
    "\n",
    "print(len(os.listdir(kor_input_root_dir)))\n",
    "\n",
    "\n",
    "kor_train_data = file2list(\"/Users/munseunghyeon/Documents/kor_food/meta/kor_train_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "948f6f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Img_020_0774.jpg',\n",
       " 'Img_020_0012.jpg',\n",
       " 'Img_020_0006.jpg',\n",
       " 'Img_020_0760.jpg',\n",
       " 'Img_020_0748.jpg',\n",
       " 'Img_020_0990.jpg',\n",
       " 'Img_020_0984.jpg',\n",
       " 'Img_020_0953.jpg',\n",
       " 'Img_020_0947.jpg',\n",
       " 'Img_020_0210.jpg',\n",
       " 'Img_020_0576.jpg',\n",
       " 'Img_020_0562.jpg',\n",
       " 'Img_020_0204.jpg',\n",
       " 'Img_020_0238.jpg',\n",
       " 'Img_020_0589.jpg',\n",
       " 'Img_020_0364.jpg',\n",
       " 'Img_020_0402.jpg',\n",
       " 'Img_020_0416.jpg',\n",
       " 'Img_020_0370.jpg',\n",
       " 'Img_020_0358.jpg',\n",
       " 'Img_020_0600.jpg',\n",
       " 'Img_020_0166.jpg',\n",
       " 'Img_020_0172.jpg',\n",
       " 'Img_020_0614.jpg',\n",
       " 'Img_020_0628.jpg',\n",
       " 'Img_020_0827.jpg',\n",
       " 'Img_020_0199.jpg',\n",
       " 'Img_020_0833.jpg',\n",
       " 'Img_020_0832.jpg',\n",
       " 'Img_020_0826.jpg',\n",
       " 'Img_020_0198.jpg',\n",
       " 'Img_020_0629.jpg',\n",
       " 'Img_020_0173.jpg',\n",
       " 'Img_020_0615.jpg',\n",
       " 'Img_020_0601.jpg',\n",
       " 'Img_020_0167.jpg',\n",
       " 'Img_020_0359.jpg',\n",
       " 'Img_020_0417.jpg',\n",
       " 'Img_020_0371.jpg',\n",
       " 'Img_020_0365.jpg',\n",
       " 'Img_020_0403.jpg',\n",
       " 'Img_020_0588.jpg',\n",
       " 'Img_020_0239.jpg',\n",
       " 'Img_020_0563.jpg',\n",
       " 'Img_020_0205.jpg',\n",
       " 'Img_020_0211.jpg',\n",
       " 'Img_020_0577.jpg',\n",
       " 'Img_020_0946.jpg',\n",
       " 'Img_020_0952.jpg',\n",
       " 'Img_020_0985.jpg',\n",
       " 'Img_020_0991.jpg',\n",
       " 'Img_020_0749.jpg',\n",
       " 'Img_020_0007.jpg',\n",
       " 'Img_020_0761.jpg',\n",
       " 'Img_020_0775.jpg',\n",
       " 'Img_020_0013.jpg',\n",
       " 'Img_020_0763.jpg',\n",
       " 'Img_020_0005.jpg',\n",
       " 'Img_020_0011.jpg',\n",
       " 'Img_020_0777.jpg',\n",
       " 'Img_020_0987.jpg',\n",
       " 'Img_020_0039.jpg',\n",
       " 'Img_020_0993.jpg',\n",
       " 'Img_020_0978.jpg',\n",
       " 'Img_020_0944.jpg',\n",
       " 'Img_020_0950.jpg',\n",
       " 'Img_020_0788.jpg',\n",
       " 'Img_020_0207.jpg',\n",
       " 'Img_020_0561.jpg',\n",
       " 'Img_020_0575.jpg',\n",
       " 'Img_020_0213.jpg',\n",
       " 'Img_020_0549.jpg',\n",
       " 'Img_020_0373.jpg',\n",
       " 'Img_020_0415.jpg',\n",
       " 'Img_020_0401.jpg',\n",
       " 'Img_020_0367.jpg',\n",
       " 'Img_020_0429.jpg',\n",
       " 'Img_020_0398.jpg',\n",
       " 'Img_020_0617.jpg',\n",
       " 'Img_020_0171.jpg',\n",
       " 'Img_020_0165.jpg',\n",
       " 'Img_020_0603.jpg',\n",
       " 'Img_020_0159.jpg',\n",
       " 'Img_020_0818.jpg',\n",
       " 'Img_020_0830.jpg',\n",
       " 'Img_020_0824.jpg',\n",
       " 'Img_020_0825.jpg',\n",
       " 'Img_020_0831.jpg',\n",
       " 'Img_020_0819.jpg',\n",
       " 'Img_020_0158.jpg',\n",
       " 'Img_020_0164.jpg',\n",
       " 'Img_020_0602.jpg',\n",
       " 'Img_020_0616.jpg',\n",
       " 'Img_020_0170.jpg',\n",
       " 'Img_020_0399.jpg',\n",
       " 'Img_020_0428.jpg',\n",
       " 'Img_020_0400.jpg',\n",
       " 'Img_020_0366.jpg',\n",
       " 'Img_020_0372.jpg',\n",
       " 'Img_020_0414.jpg',\n",
       " 'Img_020_0548.jpg',\n",
       " 'Img_020_0574.jpg',\n",
       " 'Img_020_0212.jpg',\n",
       " 'Img_020_0206.jpg',\n",
       " 'Img_020_0560.jpg',\n",
       " 'Img_020_0789.jpg',\n",
       " 'Img_020_0951.jpg',\n",
       " 'Img_020_0945.jpg',\n",
       " 'Img_020_0979.jpg',\n",
       " 'Img_020_0992.jpg',\n",
       " 'Img_020_0986.jpg',\n",
       " 'Img_020_0038.jpg',\n",
       " 'Img_020_0010.jpg',\n",
       " 'Img_020_0776.jpg',\n",
       " 'Img_020_0762.jpg',\n",
       " 'Img_020_0004.jpg',\n",
       " 'Img_020_0982.jpg',\n",
       " 'Img_020_0996.jpg',\n",
       " 'Img_020_0028.jpg',\n",
       " 'Img_020_0000.jpg',\n",
       " 'Img_020_0766.jpg',\n",
       " 'Img_020_0772.jpg',\n",
       " 'Img_020_0014.jpg',\n",
       " 'Img_020_0941.jpg',\n",
       " 'Img_020_0799.jpg',\n",
       " 'Img_020_0955.jpg',\n",
       " 'Img_020_0969.jpg',\n",
       " 'Img_020_0558.jpg',\n",
       " 'Img_020_0564.jpg',\n",
       " 'Img_020_0202.jpg',\n",
       " 'Img_020_0216.jpg',\n",
       " 'Img_020_0570.jpg',\n",
       " 'Img_020_0438.jpg',\n",
       " 'Img_020_0410.jpg',\n",
       " 'Img_020_0376.jpg',\n",
       " 'Img_020_0362.jpg',\n",
       " 'Img_020_0404.jpg',\n",
       " 'Img_020_0389.jpg',\n",
       " 'Img_020_0148.jpg',\n",
       " 'Img_020_0174.jpg',\n",
       " 'Img_020_0612.jpg',\n",
       " 'Img_020_0606.jpg',\n",
       " 'Img_020_0160.jpg',\n",
       " 'Img_020_0835.jpg',\n",
       " 'Img_020_0821.jpg',\n",
       " 'Img_020_0809.jpg',\n",
       " 'Img_020_0808.jpg',\n",
       " 'Img_020_0820.jpg',\n",
       " 'Img_020_0834.jpg',\n",
       " 'Img_020_0607.jpg',\n",
       " 'Img_020_0161.jpg',\n",
       " 'Img_020_0175.jpg',\n",
       " 'Img_020_0613.jpg',\n",
       " 'Img_020_0149.jpg',\n",
       " 'Img_020_0388.jpg',\n",
       " 'Img_020_0363.jpg',\n",
       " 'Img_020_0405.jpg',\n",
       " 'Img_020_0411.jpg',\n",
       " 'Img_020_0377.jpg',\n",
       " 'Img_020_0439.jpg',\n",
       " 'Img_020_0217.jpg',\n",
       " 'Img_020_0571.jpg',\n",
       " 'Img_020_0565.jpg',\n",
       " 'Img_020_0203.jpg',\n",
       " 'Img_020_0559.jpg',\n",
       " 'Img_020_0968.jpg',\n",
       " 'Img_020_0954.jpg',\n",
       " 'Img_020_0798.jpg',\n",
       " 'Img_020_0940.jpg',\n",
       " 'Img_020_0773.jpg',\n",
       " 'Img_020_0015.jpg',\n",
       " 'Img_020_0001.jpg',\n",
       " 'Img_020_0767.jpg',\n",
       " 'Img_020_0997.jpg',\n",
       " 'Img_020_0029.jpg',\n",
       " 'Img_020_0983.jpg',\n",
       " 'Img_020_0995.jpg',\n",
       " 'Img_020_0759.jpg',\n",
       " 'Img_020_0981.jpg',\n",
       " 'Img_020_0017.jpg',\n",
       " 'Img_020_0771.jpg',\n",
       " 'Img_020_0765.jpg',\n",
       " 'Img_020_0003.jpg',\n",
       " 'Img_020_0956.jpg',\n",
       " 'Img_020_0942.jpg',\n",
       " 'Img_020_0229.jpg',\n",
       " 'Img_020_0573.jpg',\n",
       " 'Img_020_0215.jpg',\n",
       " 'Img_020_0201.jpg',\n",
       " 'Img_020_0567.jpg',\n",
       " 'Img_020_0598.jpg',\n",
       " 'Img_020_0349.jpg',\n",
       " 'Img_020_0407.jpg',\n",
       " 'Img_020_0361.jpg',\n",
       " 'Img_020_0375.jpg',\n",
       " 'Img_020_0413.jpg',\n",
       " 'Img_020_0639.jpg',\n",
       " 'Img_020_0163.jpg',\n",
       " 'Img_020_0605.jpg',\n",
       " 'Img_020_0611.jpg',\n",
       " 'Img_020_0177.jpg',\n",
       " 'Img_020_0822.jpg',\n",
       " 'Img_020_0836.jpg',\n",
       " 'Img_020_0188.jpg',\n",
       " 'Img_020_0837.jpg',\n",
       " 'Img_020_0189.jpg',\n",
       " 'Img_020_0823.jpg',\n",
       " 'Img_020_0610.jpg',\n",
       " 'Img_020_0176.jpg',\n",
       " 'Img_020_0162.jpg',\n",
       " 'Img_020_0604.jpg',\n",
       " 'Img_020_0638.jpg',\n",
       " 'Img_020_0374.jpg',\n",
       " 'Img_020_0412.jpg',\n",
       " 'Img_020_0406.jpg',\n",
       " 'Img_020_0360.jpg',\n",
       " 'Img_020_0348.jpg',\n",
       " 'Img_020_0599.jpg',\n",
       " 'Img_020_0200.jpg',\n",
       " 'Img_020_0566.jpg',\n",
       " 'Img_020_0572.jpg',\n",
       " 'Img_020_0214.jpg',\n",
       " 'Img_020_0228.jpg',\n",
       " 'Img_020_0943.jpg',\n",
       " 'Img_020_0957.jpg',\n",
       " 'Img_020_0764.jpg',\n",
       " 'Img_020_0002.jpg',\n",
       " 'Img_020_0016.jpg',\n",
       " 'Img_020_0770.jpg',\n",
       " 'Img_020_0980.jpg',\n",
       " 'Img_020_0758.jpg',\n",
       " 'Img_020_0994.jpg',\n",
       " 'Img_020_0071.jpg',\n",
       " 'Img_020_0717.jpg',\n",
       " 'Img_020_0703.jpg',\n",
       " 'Img_020_0065.jpg',\n",
       " 'Img_020_0059.jpg',\n",
       " 'Img_020_0918.jpg',\n",
       " 'Img_020_0930.jpg',\n",
       " 'Img_020_0924.jpg',\n",
       " 'Img_020_0515.jpg',\n",
       " 'Img_020_0273.jpg',\n",
       " 'Img_020_0267.jpg',\n",
       " 'Img_020_0501.jpg',\n",
       " 'Img_020_0529.jpg',\n",
       " 'Img_020_0298.jpg',\n",
       " 'Img_020_0461.jpg',\n",
       " 'Img_020_0307.jpg',\n",
       " 'Img_020_0313.jpg',\n",
       " 'Img_020_0475.jpg',\n",
       " 'Img_020_0449.jpg',\n",
       " 'Img_020_0105.jpg',\n",
       " 'Img_020_0663.jpg',\n",
       " 'Img_020_0677.jpg',\n",
       " 'Img_020_0111.jpg',\n",
       " 'Img_020_0139.jpg',\n",
       " 'Img_020_0887.jpg',\n",
       " 'Img_020_0893.jpg',\n",
       " 'Img_020_0878.jpg',\n",
       " 'Img_020_0844.jpg',\n",
       " 'Img_020_0688.jpg',\n",
       " 'Img_020_0850.jpg',\n",
       " 'Img_020_0851.jpg',\n",
       " 'Img_020_0689.jpg',\n",
       " 'Img_020_0845.jpg',\n",
       " 'Img_020_0879.jpg',\n",
       " 'Img_020_0892.jpg',\n",
       " 'Img_020_0138.jpg',\n",
       " 'Img_020_0886.jpg',\n",
       " 'Img_020_0676.jpg',\n",
       " 'Img_020_0110.jpg',\n",
       " 'Img_020_0104.jpg',\n",
       " 'Img_020_0662.jpg',\n",
       " 'Img_020_0448.jpg',\n",
       " 'Img_020_0312.jpg',\n",
       " 'Img_020_0474.jpg',\n",
       " 'Img_020_0460.jpg',\n",
       " 'Img_020_0306.jpg',\n",
       " 'Img_020_0299.jpg',\n",
       " 'Img_020_0528.jpg',\n",
       " 'Img_020_0266.jpg',\n",
       " 'Img_020_0500.jpg',\n",
       " 'Img_020_0514.jpg',\n",
       " 'Img_020_0272.jpg',\n",
       " 'Img_020_0925.jpg',\n",
       " 'Img_020_0931.jpg',\n",
       " 'Img_020_0919.jpg',\n",
       " 'Img_020_0058.jpg',\n",
       " 'Img_020_0702.jpg',\n",
       " 'Img_020_0064.jpg',\n",
       " 'Img_020_0070.jpg',\n",
       " 'Img_020_0716.jpg',\n",
       " 'Img_020_0066.jpg',\n",
       " 'Img_020_0700.jpg',\n",
       " 'Img_020_0714.jpg',\n",
       " 'Img_020_0072.jpg',\n",
       " 'Img_020_0728.jpg',\n",
       " 'Img_020_0099.jpg',\n",
       " 'Img_020_0927.jpg',\n",
       " 'Img_020_0933.jpg',\n",
       " 'Img_020_0502.jpg',\n",
       " 'Img_020_0264.jpg',\n",
       " 'Img_020_0270.jpg',\n",
       " 'Img_020_0516.jpg',\n",
       " 'Img_020_0258.jpg',\n",
       " 'Img_020_0476.jpg',\n",
       " 'Img_020_0310.jpg',\n",
       " 'Img_020_0304.jpg',\n",
       " 'Img_020_0462.jpg',\n",
       " 'Img_020_0338.jpg',\n",
       " 'Img_020_0489.jpg',\n",
       " 'Img_020_0112.jpg',\n",
       " 'Img_020_0674.jpg',\n",
       " 'Img_020_0660.jpg',\n",
       " 'Img_020_0106.jpg',\n",
       " 'Img_020_0890.jpg',\n",
       " 'Img_020_0648.jpg',\n",
       " 'Img_020_0884.jpg',\n",
       " 'Img_020_0853.jpg',\n",
       " 'Img_020_0847.jpg',\n",
       " 'Img_020_0846.jpg',\n",
       " 'Img_020_0852.jpg',\n",
       " 'Img_020_0885.jpg',\n",
       " 'Img_020_0649.jpg',\n",
       " 'Img_020_0891.jpg',\n",
       " 'Img_020_0661.jpg',\n",
       " 'Img_020_0107.jpg',\n",
       " 'Img_020_0113.jpg',\n",
       " 'Img_020_0675.jpg',\n",
       " 'Img_020_0488.jpg',\n",
       " 'Img_020_0339.jpg',\n",
       " 'Img_020_0305.jpg',\n",
       " 'Img_020_0463.jpg',\n",
       " 'Img_020_0477.jpg',\n",
       " 'Img_020_0311.jpg',\n",
       " 'Img_020_0259.jpg',\n",
       " 'Img_020_0271.jpg',\n",
       " 'Img_020_0517.jpg',\n",
       " 'Img_020_0503.jpg',\n",
       " 'Img_020_0265.jpg',\n",
       " 'Img_020_0932.jpg',\n",
       " 'Img_020_0098.jpg',\n",
       " 'Img_020_0926.jpg',\n",
       " 'Img_020_0729.jpg',\n",
       " 'Img_020_0715.jpg',\n",
       " 'Img_020_0073.jpg',\n",
       " 'Img_020_0067.jpg',\n",
       " 'Img_020_0701.jpg',\n",
       " 'Img_020_0739.jpg',\n",
       " 'Img_020_0705.jpg',\n",
       " 'Img_020_0063.jpg',\n",
       " 'Img_020_0077.jpg',\n",
       " 'Img_020_0711.jpg',\n",
       " 'Img_020_0922.jpg',\n",
       " 'Img_020_0088.jpg',\n",
       " 'Img_020_0936.jpg',\n",
       " 'Img_020_0249.jpg',\n",
       " 'Img_020_0261.jpg',\n",
       " 'Img_020_0507.jpg',\n",
       " 'Img_020_0513.jpg',\n",
       " 'Img_020_0275.jpg',\n",
       " 'Img_020_0329.jpg',\n",
       " 'Img_020_0315.jpg',\n",
       " 'Img_020_0473.jpg',\n",
       " 'Img_020_0467.jpg',\n",
       " 'Img_020_0301.jpg',\n",
       " 'Img_020_0498.jpg',\n",
       " 'Img_020_0895.jpg',\n",
       " 'Img_020_0881.jpg',\n",
       " 'Img_020_0659.jpg',\n",
       " 'Img_020_0671.jpg',\n",
       " 'Img_020_0117.jpg',\n",
       " 'Img_020_0103.jpg',\n",
       " 'Img_020_0665.jpg',\n",
       " 'Img_020_0856.jpg',\n",
       " 'Img_020_0842.jpg',\n",
       " 'Img_020_0843.jpg',\n",
       " 'Img_020_0857.jpg',\n",
       " 'Img_020_0102.jpg',\n",
       " 'Img_020_0664.jpg',\n",
       " 'Img_020_0670.jpg',\n",
       " 'Img_020_0116.jpg',\n",
       " 'Img_020_0658.jpg',\n",
       " 'Img_020_0880.jpg',\n",
       " 'Img_020_0894.jpg',\n",
       " 'Img_020_0499.jpg',\n",
       " 'Img_020_0466.jpg',\n",
       " 'Img_020_0300.jpg',\n",
       " 'Img_020_0314.jpg',\n",
       " 'Img_020_0472.jpg',\n",
       " 'Img_020_0328.jpg',\n",
       " 'Img_020_0512.jpg',\n",
       " 'Img_020_0274.jpg',\n",
       " 'Img_020_0260.jpg',\n",
       " 'Img_020_0506.jpg',\n",
       " 'Img_020_0248.jpg',\n",
       " 'Img_020_0089.jpg',\n",
       " 'Img_020_0937.jpg',\n",
       " 'Img_020_0923.jpg',\n",
       " 'Img_020_0076.jpg',\n",
       " 'Img_020_0710.jpg',\n",
       " 'Img_020_0704.jpg',\n",
       " 'Img_020_0062.jpg',\n",
       " 'Img_020_0738.jpg',\n",
       " 'Img_020_0048.jpg',\n",
       " 'Img_020_0712.jpg',\n",
       " 'Img_020_0074.jpg',\n",
       " 'Img_020_0060.jpg',\n",
       " 'Img_020_0706.jpg',\n",
       " 'Img_020_0935.jpg',\n",
       " 'Img_020_0921.jpg',\n",
       " 'Img_020_0909.jpg',\n",
       " 'Img_020_0538.jpg',\n",
       " 'Img_020_0276.jpg',\n",
       " 'Img_020_0510.jpg',\n",
       " 'Img_020_0504.jpg',\n",
       " 'Img_020_0262.jpg',\n",
       " 'Img_020_0289.jpg',\n",
       " 'Img_020_0458.jpg',\n",
       " 'Img_020_0302.jpg',\n",
       " 'Img_020_0464.jpg',\n",
       " 'Img_020_0470.jpg',\n",
       " 'Img_020_0316.jpg',\n",
       " 'Img_020_0882.jpg',\n",
       " 'Img_020_0128.jpg',\n",
       " 'Img_020_0896.jpg',\n",
       " 'Img_020_0666.jpg',\n",
       " 'Img_020_0100.jpg',\n",
       " 'Img_020_0114.jpg',\n",
       " 'Img_020_0672.jpg',\n",
       " 'Img_020_0699.jpg',\n",
       " 'Img_020_0841.jpg',\n",
       " 'Img_020_0855.jpg',\n",
       " 'Img_020_0869.jpg',\n",
       " 'Img_020_0868.jpg',\n",
       " 'Img_020_0854.jpg',\n",
       " 'Img_020_0840.jpg',\n",
       " 'Img_020_0698.jpg',\n",
       " 'Img_020_0115.jpg',\n",
       " 'Img_020_0673.jpg',\n",
       " 'Img_020_0667.jpg',\n",
       " 'Img_020_0101.jpg',\n",
       " 'Img_020_0129.jpg',\n",
       " 'Img_020_0897.jpg',\n",
       " 'Img_020_0883.jpg',\n",
       " 'Img_020_0471.jpg',\n",
       " 'Img_020_0317.jpg',\n",
       " 'Img_020_0303.jpg',\n",
       " 'Img_020_0465.jpg',\n",
       " 'Img_020_0459.jpg',\n",
       " 'Img_020_0288.jpg',\n",
       " 'Img_020_0505.jpg',\n",
       " 'Img_020_0263.jpg',\n",
       " 'Img_020_0277.jpg',\n",
       " 'Img_020_0511.jpg',\n",
       " 'Img_020_0539.jpg',\n",
       " 'Img_020_0908.jpg',\n",
       " 'Img_020_0920.jpg',\n",
       " 'Img_020_0934.jpg',\n",
       " 'Img_020_0061.jpg',\n",
       " 'Img_020_0707.jpg',\n",
       " 'Img_020_0713.jpg',\n",
       " 'Img_020_0075.jpg',\n",
       " 'Img_020_0049.jpg',\n",
       " 'Img_020_0050.jpg',\n",
       " 'Img_020_0736.jpg',\n",
       " 'Img_020_0722.jpg',\n",
       " 'Img_020_0044.jpg',\n",
       " 'Img_020_0078.jpg',\n",
       " 'Img_020_0093.jpg',\n",
       " 'Img_020_0939.jpg',\n",
       " 'Img_020_0087.jpg',\n",
       " 'Img_020_0911.jpg',\n",
       " 'Img_020_0905.jpg',\n",
       " 'Img_020_0534.jpg',\n",
       " 'Img_020_0252.jpg',\n",
       " 'Img_020_0246.jpg',\n",
       " 'Img_020_0520.jpg',\n",
       " 'Img_020_0508.jpg',\n",
       " 'Img_020_0291.jpg',\n",
       " 'Img_020_0285.jpg',\n",
       " 'Img_020_0440.jpg',\n",
       " 'Img_020_0326.jpg',\n",
       " 'Img_020_0332.jpg',\n",
       " 'Img_020_0454.jpg',\n",
       " 'Img_020_0468.jpg',\n",
       " 'Img_020_0483.jpg',\n",
       " 'Img_020_0497.jpg',\n",
       " 'Img_020_0124.jpg',\n",
       " 'Img_020_0642.jpg',\n",
       " 'Img_020_0656.jpg',\n",
       " 'Img_020_0130.jpg',\n",
       " 'Img_020_0118.jpg',\n",
       " 'Img_020_0681.jpg',\n",
       " 'Img_020_0859.jpg',\n",
       " 'Img_020_0695.jpg',\n",
       " 'Img_020_0865.jpg',\n",
       " 'Img_020_0871.jpg',\n",
       " 'Img_020_0870.jpg',\n",
       " 'Img_020_0864.jpg',\n",
       " 'Img_020_0694.jpg',\n",
       " 'Img_020_0858.jpg',\n",
       " 'Img_020_0680.jpg',\n",
       " 'Img_020_0119.jpg',\n",
       " 'Img_020_0657.jpg',\n",
       " 'Img_020_0131.jpg',\n",
       " 'Img_020_0125.jpg',\n",
       " 'Img_020_0643.jpg',\n",
       " 'Img_020_0496.jpg',\n",
       " 'Img_020_0482.jpg',\n",
       " 'Img_020_0469.jpg',\n",
       " 'Img_020_0333.jpg',\n",
       " 'Img_020_0455.jpg',\n",
       " 'Img_020_0441.jpg',\n",
       " 'Img_020_0327.jpg',\n",
       " 'Img_020_0284.jpg',\n",
       " 'Img_020_0290.jpg',\n",
       " 'Img_020_0509.jpg',\n",
       " 'Img_020_0247.jpg',\n",
       " 'Img_020_0521.jpg',\n",
       " 'Img_020_0535.jpg',\n",
       " 'Img_020_0253.jpg',\n",
       " 'Img_020_0904.jpg',\n",
       " 'Img_020_0910.jpg',\n",
       " 'Img_020_0938.jpg',\n",
       " 'Img_020_0086.jpg',\n",
       " 'Img_020_0092.jpg',\n",
       " 'Img_020_0079.jpg',\n",
       " 'Img_020_0723.jpg',\n",
       " 'Img_020_0045.jpg',\n",
       " 'Img_020_0051.jpg',\n",
       " 'Img_020_0737.jpg',\n",
       " 'Img_020_0047.jpg',\n",
       " 'Img_020_0721.jpg',\n",
       " 'Img_020_0735.jpg',\n",
       " 'Img_020_0053.jpg',\n",
       " 'Img_020_0709.jpg',\n",
       " 'Img_020_0084.jpg',\n",
       " 'Img_020_0090.jpg',\n",
       " 'Img_020_0906.jpg',\n",
       " 'Img_020_0912.jpg',\n",
       " 'Img_020_0523.jpg',\n",
       " 'Img_020_0245.jpg',\n",
       " 'Img_020_0251.jpg',\n",
       " 'Img_020_0537.jpg',\n",
       " 'Img_020_0279.jpg',\n",
       " 'Img_020_0286.jpg',\n",
       " 'Img_020_0292.jpg',\n",
       " 'Img_020_0457.jpg',\n",
       " 'Img_020_0331.jpg',\n",
       " 'Img_020_0325.jpg',\n",
       " 'Img_020_0443.jpg',\n",
       " 'Img_020_0319.jpg',\n",
       " 'Img_020_0494.jpg',\n",
       " 'Img_020_0480.jpg',\n",
       " 'Img_020_0133.jpg',\n",
       " 'Img_020_0655.jpg',\n",
       " 'Img_020_0899.jpg',\n",
       " 'Img_020_0641.jpg',\n",
       " 'Img_020_0127.jpg',\n",
       " 'Img_020_0669.jpg',\n",
       " 'Img_020_0696.jpg',\n",
       " 'Img_020_0682.jpg',\n",
       " 'Img_020_0872.jpg',\n",
       " 'Img_020_0866.jpg',\n",
       " 'Img_020_0867.jpg',\n",
       " 'Img_020_0873.jpg',\n",
       " 'Img_020_0683.jpg',\n",
       " 'Img_020_0697.jpg',\n",
       " 'Img_020_0668.jpg',\n",
       " 'Img_020_0640.jpg',\n",
       " 'Img_020_0898.jpg',\n",
       " 'Img_020_0126.jpg',\n",
       " 'Img_020_0132.jpg',\n",
       " 'Img_020_0654.jpg',\n",
       " 'Img_020_0481.jpg',\n",
       " 'Img_020_0495.jpg',\n",
       " 'Img_020_0318.jpg',\n",
       " 'Img_020_0324.jpg',\n",
       " 'Img_020_0442.jpg',\n",
       " 'Img_020_0456.jpg',\n",
       " 'Img_020_0330.jpg',\n",
       " 'Img_020_0293.jpg',\n",
       " 'Img_020_0287.jpg',\n",
       " 'Img_020_0278.jpg',\n",
       " 'Img_020_0250.jpg',\n",
       " 'Img_020_0536.jpg',\n",
       " 'Img_020_0522.jpg',\n",
       " 'Img_020_0244.jpg',\n",
       " 'Img_020_0913.jpg',\n",
       " 'Img_020_0907.jpg',\n",
       " 'Img_020_0091.jpg',\n",
       " 'Img_020_0085.jpg',\n",
       " 'Img_020_0708.jpg',\n",
       " 'Img_020_0734.jpg',\n",
       " 'Img_020_0052.jpg',\n",
       " 'Img_020_0046.jpg',\n",
       " 'Img_020_0720.jpg',\n",
       " 'Img_020_0718.jpg',\n",
       " 'Img_020_0724.jpg',\n",
       " 'Img_020_0042.jpg',\n",
       " 'Img_020_0056.jpg',\n",
       " 'Img_020_0730.jpg',\n",
       " 'Img_020_0903.jpg',\n",
       " 'Img_020_0917.jpg',\n",
       " 'Img_020_0081.jpg',\n",
       " 'Img_020_0095.jpg',\n",
       " 'Img_020_0268.jpg',\n",
       " 'Img_020_0240.jpg',\n",
       " 'Img_020_0526.jpg',\n",
       " 'Img_020_0532.jpg',\n",
       " 'Img_020_0254.jpg',\n",
       " 'Img_020_0283.jpg',\n",
       " 'Img_020_0297.jpg',\n",
       " 'Img_020_0308.jpg',\n",
       " 'Img_020_0334.jpg',\n",
       " 'Img_020_0452.jpg',\n",
       " 'Img_020_0446.jpg',\n",
       " 'Img_020_0320.jpg',\n",
       " 'Img_020_0491.jpg',\n",
       " 'Img_020_0485.jpg',\n",
       " 'Img_020_0678.jpg',\n",
       " 'Img_020_0888.jpg',\n",
       " 'Img_020_0650.jpg',\n",
       " 'Img_020_0136.jpg',\n",
       " 'Img_020_0122.jpg',\n",
       " 'Img_020_0644.jpg',\n",
       " 'Img_020_0877.jpg',\n",
       " 'Img_020_0863.jpg',\n",
       " 'Img_020_0693.jpg',\n",
       " 'Img_020_0687.jpg',\n",
       " 'Img_020_0686.jpg',\n",
       " 'Img_020_0692.jpg',\n",
       " 'Img_020_0862.jpg',\n",
       " 'Img_020_0876.jpg',\n",
       " 'Img_020_0123.jpg',\n",
       " 'Img_020_0645.jpg',\n",
       " 'Img_020_0651.jpg',\n",
       " 'Img_020_0889.jpg',\n",
       " 'Img_020_0137.jpg',\n",
       " 'Img_020_0679.jpg',\n",
       " 'Img_020_0484.jpg',\n",
       " 'Img_020_0490.jpg',\n",
       " 'Img_020_0447.jpg',\n",
       " 'Img_020_0321.jpg',\n",
       " 'Img_020_0335.jpg',\n",
       " 'Img_020_0453.jpg',\n",
       " 'Img_020_0309.jpg',\n",
       " 'Img_020_0296.jpg',\n",
       " 'Img_020_0282.jpg',\n",
       " 'Img_020_0533.jpg',\n",
       " 'Img_020_0255.jpg',\n",
       " 'Img_020_0241.jpg',\n",
       " 'Img_020_0527.jpg',\n",
       " 'Img_020_0269.jpg',\n",
       " 'Img_020_0094.jpg',\n",
       " 'Img_020_0080.jpg',\n",
       " 'Img_020_0916.jpg',\n",
       " 'Img_020_0902.jpg',\n",
       " 'Img_020_0057.jpg',\n",
       " 'Img_020_0731.jpg',\n",
       " 'Img_020_0725.jpg',\n",
       " 'Img_020_0043.jpg',\n",
       " 'Img_020_0719.jpg',\n",
       " 'Img_020_0069.jpg',\n",
       " 'Img_020_0733.jpg',\n",
       " 'Img_020_0055.jpg',\n",
       " 'Img_020_0041.jpg',\n",
       " 'Img_020_0727.jpg',\n",
       " 'Img_020_0914.jpg',\n",
       " 'Img_020_0900.jpg',\n",
       " 'Img_020_0928.jpg',\n",
       " 'Img_020_0096.jpg',\n",
       " 'Img_020_0082.jpg',\n",
       " 'Img_020_0519.jpg',\n",
       " 'Img_020_0257.jpg',\n",
       " 'Img_020_0531.jpg',\n",
       " 'Img_020_0525.jpg',\n",
       " 'Img_020_0243.jpg',\n",
       " 'Img_020_0294.jpg',\n",
       " 'Img_020_0280.jpg',\n",
       " 'Img_020_0479.jpg',\n",
       " 'Img_020_0323.jpg',\n",
       " 'Img_020_0445.jpg',\n",
       " 'Img_020_0451.jpg',\n",
       " 'Img_020_0337.jpg',\n",
       " 'Img_020_0486.jpg',\n",
       " 'Img_020_0492.jpg',\n",
       " 'Img_020_0109.jpg',\n",
       " 'Img_020_0647.jpg',\n",
       " 'Img_020_0121.jpg',\n",
       " 'Img_020_0135.jpg',\n",
       " 'Img_020_0653.jpg',\n",
       " 'Img_020_0860.jpg',\n",
       " 'Img_020_0874.jpg',\n",
       " 'Img_020_0684.jpg',\n",
       " 'Img_020_0690.jpg',\n",
       " 'Img_020_0848.jpg',\n",
       " 'Img_020_0849.jpg',\n",
       " 'Img_020_0691.jpg',\n",
       " 'Img_020_0685.jpg',\n",
       " 'Img_020_0875.jpg',\n",
       " 'Img_020_0861.jpg',\n",
       " 'Img_020_0134.jpg',\n",
       " 'Img_020_0652.jpg',\n",
       " 'Img_020_0646.jpg',\n",
       " 'Img_020_0120.jpg',\n",
       " 'Img_020_0108.jpg',\n",
       " 'Img_020_0493.jpg',\n",
       " 'Img_020_0487.jpg',\n",
       " 'Img_020_0450.jpg',\n",
       " 'Img_020_0336.jpg',\n",
       " 'Img_020_0322.jpg',\n",
       " 'Img_020_0444.jpg',\n",
       " 'Img_020_0478.jpg',\n",
       " 'Img_020_0281.jpg',\n",
       " 'Img_020_0295.jpg',\n",
       " 'Img_020_0524.jpg',\n",
       " 'Img_020_0242.jpg',\n",
       " 'Img_020_0256.jpg',\n",
       " 'Img_020_0530.jpg',\n",
       " 'Img_020_0518.jpg',\n",
       " 'Img_020_0083.jpg',\n",
       " 'Img_020_0929.jpg',\n",
       " 'Img_020_0097.jpg',\n",
       " 'Img_020_0901.jpg',\n",
       " 'Img_020_0915.jpg',\n",
       " 'Img_020_0040.jpg',\n",
       " 'Img_020_0726.jpg',\n",
       " 'Img_020_0732.jpg',\n",
       " 'Img_020_0054.jpg',\n",
       " 'Img_020_0068.jpg',\n",
       " 'Img_020_0755.jpg',\n",
       " 'Img_020_0027.jpg',\n",
       " 'Img_020_0741.jpg',\n",
       " 'Img_020_0769.jpg',\n",
       " 'Img_020_0796.jpg',\n",
       " 'Img_020_0782.jpg',\n",
       " 'Img_020_0972.jpg',\n",
       " 'Img_020_0966.jpg',\n",
       " 'Img_020_0231.jpg',\n",
       " 'Img_020_0557.jpg',\n",
       " 'Img_020_0543.jpg',\n",
       " 'Img_020_0225.jpg',\n",
       " 'Img_020_0219.jpg',\n",
       " 'Img_020_0594.jpg',\n",
       " 'Img_020_0580.jpg',\n",
       " 'Img_020_0345.jpg',\n",
       " 'Img_020_0423.jpg',\n",
       " 'Img_020_0437.jpg',\n",
       " 'Img_020_0351.jpg',\n",
       " 'Img_020_0379.jpg',\n",
       " 'Img_020_0386.jpg',\n",
       " 'Img_020_0392.jpg',\n",
       " 'Img_020_0621.jpg',\n",
       " 'Img_020_0147.jpg',\n",
       " 'Img_020_0153.jpg',\n",
       " 'Img_020_0635.jpg',\n",
       " 'Img_020_0609.jpg',\n",
       " 'Img_020_0184.jpg',\n",
       " 'Img_020_0190.jpg',\n",
       " 'Img_020_0806.jpg',\n",
       " 'Img_020_0812.jpg',\n",
       " 'Img_020_0813.jpg',\n",
       " 'Img_020_0807.jpg',\n",
       " 'Img_020_0191.jpg',\n",
       " 'Img_020_0185.jpg',\n",
       " 'Img_020_0608.jpg',\n",
       " 'Img_020_0152.jpg',\n",
       " 'Img_020_0634.jpg',\n",
       " 'Img_020_0620.jpg',\n",
       " 'Img_020_0146.jpg',\n",
       " 'Img_020_0393.jpg',\n",
       " 'Img_020_0387.jpg',\n",
       " 'Img_020_0378.jpg',\n",
       " 'Img_020_0436.jpg',\n",
       " 'Img_020_0350.jpg',\n",
       " 'Img_020_0344.jpg',\n",
       " 'Img_020_0422.jpg',\n",
       " 'Img_020_0581.jpg',\n",
       " 'Img_020_0595.jpg',\n",
       " 'Img_020_0218.jpg',\n",
       " 'Img_020_0542.jpg',\n",
       " 'Img_020_0224.jpg',\n",
       " 'Img_020_0230.jpg',\n",
       " 'Img_020_0556.jpg',\n",
       " 'Img_020_0967.jpg',\n",
       " 'Img_020_0973.jpg',\n",
       " 'Img_020_0783.jpg',\n",
       " 'Img_020_0797.jpg',\n",
       " 'Img_020_0768.jpg',\n",
       " 'Img_020_0026.jpg',\n",
       " 'Img_020_0998.jpg',\n",
       " 'Img_020_0740.jpg',\n",
       " 'Img_020_0754.jpg',\n",
       " 'Img_020_0032.jpg',\n",
       " 'Img_020_0742.jpg',\n",
       " 'Img_020_0024.jpg',\n",
       " 'Img_020_0030.jpg',\n",
       " 'Img_020_0756.jpg',\n",
       " 'Img_020_0018.jpg',\n",
       " 'Img_020_0959.jpg',\n",
       " 'Img_020_0781.jpg',\n",
       " 'Img_020_0795.jpg',\n",
       " 'Img_020_0965.jpg',\n",
       " 'Img_020_0971.jpg',\n",
       " 'Img_020_0226.jpg',\n",
       " 'Img_020_0540.jpg',\n",
       " 'Img_020_0554.jpg',\n",
       " 'Img_020_0232.jpg',\n",
       " 'Img_020_0568.jpg',\n",
       " 'Img_020_0583.jpg',\n",
       " 'Img_020_0597.jpg',\n",
       " 'Img_020_0352.jpg',\n",
       " 'Img_020_0434.jpg',\n",
       " 'Img_020_0420.jpg',\n",
       " 'Img_020_0346.jpg',\n",
       " 'Img_020_0408.jpg',\n",
       " 'Img_020_0391.jpg',\n",
       " 'Img_020_0385.jpg',\n",
       " 'Img_020_0636.jpg',\n",
       " 'Img_020_0150.jpg',\n",
       " 'Img_020_0144.jpg',\n",
       " 'Img_020_0622.jpg',\n",
       " 'Img_020_0178.jpg',\n",
       " 'Img_020_0193.jpg',\n",
       " 'Img_020_0187.jpg',\n",
       " 'Img_020_0839.jpg',\n",
       " 'Img_020_0811.jpg',\n",
       " 'Img_020_0805.jpg',\n",
       " 'Img_020_0804.jpg',\n",
       " 'Img_020_0810.jpg',\n",
       " 'Img_020_0186.jpg',\n",
       " 'Img_020_0838.jpg',\n",
       " 'Img_020_0192.jpg',\n",
       " 'Img_020_0179.jpg',\n",
       " 'Img_020_0145.jpg',\n",
       " 'Img_020_0623.jpg',\n",
       " 'Img_020_0637.jpg',\n",
       " 'Img_020_0151.jpg',\n",
       " 'Img_020_0384.jpg',\n",
       " 'Img_020_0390.jpg',\n",
       " 'Img_020_0409.jpg',\n",
       " 'Img_020_0421.jpg',\n",
       " 'Img_020_0347.jpg',\n",
       " 'Img_020_0353.jpg',\n",
       " 'Img_020_0435.jpg',\n",
       " 'Img_020_0596.jpg',\n",
       " 'Img_020_0582.jpg',\n",
       " 'Img_020_0569.jpg',\n",
       " 'Img_020_0555.jpg',\n",
       " 'Img_020_0233.jpg',\n",
       " 'Img_020_0227.jpg',\n",
       " 'Img_020_0541.jpg',\n",
       " 'Img_020_0970.jpg',\n",
       " 'Img_020_0964.jpg',\n",
       " 'Img_020_0794.jpg',\n",
       " 'Img_020_0780.jpg',\n",
       " 'Img_020_0958.jpg',\n",
       " 'Img_020_0019.jpg',\n",
       " 'Img_020_0031.jpg',\n",
       " 'Img_020_0757.jpg',\n",
       " 'Img_020_0743.jpg',\n",
       " 'Img_020_0025.jpg',\n",
       " 'Img_020_0009.jpg',\n",
       " 'Img_020_0021.jpg',\n",
       " 'Img_020_0747.jpg',\n",
       " 'Img_020_0753.jpg',\n",
       " 'Img_020_0035.jpg',\n",
       " 'Img_020_0960.jpg',\n",
       " 'Img_020_0974.jpg',\n",
       " 'Img_020_0784.jpg',\n",
       " 'Img_020_0948.jpg',\n",
       " 'Img_020_0790.jpg',\n",
       " 'Img_020_0579.jpg',\n",
       " 'Img_020_0545.jpg',\n",
       " 'Img_020_0223.jpg',\n",
       " 'Img_020_0237.jpg',\n",
       " 'Img_020_0551.jpg',\n",
       " 'Img_020_0586.jpg',\n",
       " 'Img_020_0592.jpg',\n",
       " 'Img_020_0419.jpg',\n",
       " 'Img_020_0431.jpg',\n",
       " 'Img_020_0357.jpg',\n",
       " 'Img_020_0343.jpg',\n",
       " 'Img_020_0425.jpg',\n",
       " 'Img_020_0394.jpg',\n",
       " 'Img_020_0380.jpg',\n",
       " 'Img_020_0169.jpg',\n",
       " 'Img_020_0155.jpg',\n",
       " 'Img_020_0633.jpg',\n",
       " 'Img_020_0627.jpg',\n",
       " 'Img_020_0141.jpg',\n",
       " 'Img_020_0814.jpg',\n",
       " 'Img_020_0800.jpg',\n",
       " 'Img_020_0196.jpg',\n",
       " 'Img_020_0828.jpg',\n",
       " 'Img_020_0182.jpg',\n",
       " 'Img_020_0183.jpg',\n",
       " 'Img_020_0197.jpg',\n",
       " 'Img_020_0829.jpg',\n",
       " 'Img_020_0801.jpg',\n",
       " 'Img_020_0815.jpg',\n",
       " 'Img_020_0626.jpg',\n",
       " 'Img_020_0140.jpg',\n",
       " 'Img_020_0154.jpg',\n",
       " 'Img_020_0632.jpg',\n",
       " 'Img_020_0168.jpg',\n",
       " 'Img_020_0381.jpg',\n",
       " 'Img_020_0395.jpg',\n",
       " 'Img_020_0342.jpg',\n",
       " 'Img_020_0424.jpg',\n",
       " 'Img_020_0430.jpg',\n",
       " 'Img_020_0356.jpg',\n",
       " 'Img_020_0418.jpg',\n",
       " 'Img_020_0593.jpg',\n",
       " 'Img_020_0587.jpg',\n",
       " 'Img_020_0236.jpg',\n",
       " 'Img_020_0550.jpg',\n",
       " 'Img_020_0544.jpg',\n",
       " 'Img_020_0222.jpg',\n",
       " 'Img_020_0578.jpg',\n",
       " 'Img_020_0791.jpg',\n",
       " 'Img_020_0949.jpg',\n",
       " 'Img_020_0785.jpg',\n",
       " 'Img_020_0975.jpg',\n",
       " 'Img_020_0961.jpg',\n",
       " 'Img_020_0752.jpg',\n",
       " 'Img_020_0034.jpg',\n",
       " 'Img_020_0020.jpg',\n",
       " 'Img_020_0746.jpg',\n",
       " 'Img_020_0008.jpg',\n",
       " 'Img_020_0778.jpg',\n",
       " 'Img_020_0036.jpg',\n",
       " 'Img_020_0750.jpg',\n",
       " 'Img_020_0988.jpg',\n",
       " 'Img_020_0744.jpg',\n",
       " 'Img_020_0022.jpg',\n",
       " 'Img_020_0977.jpg',\n",
       " 'Img_020_0963.jpg',\n",
       " 'Img_020_0793.jpg',\n",
       " 'Img_020_0787.jpg',\n",
       " 'Img_020_0208.jpg',\n",
       " 'Img_020_0552.jpg',\n",
       " 'Img_020_0234.jpg',\n",
       " 'Img_020_0220.jpg',\n",
       " 'Img_020_0546.jpg',\n",
       " 'Img_020_0591.jpg',\n",
       " 'Img_020_0585.jpg',\n",
       " 'Img_020_0368.jpg',\n",
       " 'Img_020_0426.jpg',\n",
       " 'Img_020_0340.jpg',\n",
       " 'Img_020_0354.jpg',\n",
       " 'Img_020_0432.jpg',\n",
       " 'Img_020_0383.jpg',\n",
       " 'Img_020_0397.jpg',\n",
       " 'Img_020_0618.jpg',\n",
       " 'Img_020_0142.jpg',\n",
       " 'Img_020_0624.jpg',\n",
       " 'Img_020_0630.jpg',\n",
       " 'Img_020_0156.jpg',\n",
       " 'Img_020_0803.jpg',\n",
       " 'Img_020_0817.jpg',\n",
       " 'Img_020_0181.jpg',\n",
       " 'Img_020_0195.jpg',\n",
       " 'Img_020_0194.jpg',\n",
       " 'Img_020_0180.jpg',\n",
       " 'Img_020_0816.jpg',\n",
       " 'Img_020_0802.jpg',\n",
       " 'Img_020_0631.jpg',\n",
       " 'Img_020_0157.jpg',\n",
       " 'Img_020_0143.jpg',\n",
       " 'Img_020_0625.jpg',\n",
       " 'Img_020_0619.jpg',\n",
       " 'Img_020_0396.jpg',\n",
       " 'Img_020_0382.jpg',\n",
       " 'Img_020_0355.jpg',\n",
       " 'Img_020_0433.jpg',\n",
       " 'Img_020_0427.jpg',\n",
       " 'Img_020_0341.jpg',\n",
       " 'Img_020_0369.jpg',\n",
       " 'Img_020_0584.jpg',\n",
       " 'Img_020_0590.jpg',\n",
       " 'Img_020_0221.jpg',\n",
       " 'Img_020_0547.jpg',\n",
       " 'Img_020_0553.jpg',\n",
       " 'Img_020_0235.jpg',\n",
       " 'Img_020_0209.jpg',\n",
       " 'Img_020_0786.jpg',\n",
       " 'Img_020_0792.jpg',\n",
       " 'Img_020_0962.jpg',\n",
       " 'Img_020_0976.jpg',\n",
       " 'Img_020_0745.jpg',\n",
       " 'Img_020_0023.jpg',\n",
       " 'Img_020_0037.jpg',\n",
       " 'Img_020_0989.jpg',\n",
       " 'Img_020_0751.jpg',\n",
       " 'Img_020_0779.jpg',\n",
       " 'Img_005_0488.jpg',\n",
       " 'Img_005_0339.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "17c21805",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_train_dataset = FoodData(kor_train_data, kor_input_root_dir, 256, transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "314da3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "valid_size = 0.2\n",
    "num = kor_train_data.__len__()\n",
    "# Dividing the indices for train and cross validation\n",
    "indices = list(range(num))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size*num))\n",
    "kor_train_idx,kor_valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "#Create Samplers\n",
    "kor_train_sampler = SubsetRandomSampler(kor_train_idx)\n",
    "kor_valid_sampler = SubsetRandomSampler(kor_valid_idx)\n",
    "\n",
    "kor_train_loader = DataLoader(kor_train_dataset, batch_size = batch, sampler = kor_train_sampler)\n",
    "kor_valid_loader = DataLoader(kor_train_dataset, batch_size = batch, sampler = kor_valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "11755999",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_dataloaders = {}\n",
    "kor_dataset_sizes = {}\n",
    "kor_dataloaders['train'] = kor_train_loader\n",
    "kor_dataloaders['val'] = kor_valid_loader\n",
    "kor_dataset_sizes['train'] = kor_train_sampler.__len__()\n",
    "kor_dataset_sizes['val'] = kor_valid_sampler.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06ae40ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/munseunghyeon/input/food-101/food-101/meta/train.txt\n"
     ]
    }
   ],
   "source": [
    "print(train_img_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03a51132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: 40], \tTest Loss: 0.2233, \tTest Accuracy: 68.37 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "   print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        EPOCHS, valid_loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95208323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH: 40], \tTest Loss: 0.2233, \tTest Accuracy: 83.07 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "   print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        EPOCHS, valid_loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dd1014f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kor_dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]) :\n\u001b[1;32m      2\u001b[0m         image \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      3\u001b[0m         label \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m, in \u001b[0;36mFoodData.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,index):\n\u001b[0;32m---> 13\u001b[0m     label,img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path[index]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/images/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mlabel\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mimg_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "for batch_idx, item in enumerate(kor_dataloaders['train']) :\n",
    "        image = item['gt'].to(DEVICE)\n",
    "        label = item['label'].to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        image = image.to(torch.float32)\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9b1e6e7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m kor_dataloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m] :\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m, in \u001b[0;36mFoodData.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,index):\n\u001b[0;32m---> 13\u001b[0m     label,img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path[index]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/images/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mlabel\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mimg_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "for i in kor_dataloaders['train'] :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5cf8fb33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkor_dataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model2, kor_dataloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[EPOCH: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     14\u001b[0m         epoch, valid_loss, valid_accuracy))\n",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, log_interval)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, train_loader, optimizer, log_interval):\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader) :\n\u001b[1;32m      5\u001b[0m         image \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      6\u001b[0m         label \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cap/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m, in \u001b[0;36mFoodData.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,index):\n\u001b[0;32m---> 13\u001b[0m     label,img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path[index]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/images/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mlabel\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mimg_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "model2 = models.resnet18()\n",
    "num_ftrs = model2.fc.in_features\n",
    "model2.fc = nn.Linear(num_ftrs, 150)\n",
    "model2 = model2.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "\n",
    "EPOCHS = 2\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model2, kor_dataloaders[\"train\"], optimizer, log_interval = 5)\n",
    "    valid_loss, valid_accuracy = evaluate(model2, kor_dataloaders[\"val\"])\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, valid_loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9fe99fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "947"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders['train'].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "16d95168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1848"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_dataloaders['train'].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc045a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb0987d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
